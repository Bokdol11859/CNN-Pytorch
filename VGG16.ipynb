{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfISOy7pnIvC0/BihH5Cig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bokdol11859/CNN-Pytorch/blob/main/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBtSusDQJmIF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter('runs/cifar10123')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Fl9taVmm1qAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper-parameter\n",
        "num_epochs = 30\n",
        "batch_size = 40\n",
        "learning_rate = 0.001\n",
        "num_classes = 10"
      ],
      "metadata": {
        "id": "KcM-h2K01rn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KklT1mb1tdG",
        "outputId": "2048dae3-f266-4e9d-93aa-1c59847c3e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VggNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VggNet, self).__init__()\n",
        "\n",
        "    self.cnn_layers = Seqential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d(output_size = (7, 7))\n",
        "    \n",
        "    self.linear_layers = Sequential(\n",
        "        nn.Linear(in_features=512*7*7, out_features=4096),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(p=0.5),\n",
        "        \n",
        "        nn.Linear(in_features=4096, out_features=4096),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(p=0.5),\n",
        "\n",
        "        nn.Linear(in_features=4096, out_features=10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.cnn_layers(x)\n",
        "    out = out.view(-1, 512*7*7)\n",
        "    out = self.avgpool(out)\n",
        "    out = self.linear_layers(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "aO5tljM_mQqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "model = models.vgg16().to(device)\n",
        "# model = VggNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11dePg-c1O0S",
        "outputId": "e76a347b-f3a9-4433-a7f7-b4471bf956e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_steps = len(train_loader)\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start.record()\n",
        "running_loss = 0.0\n",
        "running_correct = 0.0\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    #Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass, update\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    running_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    if (i+1) % 10 == 0:\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "      writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
        "      writer.add_scalar('accuracy', running_correct / 100, epoch * n_total_steps + i)\n",
        "      running_loss = 0.0\n",
        "      running_correct = 0.0\n",
        "      FILE = 'model.pth'\n",
        "      torch.save(model, FILE)\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()\n",
        "print('Training Done')\n",
        "print(start.elapsed_time(end))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EtFhWDT14pM",
        "outputId": "d9c13c2f-93bd-4faa-9128-0d35f77d39f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Step [10/1250], Loss: 6.8141\n",
            "Epoch [1/30], Step [20/1250], Loss: 5.2584\n",
            "Epoch [1/30], Step [30/1250], Loss: 4.3395\n",
            "Epoch [1/30], Step [40/1250], Loss: 3.0606\n",
            "Epoch [1/30], Step [50/1250], Loss: 2.6897\n",
            "Epoch [1/30], Step [60/1250], Loss: 2.3885\n",
            "Epoch [1/30], Step [70/1250], Loss: 2.4557\n",
            "Epoch [1/30], Step [80/1250], Loss: 2.2340\n",
            "Epoch [1/30], Step [90/1250], Loss: 2.4720\n",
            "Epoch [1/30], Step [100/1250], Loss: 2.4118\n",
            "Epoch [1/30], Step [110/1250], Loss: 2.3453\n",
            "Epoch [1/30], Step [120/1250], Loss: 2.3568\n",
            "Epoch [1/30], Step [130/1250], Loss: 2.2873\n",
            "Epoch [1/30], Step [140/1250], Loss: 2.4258\n",
            "Epoch [1/30], Step [150/1250], Loss: 2.2238\n",
            "Epoch [1/30], Step [160/1250], Loss: 2.2677\n",
            "Epoch [1/30], Step [170/1250], Loss: 2.3715\n",
            "Epoch [1/30], Step [180/1250], Loss: 2.2947\n",
            "Epoch [1/30], Step [190/1250], Loss: 2.2372\n",
            "Epoch [1/30], Step [200/1250], Loss: 2.2885\n",
            "Epoch [1/30], Step [210/1250], Loss: 2.1641\n",
            "Epoch [1/30], Step [220/1250], Loss: 2.2905\n",
            "Epoch [1/30], Step [230/1250], Loss: 2.2187\n",
            "Epoch [1/30], Step [240/1250], Loss: 2.0448\n",
            "Epoch [1/30], Step [250/1250], Loss: 2.1463\n",
            "Epoch [1/30], Step [260/1250], Loss: 2.2544\n",
            "Epoch [1/30], Step [270/1250], Loss: 2.0472\n",
            "Epoch [1/30], Step [280/1250], Loss: 2.1825\n",
            "Epoch [1/30], Step [290/1250], Loss: 2.1940\n",
            "Epoch [1/30], Step [300/1250], Loss: 1.8864\n",
            "Epoch [1/30], Step [310/1250], Loss: 2.0222\n",
            "Epoch [1/30], Step [320/1250], Loss: 2.0381\n",
            "Epoch [1/30], Step [330/1250], Loss: 1.9503\n",
            "Epoch [1/30], Step [340/1250], Loss: 1.8258\n",
            "Epoch [1/30], Step [350/1250], Loss: 2.3102\n",
            "Epoch [1/30], Step [360/1250], Loss: 2.1226\n",
            "Epoch [1/30], Step [370/1250], Loss: 2.2659\n",
            "Epoch [1/30], Step [380/1250], Loss: 1.9850\n",
            "Epoch [1/30], Step [390/1250], Loss: 2.1066\n",
            "Epoch [1/30], Step [400/1250], Loss: 2.2269\n",
            "Epoch [1/30], Step [410/1250], Loss: 2.0979\n",
            "Epoch [1/30], Step [420/1250], Loss: 1.8755\n",
            "Epoch [1/30], Step [430/1250], Loss: 2.0217\n",
            "Epoch [1/30], Step [440/1250], Loss: 2.0696\n",
            "Epoch [1/30], Step [450/1250], Loss: 1.8614\n",
            "Epoch [1/30], Step [460/1250], Loss: 1.9541\n",
            "Epoch [1/30], Step [470/1250], Loss: 1.9286\n",
            "Epoch [1/30], Step [480/1250], Loss: 2.0852\n",
            "Epoch [1/30], Step [490/1250], Loss: 2.1510\n",
            "Epoch [1/30], Step [500/1250], Loss: 2.0990\n",
            "Epoch [1/30], Step [510/1250], Loss: 1.8109\n",
            "Epoch [1/30], Step [520/1250], Loss: 1.8946\n",
            "Epoch [1/30], Step [530/1250], Loss: 2.0453\n",
            "Epoch [1/30], Step [540/1250], Loss: 1.8045\n",
            "Epoch [1/30], Step [550/1250], Loss: 1.7560\n",
            "Epoch [1/30], Step [560/1250], Loss: 1.8238\n",
            "Epoch [1/30], Step [570/1250], Loss: 1.9050\n",
            "Epoch [1/30], Step [580/1250], Loss: 1.9085\n",
            "Epoch [1/30], Step [590/1250], Loss: 2.2924\n",
            "Epoch [1/30], Step [600/1250], Loss: 1.9748\n",
            "Epoch [1/30], Step [610/1250], Loss: 2.0863\n",
            "Epoch [1/30], Step [620/1250], Loss: 1.6628\n",
            "Epoch [1/30], Step [630/1250], Loss: 1.8025\n",
            "Epoch [1/30], Step [640/1250], Loss: 1.8559\n",
            "Epoch [1/30], Step [650/1250], Loss: 1.9964\n",
            "Epoch [1/30], Step [660/1250], Loss: 1.8920\n",
            "Epoch [1/30], Step [670/1250], Loss: 1.7173\n",
            "Epoch [1/30], Step [680/1250], Loss: 1.7571\n",
            "Epoch [1/30], Step [690/1250], Loss: 1.7995\n",
            "Epoch [1/30], Step [700/1250], Loss: 1.6823\n",
            "Epoch [1/30], Step [710/1250], Loss: 1.7894\n",
            "Epoch [1/30], Step [720/1250], Loss: 1.6759\n",
            "Epoch [1/30], Step [730/1250], Loss: 1.5577\n",
            "Epoch [1/30], Step [740/1250], Loss: 1.9562\n",
            "Epoch [1/30], Step [750/1250], Loss: 1.5662\n",
            "Epoch [1/30], Step [760/1250], Loss: 1.8691\n",
            "Epoch [1/30], Step [770/1250], Loss: 1.7559\n",
            "Epoch [1/30], Step [780/1250], Loss: 1.6382\n",
            "Epoch [1/30], Step [790/1250], Loss: 1.7082\n",
            "Epoch [1/30], Step [800/1250], Loss: 1.4985\n",
            "Epoch [1/30], Step [810/1250], Loss: 1.7187\n",
            "Epoch [1/30], Step [820/1250], Loss: 1.8017\n",
            "Epoch [1/30], Step [830/1250], Loss: 2.0367\n",
            "Epoch [1/30], Step [840/1250], Loss: 1.6096\n",
            "Epoch [1/30], Step [850/1250], Loss: 2.1101\n",
            "Epoch [1/30], Step [860/1250], Loss: 1.8472\n",
            "Epoch [1/30], Step [870/1250], Loss: 1.8124\n",
            "Epoch [1/30], Step [880/1250], Loss: 1.9173\n",
            "Epoch [1/30], Step [890/1250], Loss: 1.6659\n",
            "Epoch [1/30], Step [900/1250], Loss: 1.6896\n",
            "Epoch [1/30], Step [910/1250], Loss: 1.6397\n",
            "Epoch [1/30], Step [920/1250], Loss: 1.5657\n",
            "Epoch [1/30], Step [930/1250], Loss: 1.5056\n",
            "Epoch [1/30], Step [940/1250], Loss: 1.7627\n",
            "Epoch [1/30], Step [950/1250], Loss: 1.7522\n",
            "Epoch [1/30], Step [960/1250], Loss: 1.8616\n",
            "Epoch [1/30], Step [970/1250], Loss: 1.6970\n",
            "Epoch [1/30], Step [980/1250], Loss: 1.7301\n",
            "Epoch [1/30], Step [990/1250], Loss: 1.6646\n",
            "Epoch [1/30], Step [1000/1250], Loss: 1.5705\n",
            "Epoch [1/30], Step [1010/1250], Loss: 1.7968\n",
            "Epoch [1/30], Step [1020/1250], Loss: 1.8778\n",
            "Epoch [1/30], Step [1030/1250], Loss: 1.8654\n",
            "Epoch [1/30], Step [1040/1250], Loss: 1.8045\n",
            "Epoch [1/30], Step [1050/1250], Loss: 1.5436\n",
            "Epoch [1/30], Step [1060/1250], Loss: 1.6623\n",
            "Epoch [1/30], Step [1070/1250], Loss: 1.6930\n",
            "Epoch [1/30], Step [1080/1250], Loss: 1.8218\n",
            "Epoch [1/30], Step [1090/1250], Loss: 1.6146\n",
            "Epoch [1/30], Step [1100/1250], Loss: 1.4597\n",
            "Epoch [1/30], Step [1110/1250], Loss: 1.5867\n",
            "Epoch [1/30], Step [1120/1250], Loss: 1.5567\n",
            "Epoch [1/30], Step [1130/1250], Loss: 1.4735\n",
            "Epoch [1/30], Step [1140/1250], Loss: 1.6270\n",
            "Epoch [1/30], Step [1150/1250], Loss: 1.5467\n",
            "Epoch [1/30], Step [1160/1250], Loss: 1.5214\n",
            "Epoch [1/30], Step [1170/1250], Loss: 1.4861\n",
            "Epoch [1/30], Step [1180/1250], Loss: 1.6064\n",
            "Epoch [1/30], Step [1190/1250], Loss: 1.5789\n",
            "Epoch [1/30], Step [1200/1250], Loss: 1.4964\n",
            "Epoch [1/30], Step [1210/1250], Loss: 1.8924\n",
            "Epoch [1/30], Step [1220/1250], Loss: 1.6754\n",
            "Epoch [1/30], Step [1230/1250], Loss: 1.4994\n",
            "Epoch [1/30], Step [1240/1250], Loss: 1.8567\n",
            "Epoch [1/30], Step [1250/1250], Loss: 1.9171\n",
            "Epoch [2/30], Step [10/1250], Loss: 1.8121\n",
            "Epoch [2/30], Step [20/1250], Loss: 1.6230\n",
            "Epoch [2/30], Step [30/1250], Loss: 1.4450\n",
            "Epoch [2/30], Step [40/1250], Loss: 1.8936\n",
            "Epoch [2/30], Step [50/1250], Loss: 2.0061\n",
            "Epoch [2/30], Step [60/1250], Loss: 1.3010\n",
            "Epoch [2/30], Step [70/1250], Loss: 1.5332\n",
            "Epoch [2/30], Step [80/1250], Loss: 1.6701\n",
            "Epoch [2/30], Step [90/1250], Loss: 1.5762\n",
            "Epoch [2/30], Step [100/1250], Loss: 1.5371\n",
            "Epoch [2/30], Step [110/1250], Loss: 1.9312\n",
            "Epoch [2/30], Step [120/1250], Loss: 1.7129\n",
            "Epoch [2/30], Step [130/1250], Loss: 2.1859\n",
            "Epoch [2/30], Step [140/1250], Loss: 1.7068\n",
            "Epoch [2/30], Step [150/1250], Loss: 1.1987\n",
            "Epoch [2/30], Step [160/1250], Loss: 1.8144\n",
            "Epoch [2/30], Step [170/1250], Loss: 1.5677\n",
            "Epoch [2/30], Step [180/1250], Loss: 1.8104\n",
            "Epoch [2/30], Step [190/1250], Loss: 1.4500\n",
            "Epoch [2/30], Step [200/1250], Loss: 1.5619\n",
            "Epoch [2/30], Step [210/1250], Loss: 1.6109\n",
            "Epoch [2/30], Step [220/1250], Loss: 1.8311\n",
            "Epoch [2/30], Step [230/1250], Loss: 1.4929\n",
            "Epoch [2/30], Step [240/1250], Loss: 1.6399\n",
            "Epoch [2/30], Step [250/1250], Loss: 1.6125\n",
            "Epoch [2/30], Step [260/1250], Loss: 1.7117\n",
            "Epoch [2/30], Step [270/1250], Loss: 1.5400\n",
            "Epoch [2/30], Step [280/1250], Loss: 1.3444\n",
            "Epoch [2/30], Step [290/1250], Loss: 1.7303\n",
            "Epoch [2/30], Step [300/1250], Loss: 1.4542\n",
            "Epoch [2/30], Step [310/1250], Loss: 1.4899\n",
            "Epoch [2/30], Step [320/1250], Loss: 1.5378\n",
            "Epoch [2/30], Step [330/1250], Loss: 1.5323\n",
            "Epoch [2/30], Step [340/1250], Loss: 1.4728\n",
            "Epoch [2/30], Step [350/1250], Loss: 1.6318\n",
            "Epoch [2/30], Step [360/1250], Loss: 1.5354\n",
            "Epoch [2/30], Step [370/1250], Loss: 1.5069\n",
            "Epoch [2/30], Step [380/1250], Loss: 1.6891\n",
            "Epoch [2/30], Step [390/1250], Loss: 1.8364\n",
            "Epoch [2/30], Step [400/1250], Loss: 1.6187\n",
            "Epoch [2/30], Step [410/1250], Loss: 1.5204\n",
            "Epoch [2/30], Step [420/1250], Loss: 1.5612\n",
            "Epoch [2/30], Step [430/1250], Loss: 1.4339\n",
            "Epoch [2/30], Step [440/1250], Loss: 1.4604\n",
            "Epoch [2/30], Step [450/1250], Loss: 1.5929\n",
            "Epoch [2/30], Step [460/1250], Loss: 1.1883\n",
            "Epoch [2/30], Step [470/1250], Loss: 1.4976\n",
            "Epoch [2/30], Step [480/1250], Loss: 1.6612\n",
            "Epoch [2/30], Step [490/1250], Loss: 1.3484\n",
            "Epoch [2/30], Step [500/1250], Loss: 1.2108\n",
            "Epoch [2/30], Step [510/1250], Loss: 1.1536\n",
            "Epoch [2/30], Step [520/1250], Loss: 1.3405\n",
            "Epoch [2/30], Step [530/1250], Loss: 1.4335\n",
            "Epoch [2/30], Step [540/1250], Loss: 1.4626\n",
            "Epoch [2/30], Step [550/1250], Loss: 1.5239\n",
            "Epoch [2/30], Step [560/1250], Loss: 1.4330\n",
            "Epoch [2/30], Step [570/1250], Loss: 1.5026\n",
            "Epoch [2/30], Step [580/1250], Loss: 1.5371\n",
            "Epoch [2/30], Step [590/1250], Loss: 1.3067\n",
            "Epoch [2/30], Step [600/1250], Loss: 1.6852\n",
            "Epoch [2/30], Step [610/1250], Loss: 1.3796\n",
            "Epoch [2/30], Step [620/1250], Loss: 1.3391\n",
            "Epoch [2/30], Step [630/1250], Loss: 1.3041\n",
            "Epoch [2/30], Step [640/1250], Loss: 1.3371\n",
            "Epoch [2/30], Step [650/1250], Loss: 1.3088\n",
            "Epoch [2/30], Step [660/1250], Loss: 1.2871\n",
            "Epoch [2/30], Step [670/1250], Loss: 1.5477\n",
            "Epoch [2/30], Step [680/1250], Loss: 1.5936\n",
            "Epoch [2/30], Step [690/1250], Loss: 1.5706\n",
            "Epoch [2/30], Step [700/1250], Loss: 1.7060\n",
            "Epoch [2/30], Step [710/1250], Loss: 1.1345\n",
            "Epoch [2/30], Step [720/1250], Loss: 1.4369\n",
            "Epoch [2/30], Step [730/1250], Loss: 1.4023\n",
            "Epoch [2/30], Step [740/1250], Loss: 1.5117\n",
            "Epoch [2/30], Step [750/1250], Loss: 1.7226\n",
            "Epoch [2/30], Step [760/1250], Loss: 1.4014\n",
            "Epoch [2/30], Step [770/1250], Loss: 1.5019\n",
            "Epoch [2/30], Step [780/1250], Loss: 1.5476\n",
            "Epoch [2/30], Step [790/1250], Loss: 1.4711\n",
            "Epoch [2/30], Step [800/1250], Loss: 1.1740\n",
            "Epoch [2/30], Step [810/1250], Loss: 1.2737\n",
            "Epoch [2/30], Step [820/1250], Loss: 1.3846\n",
            "Epoch [2/30], Step [830/1250], Loss: 1.5412\n",
            "Epoch [2/30], Step [840/1250], Loss: 1.4887\n",
            "Epoch [2/30], Step [850/1250], Loss: 1.4883\n",
            "Epoch [2/30], Step [860/1250], Loss: 1.3401\n",
            "Epoch [2/30], Step [870/1250], Loss: 1.4538\n",
            "Epoch [2/30], Step [880/1250], Loss: 1.4516\n",
            "Epoch [2/30], Step [890/1250], Loss: 1.3743\n",
            "Epoch [2/30], Step [900/1250], Loss: 1.5002\n",
            "Epoch [2/30], Step [910/1250], Loss: 1.3861\n",
            "Epoch [2/30], Step [920/1250], Loss: 1.3205\n",
            "Epoch [2/30], Step [930/1250], Loss: 1.3199\n",
            "Epoch [2/30], Step [940/1250], Loss: 1.2234\n",
            "Epoch [2/30], Step [950/1250], Loss: 1.1161\n",
            "Epoch [2/30], Step [960/1250], Loss: 1.0713\n",
            "Epoch [2/30], Step [970/1250], Loss: 1.0673\n",
            "Epoch [2/30], Step [980/1250], Loss: 1.6554\n",
            "Epoch [2/30], Step [990/1250], Loss: 1.2302\n",
            "Epoch [2/30], Step [1000/1250], Loss: 1.2383\n",
            "Epoch [2/30], Step [1010/1250], Loss: 1.6226\n",
            "Epoch [2/30], Step [1020/1250], Loss: 1.2507\n",
            "Epoch [2/30], Step [1030/1250], Loss: 1.2040\n",
            "Epoch [2/30], Step [1040/1250], Loss: 1.3731\n",
            "Epoch [2/30], Step [1050/1250], Loss: 1.2114\n",
            "Epoch [2/30], Step [1060/1250], Loss: 1.3305\n",
            "Epoch [2/30], Step [1070/1250], Loss: 1.3386\n",
            "Epoch [2/30], Step [1080/1250], Loss: 1.3151\n",
            "Epoch [2/30], Step [1090/1250], Loss: 1.4490\n",
            "Epoch [2/30], Step [1100/1250], Loss: 1.3448\n",
            "Epoch [2/30], Step [1110/1250], Loss: 1.6845\n",
            "Epoch [2/30], Step [1120/1250], Loss: 1.6273\n",
            "Epoch [2/30], Step [1130/1250], Loss: 1.3511\n",
            "Epoch [2/30], Step [1140/1250], Loss: 1.0075\n",
            "Epoch [2/30], Step [1150/1250], Loss: 1.2953\n",
            "Epoch [2/30], Step [1160/1250], Loss: 1.3118\n",
            "Epoch [2/30], Step [1170/1250], Loss: 1.3120\n",
            "Epoch [2/30], Step [1180/1250], Loss: 1.5944\n",
            "Epoch [2/30], Step [1190/1250], Loss: 1.3273\n",
            "Epoch [2/30], Step [1200/1250], Loss: 1.2872\n",
            "Epoch [2/30], Step [1210/1250], Loss: 1.3880\n",
            "Epoch [2/30], Step [1220/1250], Loss: 1.0085\n",
            "Epoch [2/30], Step [1230/1250], Loss: 1.2589\n",
            "Epoch [2/30], Step [1240/1250], Loss: 1.0608\n",
            "Epoch [2/30], Step [1250/1250], Loss: 1.5080\n",
            "Epoch [3/30], Step [10/1250], Loss: 1.3090\n",
            "Epoch [3/30], Step [20/1250], Loss: 1.3373\n",
            "Epoch [3/30], Step [30/1250], Loss: 0.9467\n",
            "Epoch [3/30], Step [40/1250], Loss: 1.3680\n",
            "Epoch [3/30], Step [50/1250], Loss: 0.9519\n",
            "Epoch [3/30], Step [60/1250], Loss: 1.4273\n",
            "Epoch [3/30], Step [70/1250], Loss: 1.2578\n",
            "Epoch [3/30], Step [80/1250], Loss: 1.2142\n",
            "Epoch [3/30], Step [90/1250], Loss: 1.2278\n",
            "Epoch [3/30], Step [100/1250], Loss: 1.4012\n",
            "Epoch [3/30], Step [110/1250], Loss: 1.3245\n",
            "Epoch [3/30], Step [120/1250], Loss: 1.3127\n",
            "Epoch [3/30], Step [130/1250], Loss: 1.6442\n",
            "Epoch [3/30], Step [140/1250], Loss: 1.3815\n",
            "Epoch [3/30], Step [150/1250], Loss: 1.1090\n",
            "Epoch [3/30], Step [160/1250], Loss: 1.3098\n",
            "Epoch [3/30], Step [170/1250], Loss: 1.4002\n",
            "Epoch [3/30], Step [180/1250], Loss: 1.5157\n",
            "Epoch [3/30], Step [190/1250], Loss: 1.1219\n",
            "Epoch [3/30], Step [200/1250], Loss: 1.1786\n",
            "Epoch [3/30], Step [210/1250], Loss: 1.2721\n",
            "Epoch [3/30], Step [220/1250], Loss: 1.3321\n",
            "Epoch [3/30], Step [230/1250], Loss: 1.1756\n",
            "Epoch [3/30], Step [240/1250], Loss: 1.3765\n",
            "Epoch [3/30], Step [250/1250], Loss: 1.2595\n",
            "Epoch [3/30], Step [260/1250], Loss: 1.6631\n",
            "Epoch [3/30], Step [270/1250], Loss: 1.2787\n",
            "Epoch [3/30], Step [280/1250], Loss: 1.0656\n",
            "Epoch [3/30], Step [290/1250], Loss: 1.5157\n",
            "Epoch [3/30], Step [300/1250], Loss: 1.1935\n",
            "Epoch [3/30], Step [310/1250], Loss: 1.2132\n",
            "Epoch [3/30], Step [320/1250], Loss: 1.2798\n",
            "Epoch [3/30], Step [330/1250], Loss: 1.3609\n",
            "Epoch [3/30], Step [340/1250], Loss: 1.0645\n",
            "Epoch [3/30], Step [350/1250], Loss: 1.3436\n",
            "Epoch [3/30], Step [360/1250], Loss: 1.3580\n",
            "Epoch [3/30], Step [370/1250], Loss: 1.5407\n",
            "Epoch [3/30], Step [380/1250], Loss: 1.3390\n",
            "Epoch [3/30], Step [390/1250], Loss: 1.3283\n",
            "Epoch [3/30], Step [400/1250], Loss: 1.1887\n",
            "Epoch [3/30], Step [410/1250], Loss: 1.1548\n",
            "Epoch [3/30], Step [420/1250], Loss: 1.2055\n",
            "Epoch [3/30], Step [430/1250], Loss: 1.4476\n",
            "Epoch [3/30], Step [440/1250], Loss: 1.1644\n",
            "Epoch [3/30], Step [450/1250], Loss: 1.1906\n",
            "Epoch [3/30], Step [460/1250], Loss: 1.3025\n",
            "Epoch [3/30], Step [470/1250], Loss: 1.3312\n",
            "Epoch [3/30], Step [480/1250], Loss: 1.1398\n",
            "Epoch [3/30], Step [490/1250], Loss: 1.2304\n",
            "Epoch [3/30], Step [500/1250], Loss: 1.4139\n",
            "Epoch [3/30], Step [510/1250], Loss: 1.3175\n",
            "Epoch [3/30], Step [520/1250], Loss: 1.2542\n",
            "Epoch [3/30], Step [530/1250], Loss: 1.2844\n",
            "Epoch [3/30], Step [540/1250], Loss: 1.2582\n",
            "Epoch [3/30], Step [550/1250], Loss: 0.8993\n",
            "Epoch [3/30], Step [560/1250], Loss: 1.1125\n",
            "Epoch [3/30], Step [570/1250], Loss: 1.1871\n",
            "Epoch [3/30], Step [580/1250], Loss: 1.0963\n",
            "Epoch [3/30], Step [590/1250], Loss: 1.1941\n",
            "Epoch [3/30], Step [600/1250], Loss: 1.1648\n",
            "Epoch [3/30], Step [610/1250], Loss: 1.4332\n",
            "Epoch [3/30], Step [620/1250], Loss: 1.1351\n",
            "Epoch [3/30], Step [630/1250], Loss: 1.1506\n",
            "Epoch [3/30], Step [640/1250], Loss: 1.1291\n",
            "Epoch [3/30], Step [650/1250], Loss: 1.1381\n",
            "Epoch [3/30], Step [660/1250], Loss: 1.1520\n",
            "Epoch [3/30], Step [670/1250], Loss: 1.4044\n",
            "Epoch [3/30], Step [680/1250], Loss: 1.3726\n",
            "Epoch [3/30], Step [690/1250], Loss: 1.4307\n",
            "Epoch [3/30], Step [700/1250], Loss: 1.1317\n",
            "Epoch [3/30], Step [710/1250], Loss: 1.2093\n",
            "Epoch [3/30], Step [720/1250], Loss: 1.1480\n",
            "Epoch [3/30], Step [730/1250], Loss: 1.2354\n",
            "Epoch [3/30], Step [740/1250], Loss: 1.3477\n",
            "Epoch [3/30], Step [750/1250], Loss: 1.1089\n",
            "Epoch [3/30], Step [760/1250], Loss: 0.8531\n",
            "Epoch [3/30], Step [770/1250], Loss: 1.0496\n",
            "Epoch [3/30], Step [780/1250], Loss: 1.2627\n",
            "Epoch [3/30], Step [790/1250], Loss: 1.3570\n",
            "Epoch [3/30], Step [800/1250], Loss: 1.2830\n",
            "Epoch [3/30], Step [810/1250], Loss: 0.7528\n",
            "Epoch [3/30], Step [820/1250], Loss: 1.4530\n",
            "Epoch [3/30], Step [830/1250], Loss: 1.2669\n",
            "Epoch [3/30], Step [840/1250], Loss: 1.2491\n",
            "Epoch [3/30], Step [850/1250], Loss: 0.9213\n",
            "Epoch [3/30], Step [860/1250], Loss: 1.0000\n",
            "Epoch [3/30], Step [870/1250], Loss: 1.0521\n",
            "Epoch [3/30], Step [880/1250], Loss: 1.2007\n",
            "Epoch [3/30], Step [890/1250], Loss: 1.3322\n",
            "Epoch [3/30], Step [900/1250], Loss: 1.0877\n",
            "Epoch [3/30], Step [910/1250], Loss: 1.1874\n",
            "Epoch [3/30], Step [920/1250], Loss: 1.2714\n",
            "Epoch [3/30], Step [930/1250], Loss: 0.9547\n",
            "Epoch [3/30], Step [940/1250], Loss: 1.2451\n",
            "Epoch [3/30], Step [950/1250], Loss: 1.3342\n",
            "Epoch [3/30], Step [960/1250], Loss: 1.0380\n",
            "Epoch [3/30], Step [970/1250], Loss: 0.9671\n",
            "Epoch [3/30], Step [980/1250], Loss: 1.0303\n",
            "Epoch [3/30], Step [990/1250], Loss: 1.1310\n",
            "Epoch [3/30], Step [1000/1250], Loss: 1.3166\n",
            "Epoch [3/30], Step [1010/1250], Loss: 0.8223\n",
            "Epoch [3/30], Step [1020/1250], Loss: 0.9246\n",
            "Epoch [3/30], Step [1030/1250], Loss: 1.3668\n",
            "Epoch [3/30], Step [1040/1250], Loss: 1.2115\n",
            "Epoch [3/30], Step [1050/1250], Loss: 1.1762\n",
            "Epoch [3/30], Step [1060/1250], Loss: 1.1057\n",
            "Epoch [3/30], Step [1070/1250], Loss: 0.8464\n",
            "Epoch [3/30], Step [1080/1250], Loss: 1.1092\n",
            "Epoch [3/30], Step [1090/1250], Loss: 1.1093\n",
            "Epoch [3/30], Step [1100/1250], Loss: 0.8140\n",
            "Epoch [3/30], Step [1110/1250], Loss: 1.0604\n",
            "Epoch [3/30], Step [1120/1250], Loss: 0.9426\n",
            "Epoch [3/30], Step [1130/1250], Loss: 1.0196\n",
            "Epoch [3/30], Step [1140/1250], Loss: 1.3242\n",
            "Epoch [3/30], Step [1150/1250], Loss: 1.2466\n",
            "Epoch [3/30], Step [1160/1250], Loss: 1.1545\n",
            "Epoch [3/30], Step [1170/1250], Loss: 1.0453\n",
            "Epoch [3/30], Step [1180/1250], Loss: 1.1554\n",
            "Epoch [3/30], Step [1190/1250], Loss: 0.8747\n",
            "Epoch [3/30], Step [1200/1250], Loss: 1.3323\n",
            "Epoch [3/30], Step [1210/1250], Loss: 1.1326\n",
            "Epoch [3/30], Step [1220/1250], Loss: 1.3723\n",
            "Epoch [3/30], Step [1230/1250], Loss: 1.1511\n",
            "Epoch [3/30], Step [1240/1250], Loss: 0.8289\n",
            "Epoch [3/30], Step [1250/1250], Loss: 1.6815\n",
            "Epoch [4/30], Step [10/1250], Loss: 0.8822\n",
            "Epoch [4/30], Step [20/1250], Loss: 0.8043\n",
            "Epoch [4/30], Step [30/1250], Loss: 1.0151\n",
            "Epoch [4/30], Step [40/1250], Loss: 1.1578\n",
            "Epoch [4/30], Step [50/1250], Loss: 1.1084\n",
            "Epoch [4/30], Step [60/1250], Loss: 1.0788\n",
            "Epoch [4/30], Step [70/1250], Loss: 1.0130\n",
            "Epoch [4/30], Step [80/1250], Loss: 1.2035\n",
            "Epoch [4/30], Step [90/1250], Loss: 1.1726\n",
            "Epoch [4/30], Step [100/1250], Loss: 0.9353\n",
            "Epoch [4/30], Step [110/1250], Loss: 1.1700\n",
            "Epoch [4/30], Step [120/1250], Loss: 1.1339\n",
            "Epoch [4/30], Step [130/1250], Loss: 1.5674\n",
            "Epoch [4/30], Step [140/1250], Loss: 1.0273\n",
            "Epoch [4/30], Step [150/1250], Loss: 1.0204\n",
            "Epoch [4/30], Step [160/1250], Loss: 1.4085\n",
            "Epoch [4/30], Step [170/1250], Loss: 1.1370\n",
            "Epoch [4/30], Step [180/1250], Loss: 0.9058\n",
            "Epoch [4/30], Step [190/1250], Loss: 1.2326\n",
            "Epoch [4/30], Step [200/1250], Loss: 1.1938\n",
            "Epoch [4/30], Step [210/1250], Loss: 1.0081\n",
            "Epoch [4/30], Step [220/1250], Loss: 1.1066\n",
            "Epoch [4/30], Step [230/1250], Loss: 1.0799\n",
            "Epoch [4/30], Step [240/1250], Loss: 1.0938\n",
            "Epoch [4/30], Step [250/1250], Loss: 1.0333\n",
            "Epoch [4/30], Step [260/1250], Loss: 0.9222\n",
            "Epoch [4/30], Step [270/1250], Loss: 1.3709\n",
            "Epoch [4/30], Step [280/1250], Loss: 1.0716\n",
            "Epoch [4/30], Step [290/1250], Loss: 1.4328\n",
            "Epoch [4/30], Step [300/1250], Loss: 1.4395\n",
            "Epoch [4/30], Step [310/1250], Loss: 1.0152\n",
            "Epoch [4/30], Step [320/1250], Loss: 1.0304\n",
            "Epoch [4/30], Step [330/1250], Loss: 1.0702\n",
            "Epoch [4/30], Step [340/1250], Loss: 0.8832\n",
            "Epoch [4/30], Step [350/1250], Loss: 0.9803\n",
            "Epoch [4/30], Step [360/1250], Loss: 1.1972\n",
            "Epoch [4/30], Step [370/1250], Loss: 1.0337\n",
            "Epoch [4/30], Step [380/1250], Loss: 0.8606\n",
            "Epoch [4/30], Step [390/1250], Loss: 1.0820\n",
            "Epoch [4/30], Step [400/1250], Loss: 1.0645\n",
            "Epoch [4/30], Step [410/1250], Loss: 0.7298\n",
            "Epoch [4/30], Step [420/1250], Loss: 0.9423\n",
            "Epoch [4/30], Step [430/1250], Loss: 0.8423\n",
            "Epoch [4/30], Step [440/1250], Loss: 1.0768\n",
            "Epoch [4/30], Step [450/1250], Loss: 1.1529\n",
            "Epoch [4/30], Step [460/1250], Loss: 0.9370\n",
            "Epoch [4/30], Step [470/1250], Loss: 1.2912\n",
            "Epoch [4/30], Step [480/1250], Loss: 1.4987\n",
            "Epoch [4/30], Step [490/1250], Loss: 0.8478\n",
            "Epoch [4/30], Step [500/1250], Loss: 0.8619\n",
            "Epoch [4/30], Step [510/1250], Loss: 0.9105\n",
            "Epoch [4/30], Step [520/1250], Loss: 0.9981\n",
            "Epoch [4/30], Step [530/1250], Loss: 1.3538\n",
            "Epoch [4/30], Step [540/1250], Loss: 0.9298\n",
            "Epoch [4/30], Step [550/1250], Loss: 0.7880\n",
            "Epoch [4/30], Step [560/1250], Loss: 0.9632\n",
            "Epoch [4/30], Step [570/1250], Loss: 1.1635\n",
            "Epoch [4/30], Step [580/1250], Loss: 1.1474\n",
            "Epoch [4/30], Step [590/1250], Loss: 0.7894\n",
            "Epoch [4/30], Step [600/1250], Loss: 0.8420\n",
            "Epoch [4/30], Step [610/1250], Loss: 0.7229\n",
            "Epoch [4/30], Step [620/1250], Loss: 1.1621\n",
            "Epoch [4/30], Step [630/1250], Loss: 0.9091\n",
            "Epoch [4/30], Step [640/1250], Loss: 1.0258\n",
            "Epoch [4/30], Step [650/1250], Loss: 1.1868\n",
            "Epoch [4/30], Step [660/1250], Loss: 0.9577\n",
            "Epoch [4/30], Step [670/1250], Loss: 0.9948\n",
            "Epoch [4/30], Step [680/1250], Loss: 0.9634\n",
            "Epoch [4/30], Step [690/1250], Loss: 1.0649\n",
            "Epoch [4/30], Step [700/1250], Loss: 1.2452\n",
            "Epoch [4/30], Step [710/1250], Loss: 1.2797\n",
            "Epoch [4/30], Step [720/1250], Loss: 0.7425\n",
            "Epoch [4/30], Step [730/1250], Loss: 1.1490\n",
            "Epoch [4/30], Step [740/1250], Loss: 1.1799\n",
            "Epoch [4/30], Step [750/1250], Loss: 0.9850\n",
            "Epoch [4/30], Step [760/1250], Loss: 0.9794\n",
            "Epoch [4/30], Step [770/1250], Loss: 0.8064\n",
            "Epoch [4/30], Step [780/1250], Loss: 1.0928\n",
            "Epoch [4/30], Step [790/1250], Loss: 1.1727\n",
            "Epoch [4/30], Step [800/1250], Loss: 0.9780\n",
            "Epoch [4/30], Step [810/1250], Loss: 1.0489\n",
            "Epoch [4/30], Step [820/1250], Loss: 1.1039\n",
            "Epoch [4/30], Step [830/1250], Loss: 0.7792\n",
            "Epoch [4/30], Step [840/1250], Loss: 1.1162\n",
            "Epoch [4/30], Step [850/1250], Loss: 0.9108\n",
            "Epoch [4/30], Step [860/1250], Loss: 0.7789\n",
            "Epoch [4/30], Step [870/1250], Loss: 0.9045\n",
            "Epoch [4/30], Step [880/1250], Loss: 1.0152\n",
            "Epoch [4/30], Step [890/1250], Loss: 1.1202\n",
            "Epoch [4/30], Step [900/1250], Loss: 0.9646\n",
            "Epoch [4/30], Step [910/1250], Loss: 1.0532\n",
            "Epoch [4/30], Step [920/1250], Loss: 0.8832\n",
            "Epoch [4/30], Step [930/1250], Loss: 1.1463\n",
            "Epoch [4/30], Step [940/1250], Loss: 1.0849\n",
            "Epoch [4/30], Step [950/1250], Loss: 1.0505\n",
            "Epoch [4/30], Step [960/1250], Loss: 0.9045\n",
            "Epoch [4/30], Step [970/1250], Loss: 0.9327\n",
            "Epoch [4/30], Step [980/1250], Loss: 1.0473\n",
            "Epoch [4/30], Step [990/1250], Loss: 0.9531\n",
            "Epoch [4/30], Step [1000/1250], Loss: 0.9910\n",
            "Epoch [4/30], Step [1010/1250], Loss: 1.0231\n",
            "Epoch [4/30], Step [1020/1250], Loss: 1.1381\n",
            "Epoch [4/30], Step [1030/1250], Loss: 1.0859\n",
            "Epoch [4/30], Step [1040/1250], Loss: 0.9862\n",
            "Epoch [4/30], Step [1050/1250], Loss: 0.7198\n",
            "Epoch [4/30], Step [1060/1250], Loss: 1.2534\n",
            "Epoch [4/30], Step [1070/1250], Loss: 0.8812\n",
            "Epoch [4/30], Step [1080/1250], Loss: 1.0910\n",
            "Epoch [4/30], Step [1090/1250], Loss: 0.7746\n",
            "Epoch [4/30], Step [1100/1250], Loss: 0.8132\n",
            "Epoch [4/30], Step [1110/1250], Loss: 1.0163\n",
            "Epoch [4/30], Step [1120/1250], Loss: 0.8343\n",
            "Epoch [4/30], Step [1130/1250], Loss: 0.9641\n",
            "Epoch [4/30], Step [1140/1250], Loss: 1.0712\n",
            "Epoch [4/30], Step [1150/1250], Loss: 1.3216\n",
            "Epoch [4/30], Step [1160/1250], Loss: 0.9630\n",
            "Epoch [4/30], Step [1170/1250], Loss: 0.6590\n",
            "Epoch [4/30], Step [1180/1250], Loss: 0.8801\n",
            "Epoch [4/30], Step [1190/1250], Loss: 0.7056\n",
            "Epoch [4/30], Step [1200/1250], Loss: 0.9212\n",
            "Epoch [4/30], Step [1210/1250], Loss: 1.2072\n",
            "Epoch [4/30], Step [1220/1250], Loss: 1.1516\n",
            "Epoch [4/30], Step [1230/1250], Loss: 1.2079\n",
            "Epoch [4/30], Step [1240/1250], Loss: 1.0957\n",
            "Epoch [4/30], Step [1250/1250], Loss: 1.3135\n",
            "Epoch [5/30], Step [10/1250], Loss: 0.7664\n",
            "Epoch [5/30], Step [20/1250], Loss: 0.8136\n",
            "Epoch [5/30], Step [30/1250], Loss: 0.6891\n",
            "Epoch [5/30], Step [40/1250], Loss: 1.0322\n",
            "Epoch [5/30], Step [50/1250], Loss: 0.7899\n",
            "Epoch [5/30], Step [60/1250], Loss: 0.7112\n",
            "Epoch [5/30], Step [70/1250], Loss: 0.8962\n",
            "Epoch [5/30], Step [80/1250], Loss: 0.9310\n",
            "Epoch [5/30], Step [90/1250], Loss: 1.0430\n",
            "Epoch [5/30], Step [100/1250], Loss: 1.3639\n",
            "Epoch [5/30], Step [110/1250], Loss: 0.8571\n",
            "Epoch [5/30], Step [120/1250], Loss: 0.8610\n",
            "Epoch [5/30], Step [130/1250], Loss: 1.0651\n",
            "Epoch [5/30], Step [140/1250], Loss: 1.1719\n",
            "Epoch [5/30], Step [150/1250], Loss: 0.7022\n",
            "Epoch [5/30], Step [160/1250], Loss: 0.6977\n",
            "Epoch [5/30], Step [170/1250], Loss: 1.0403\n",
            "Epoch [5/30], Step [180/1250], Loss: 0.8547\n",
            "Epoch [5/30], Step [190/1250], Loss: 0.7513\n",
            "Epoch [5/30], Step [200/1250], Loss: 0.7577\n",
            "Epoch [5/30], Step [210/1250], Loss: 1.0533\n",
            "Epoch [5/30], Step [220/1250], Loss: 0.6830\n",
            "Epoch [5/30], Step [230/1250], Loss: 1.0080\n",
            "Epoch [5/30], Step [240/1250], Loss: 0.9055\n",
            "Epoch [5/30], Step [250/1250], Loss: 0.7248\n",
            "Epoch [5/30], Step [260/1250], Loss: 0.6079\n",
            "Epoch [5/30], Step [270/1250], Loss: 0.7236\n",
            "Epoch [5/30], Step [280/1250], Loss: 0.9174\n",
            "Epoch [5/30], Step [290/1250], Loss: 1.2410\n",
            "Epoch [5/30], Step [300/1250], Loss: 0.8720\n",
            "Epoch [5/30], Step [310/1250], Loss: 0.9691\n",
            "Epoch [5/30], Step [320/1250], Loss: 0.5819\n",
            "Epoch [5/30], Step [330/1250], Loss: 1.0929\n",
            "Epoch [5/30], Step [340/1250], Loss: 0.9156\n",
            "Epoch [5/30], Step [350/1250], Loss: 0.6109\n",
            "Epoch [5/30], Step [360/1250], Loss: 0.6936\n",
            "Epoch [5/30], Step [370/1250], Loss: 0.8190\n",
            "Epoch [5/30], Step [380/1250], Loss: 0.9762\n",
            "Epoch [5/30], Step [390/1250], Loss: 1.0526\n",
            "Epoch [5/30], Step [400/1250], Loss: 0.9752\n",
            "Epoch [5/30], Step [410/1250], Loss: 0.9419\n",
            "Epoch [5/30], Step [420/1250], Loss: 0.9464\n",
            "Epoch [5/30], Step [430/1250], Loss: 1.1866\n",
            "Epoch [5/30], Step [440/1250], Loss: 0.6037\n",
            "Epoch [5/30], Step [450/1250], Loss: 0.9435\n",
            "Epoch [5/30], Step [460/1250], Loss: 0.8007\n",
            "Epoch [5/30], Step [470/1250], Loss: 0.8920\n",
            "Epoch [5/30], Step [480/1250], Loss: 0.6772\n",
            "Epoch [5/30], Step [490/1250], Loss: 1.1253\n",
            "Epoch [5/30], Step [500/1250], Loss: 0.9526\n",
            "Epoch [5/30], Step [510/1250], Loss: 1.1772\n",
            "Epoch [5/30], Step [520/1250], Loss: 1.0295\n",
            "Epoch [5/30], Step [530/1250], Loss: 0.8581\n",
            "Epoch [5/30], Step [540/1250], Loss: 1.0962\n",
            "Epoch [5/30], Step [550/1250], Loss: 0.6584\n",
            "Epoch [5/30], Step [560/1250], Loss: 0.5362\n",
            "Epoch [5/30], Step [570/1250], Loss: 1.3505\n",
            "Epoch [5/30], Step [580/1250], Loss: 1.1708\n",
            "Epoch [5/30], Step [590/1250], Loss: 1.0237\n",
            "Epoch [5/30], Step [600/1250], Loss: 1.0748\n",
            "Epoch [5/30], Step [610/1250], Loss: 0.8815\n",
            "Epoch [5/30], Step [620/1250], Loss: 0.9837\n",
            "Epoch [5/30], Step [630/1250], Loss: 0.9665\n",
            "Epoch [5/30], Step [640/1250], Loss: 0.6267\n",
            "Epoch [5/30], Step [650/1250], Loss: 0.8992\n",
            "Epoch [5/30], Step [660/1250], Loss: 0.7585\n",
            "Epoch [5/30], Step [670/1250], Loss: 0.9286\n",
            "Epoch [5/30], Step [680/1250], Loss: 0.9351\n",
            "Epoch [5/30], Step [690/1250], Loss: 0.5199\n",
            "Epoch [5/30], Step [700/1250], Loss: 0.8707\n",
            "Epoch [5/30], Step [710/1250], Loss: 0.8046\n",
            "Epoch [5/30], Step [720/1250], Loss: 0.6734\n",
            "Epoch [5/30], Step [730/1250], Loss: 0.9339\n",
            "Epoch [5/30], Step [740/1250], Loss: 0.6514\n",
            "Epoch [5/30], Step [750/1250], Loss: 0.6298\n",
            "Epoch [5/30], Step [760/1250], Loss: 1.0775\n",
            "Epoch [5/30], Step [770/1250], Loss: 0.9120\n",
            "Epoch [5/30], Step [780/1250], Loss: 0.6615\n",
            "Epoch [5/30], Step [790/1250], Loss: 0.7852\n",
            "Epoch [5/30], Step [800/1250], Loss: 0.6753\n",
            "Epoch [5/30], Step [810/1250], Loss: 0.7937\n",
            "Epoch [5/30], Step [820/1250], Loss: 0.7499\n",
            "Epoch [5/30], Step [830/1250], Loss: 0.7060\n",
            "Epoch [5/30], Step [840/1250], Loss: 0.4335\n",
            "Epoch [5/30], Step [850/1250], Loss: 0.7911\n",
            "Epoch [5/30], Step [860/1250], Loss: 0.8199\n",
            "Epoch [5/30], Step [870/1250], Loss: 0.9259\n",
            "Epoch [5/30], Step [880/1250], Loss: 0.8330\n",
            "Epoch [5/30], Step [890/1250], Loss: 0.7332\n",
            "Epoch [5/30], Step [900/1250], Loss: 1.0135\n",
            "Epoch [5/30], Step [910/1250], Loss: 1.1408\n",
            "Epoch [5/30], Step [920/1250], Loss: 0.8273\n",
            "Epoch [5/30], Step [930/1250], Loss: 0.9365\n",
            "Epoch [5/30], Step [940/1250], Loss: 0.7936\n",
            "Epoch [5/30], Step [950/1250], Loss: 0.9163\n",
            "Epoch [5/30], Step [960/1250], Loss: 0.9304\n",
            "Epoch [5/30], Step [970/1250], Loss: 0.8853\n",
            "Epoch [5/30], Step [980/1250], Loss: 0.8801\n",
            "Epoch [5/30], Step [990/1250], Loss: 0.8810\n",
            "Epoch [5/30], Step [1000/1250], Loss: 0.8474\n",
            "Epoch [5/30], Step [1010/1250], Loss: 0.9899\n",
            "Epoch [5/30], Step [1020/1250], Loss: 0.5822\n",
            "Epoch [5/30], Step [1030/1250], Loss: 0.8016\n",
            "Epoch [5/30], Step [1040/1250], Loss: 0.6060\n",
            "Epoch [5/30], Step [1050/1250], Loss: 1.0523\n",
            "Epoch [5/30], Step [1060/1250], Loss: 1.0366\n",
            "Epoch [5/30], Step [1070/1250], Loss: 0.9799\n",
            "Epoch [5/30], Step [1080/1250], Loss: 0.7121\n",
            "Epoch [5/30], Step [1090/1250], Loss: 0.7171\n",
            "Epoch [5/30], Step [1100/1250], Loss: 0.7593\n",
            "Epoch [5/30], Step [1110/1250], Loss: 0.9528\n",
            "Epoch [5/30], Step [1120/1250], Loss: 0.8217\n",
            "Epoch [5/30], Step [1130/1250], Loss: 0.7582\n",
            "Epoch [5/30], Step [1140/1250], Loss: 0.4965\n",
            "Epoch [5/30], Step [1150/1250], Loss: 0.5997\n",
            "Epoch [5/30], Step [1160/1250], Loss: 1.0504\n",
            "Epoch [5/30], Step [1170/1250], Loss: 0.8644\n",
            "Epoch [5/30], Step [1180/1250], Loss: 0.5812\n",
            "Epoch [5/30], Step [1190/1250], Loss: 1.0897\n",
            "Epoch [5/30], Step [1200/1250], Loss: 0.5708\n",
            "Epoch [5/30], Step [1210/1250], Loss: 0.8847\n",
            "Epoch [5/30], Step [1220/1250], Loss: 1.0501\n",
            "Epoch [5/30], Step [1230/1250], Loss: 0.7108\n",
            "Epoch [5/30], Step [1240/1250], Loss: 0.6490\n",
            "Epoch [5/30], Step [1250/1250], Loss: 0.7600\n",
            "Epoch [6/30], Step [10/1250], Loss: 0.6693\n",
            "Epoch [6/30], Step [20/1250], Loss: 0.4400\n",
            "Epoch [6/30], Step [30/1250], Loss: 0.7133\n",
            "Epoch [6/30], Step [40/1250], Loss: 0.5117\n",
            "Epoch [6/30], Step [50/1250], Loss: 0.6682\n",
            "Epoch [6/30], Step [60/1250], Loss: 0.8433\n",
            "Epoch [6/30], Step [70/1250], Loss: 1.1395\n",
            "Epoch [6/30], Step [80/1250], Loss: 0.6239\n",
            "Epoch [6/30], Step [90/1250], Loss: 0.7266\n",
            "Epoch [6/30], Step [100/1250], Loss: 1.0589\n",
            "Epoch [6/30], Step [110/1250], Loss: 0.5984\n",
            "Epoch [6/30], Step [120/1250], Loss: 0.7762\n",
            "Epoch [6/30], Step [130/1250], Loss: 0.7375\n",
            "Epoch [6/30], Step [140/1250], Loss: 0.7953\n",
            "Epoch [6/30], Step [150/1250], Loss: 0.7184\n",
            "Epoch [6/30], Step [160/1250], Loss: 0.7393\n",
            "Epoch [6/30], Step [170/1250], Loss: 0.7102\n",
            "Epoch [6/30], Step [180/1250], Loss: 0.7536\n",
            "Epoch [6/30], Step [190/1250], Loss: 0.9207\n",
            "Epoch [6/30], Step [200/1250], Loss: 0.7296\n",
            "Epoch [6/30], Step [210/1250], Loss: 0.6556\n",
            "Epoch [6/30], Step [220/1250], Loss: 0.8797\n",
            "Epoch [6/30], Step [230/1250], Loss: 0.6876\n",
            "Epoch [6/30], Step [240/1250], Loss: 0.7153\n",
            "Epoch [6/30], Step [250/1250], Loss: 0.9648\n",
            "Epoch [6/30], Step [260/1250], Loss: 0.4596\n",
            "Epoch [6/30], Step [270/1250], Loss: 0.5375\n",
            "Epoch [6/30], Step [280/1250], Loss: 0.6988\n",
            "Epoch [6/30], Step [290/1250], Loss: 0.6836\n",
            "Epoch [6/30], Step [300/1250], Loss: 0.7479\n",
            "Epoch [6/30], Step [310/1250], Loss: 0.7735\n",
            "Epoch [6/30], Step [320/1250], Loss: 0.9702\n",
            "Epoch [6/30], Step [330/1250], Loss: 0.8730\n",
            "Epoch [6/30], Step [340/1250], Loss: 0.6832\n",
            "Epoch [6/30], Step [350/1250], Loss: 0.4244\n",
            "Epoch [6/30], Step [360/1250], Loss: 0.7379\n",
            "Epoch [6/30], Step [370/1250], Loss: 0.9728\n",
            "Epoch [6/30], Step [380/1250], Loss: 0.7345\n",
            "Epoch [6/30], Step [390/1250], Loss: 0.8426\n",
            "Epoch [6/30], Step [400/1250], Loss: 0.7095\n",
            "Epoch [6/30], Step [410/1250], Loss: 0.7498\n",
            "Epoch [6/30], Step [420/1250], Loss: 0.6891\n",
            "Epoch [6/30], Step [430/1250], Loss: 0.5992\n",
            "Epoch [6/30], Step [440/1250], Loss: 0.6718\n",
            "Epoch [6/30], Step [450/1250], Loss: 1.1475\n",
            "Epoch [6/30], Step [460/1250], Loss: 0.5159\n",
            "Epoch [6/30], Step [470/1250], Loss: 0.9150\n",
            "Epoch [6/30], Step [480/1250], Loss: 0.8194\n",
            "Epoch [6/30], Step [490/1250], Loss: 0.6629\n",
            "Epoch [6/30], Step [500/1250], Loss: 0.7757\n",
            "Epoch [6/30], Step [510/1250], Loss: 1.0156\n",
            "Epoch [6/30], Step [520/1250], Loss: 0.6720\n",
            "Epoch [6/30], Step [530/1250], Loss: 0.8297\n",
            "Epoch [6/30], Step [540/1250], Loss: 0.6932\n",
            "Epoch [6/30], Step [550/1250], Loss: 0.6264\n",
            "Epoch [6/30], Step [560/1250], Loss: 0.7357\n",
            "Epoch [6/30], Step [570/1250], Loss: 0.9178\n",
            "Epoch [6/30], Step [580/1250], Loss: 0.8105\n",
            "Epoch [6/30], Step [590/1250], Loss: 0.6901\n",
            "Epoch [6/30], Step [600/1250], Loss: 0.7090\n",
            "Epoch [6/30], Step [610/1250], Loss: 0.8783\n",
            "Epoch [6/30], Step [620/1250], Loss: 0.7684\n",
            "Epoch [6/30], Step [630/1250], Loss: 0.8208\n",
            "Epoch [6/30], Step [640/1250], Loss: 0.3593\n",
            "Epoch [6/30], Step [650/1250], Loss: 0.7129\n",
            "Epoch [6/30], Step [660/1250], Loss: 0.7791\n",
            "Epoch [6/30], Step [670/1250], Loss: 0.7914\n",
            "Epoch [6/30], Step [680/1250], Loss: 0.6057\n",
            "Epoch [6/30], Step [690/1250], Loss: 1.0249\n",
            "Epoch [6/30], Step [700/1250], Loss: 0.7324\n",
            "Epoch [6/30], Step [710/1250], Loss: 1.0575\n",
            "Epoch [6/30], Step [720/1250], Loss: 0.6873\n",
            "Epoch [6/30], Step [730/1250], Loss: 0.6314\n",
            "Epoch [6/30], Step [740/1250], Loss: 0.7493\n",
            "Epoch [6/30], Step [750/1250], Loss: 0.8321\n",
            "Epoch [6/30], Step [760/1250], Loss: 0.7557\n",
            "Epoch [6/30], Step [770/1250], Loss: 0.6692\n",
            "Epoch [6/30], Step [780/1250], Loss: 0.8554\n",
            "Epoch [6/30], Step [790/1250], Loss: 0.7553\n",
            "Epoch [6/30], Step [800/1250], Loss: 0.7591\n",
            "Epoch [6/30], Step [810/1250], Loss: 0.5699\n",
            "Epoch [6/30], Step [820/1250], Loss: 0.5579\n",
            "Epoch [6/30], Step [830/1250], Loss: 0.6006\n",
            "Epoch [6/30], Step [840/1250], Loss: 0.9342\n",
            "Epoch [6/30], Step [850/1250], Loss: 0.7134\n",
            "Epoch [6/30], Step [860/1250], Loss: 0.7110\n",
            "Epoch [6/30], Step [870/1250], Loss: 0.7762\n",
            "Epoch [6/30], Step [880/1250], Loss: 0.5849\n",
            "Epoch [6/30], Step [890/1250], Loss: 0.4650\n",
            "Epoch [6/30], Step [900/1250], Loss: 1.0827\n",
            "Epoch [6/30], Step [910/1250], Loss: 0.7338\n",
            "Epoch [6/30], Step [920/1250], Loss: 0.8465\n",
            "Epoch [6/30], Step [930/1250], Loss: 0.9112\n",
            "Epoch [6/30], Step [940/1250], Loss: 0.8120\n",
            "Epoch [6/30], Step [950/1250], Loss: 0.8959\n",
            "Epoch [6/30], Step [960/1250], Loss: 0.5457\n",
            "Epoch [6/30], Step [970/1250], Loss: 0.9698\n",
            "Epoch [6/30], Step [980/1250], Loss: 0.6102\n",
            "Epoch [6/30], Step [990/1250], Loss: 0.7947\n",
            "Epoch [6/30], Step [1000/1250], Loss: 0.5398\n",
            "Epoch [6/30], Step [1010/1250], Loss: 0.6894\n",
            "Epoch [6/30], Step [1020/1250], Loss: 0.7344\n",
            "Epoch [6/30], Step [1030/1250], Loss: 0.6269\n",
            "Epoch [6/30], Step [1040/1250], Loss: 0.7123\n",
            "Epoch [6/30], Step [1050/1250], Loss: 0.8322\n",
            "Epoch [6/30], Step [1060/1250], Loss: 1.0321\n",
            "Epoch [6/30], Step [1070/1250], Loss: 0.6148\n",
            "Epoch [6/30], Step [1080/1250], Loss: 0.5667\n",
            "Epoch [6/30], Step [1090/1250], Loss: 0.7373\n",
            "Epoch [6/30], Step [1100/1250], Loss: 0.9140\n",
            "Epoch [6/30], Step [1110/1250], Loss: 0.7182\n",
            "Epoch [6/30], Step [1120/1250], Loss: 0.7930\n",
            "Epoch [6/30], Step [1130/1250], Loss: 0.8880\n",
            "Epoch [6/30], Step [1140/1250], Loss: 0.8979\n",
            "Epoch [6/30], Step [1150/1250], Loss: 0.8424\n",
            "Epoch [6/30], Step [1160/1250], Loss: 0.9186\n",
            "Epoch [6/30], Step [1170/1250], Loss: 0.8177\n",
            "Epoch [6/30], Step [1180/1250], Loss: 0.5707\n",
            "Epoch [6/30], Step [1190/1250], Loss: 0.6364\n",
            "Epoch [6/30], Step [1200/1250], Loss: 0.6984\n",
            "Epoch [6/30], Step [1210/1250], Loss: 0.5057\n",
            "Epoch [6/30], Step [1220/1250], Loss: 0.7064\n",
            "Epoch [6/30], Step [1230/1250], Loss: 0.8049\n",
            "Epoch [6/30], Step [1240/1250], Loss: 0.6145\n",
            "Epoch [6/30], Step [1250/1250], Loss: 0.5318\n",
            "Epoch [7/30], Step [10/1250], Loss: 0.6339\n",
            "Epoch [7/30], Step [20/1250], Loss: 0.6937\n",
            "Epoch [7/30], Step [30/1250], Loss: 0.5494\n",
            "Epoch [7/30], Step [40/1250], Loss: 0.5465\n",
            "Epoch [7/30], Step [50/1250], Loss: 0.3697\n",
            "Epoch [7/30], Step [60/1250], Loss: 0.5944\n",
            "Epoch [7/30], Step [70/1250], Loss: 0.3989\n",
            "Epoch [7/30], Step [80/1250], Loss: 0.8420\n",
            "Epoch [7/30], Step [90/1250], Loss: 0.8585\n",
            "Epoch [7/30], Step [100/1250], Loss: 0.3775\n",
            "Epoch [7/30], Step [110/1250], Loss: 0.8713\n",
            "Epoch [7/30], Step [120/1250], Loss: 0.5704\n",
            "Epoch [7/30], Step [130/1250], Loss: 0.6116\n",
            "Epoch [7/30], Step [140/1250], Loss: 0.4510\n",
            "Epoch [7/30], Step [150/1250], Loss: 0.6222\n",
            "Epoch [7/30], Step [160/1250], Loss: 0.4157\n",
            "Epoch [7/30], Step [170/1250], Loss: 0.5815\n",
            "Epoch [7/30], Step [180/1250], Loss: 0.4304\n",
            "Epoch [7/30], Step [190/1250], Loss: 0.6065\n",
            "Epoch [7/30], Step [200/1250], Loss: 1.0068\n",
            "Epoch [7/30], Step [210/1250], Loss: 0.5366\n",
            "Epoch [7/30], Step [220/1250], Loss: 0.4766\n",
            "Epoch [7/30], Step [230/1250], Loss: 0.5400\n",
            "Epoch [7/30], Step [240/1250], Loss: 0.4996\n",
            "Epoch [7/30], Step [250/1250], Loss: 0.6797\n",
            "Epoch [7/30], Step [260/1250], Loss: 0.5623\n",
            "Epoch [7/30], Step [270/1250], Loss: 0.6709\n",
            "Epoch [7/30], Step [280/1250], Loss: 0.7995\n",
            "Epoch [7/30], Step [290/1250], Loss: 0.5901\n",
            "Epoch [7/30], Step [300/1250], Loss: 0.8814\n",
            "Epoch [7/30], Step [310/1250], Loss: 0.5102\n",
            "Epoch [7/30], Step [320/1250], Loss: 0.9195\n",
            "Epoch [7/30], Step [330/1250], Loss: 0.5470\n",
            "Epoch [7/30], Step [340/1250], Loss: 0.4092\n",
            "Epoch [7/30], Step [350/1250], Loss: 0.5143\n",
            "Epoch [7/30], Step [360/1250], Loss: 0.4739\n",
            "Epoch [7/30], Step [370/1250], Loss: 0.5594\n",
            "Epoch [7/30], Step [380/1250], Loss: 0.7907\n",
            "Epoch [7/30], Step [390/1250], Loss: 0.6560\n",
            "Epoch [7/30], Step [400/1250], Loss: 0.5452\n",
            "Epoch [7/30], Step [410/1250], Loss: 0.7333\n",
            "Epoch [7/30], Step [420/1250], Loss: 0.5471\n",
            "Epoch [7/30], Step [430/1250], Loss: 0.5196\n",
            "Epoch [7/30], Step [440/1250], Loss: 0.6048\n",
            "Epoch [7/30], Step [450/1250], Loss: 0.4075\n",
            "Epoch [7/30], Step [460/1250], Loss: 0.6003\n",
            "Epoch [7/30], Step [470/1250], Loss: 0.9254\n",
            "Epoch [7/30], Step [480/1250], Loss: 0.7250\n",
            "Epoch [7/30], Step [490/1250], Loss: 0.5257\n",
            "Epoch [7/30], Step [500/1250], Loss: 0.4430\n",
            "Epoch [7/30], Step [510/1250], Loss: 0.6515\n",
            "Epoch [7/30], Step [520/1250], Loss: 0.4356\n",
            "Epoch [7/30], Step [530/1250], Loss: 0.6505\n",
            "Epoch [7/30], Step [540/1250], Loss: 0.6867\n",
            "Epoch [7/30], Step [550/1250], Loss: 0.5633\n",
            "Epoch [7/30], Step [560/1250], Loss: 0.7467\n",
            "Epoch [7/30], Step [570/1250], Loss: 0.6741\n",
            "Epoch [7/30], Step [580/1250], Loss: 0.8153\n",
            "Epoch [7/30], Step [590/1250], Loss: 0.6992\n",
            "Epoch [7/30], Step [600/1250], Loss: 0.6444\n",
            "Epoch [7/30], Step [610/1250], Loss: 0.4869\n",
            "Epoch [7/30], Step [620/1250], Loss: 0.4868\n",
            "Epoch [7/30], Step [630/1250], Loss: 0.4088\n",
            "Epoch [7/30], Step [640/1250], Loss: 0.8014\n",
            "Epoch [7/30], Step [650/1250], Loss: 0.5085\n",
            "Epoch [7/30], Step [660/1250], Loss: 0.5599\n",
            "Epoch [7/30], Step [670/1250], Loss: 0.6662\n",
            "Epoch [7/30], Step [680/1250], Loss: 0.6220\n",
            "Epoch [7/30], Step [690/1250], Loss: 0.7223\n",
            "Epoch [7/30], Step [700/1250], Loss: 0.4653\n",
            "Epoch [7/30], Step [710/1250], Loss: 0.6444\n",
            "Epoch [7/30], Step [720/1250], Loss: 0.5066\n",
            "Epoch [7/30], Step [730/1250], Loss: 0.7282\n",
            "Epoch [7/30], Step [740/1250], Loss: 0.4076\n",
            "Epoch [7/30], Step [750/1250], Loss: 0.6337\n",
            "Epoch [7/30], Step [760/1250], Loss: 0.6628\n",
            "Epoch [7/30], Step [770/1250], Loss: 0.5609\n",
            "Epoch [7/30], Step [780/1250], Loss: 0.8922\n",
            "Epoch [7/30], Step [790/1250], Loss: 0.3033\n",
            "Epoch [7/30], Step [800/1250], Loss: 0.7312\n",
            "Epoch [7/30], Step [810/1250], Loss: 0.7527\n",
            "Epoch [7/30], Step [820/1250], Loss: 1.0131\n",
            "Epoch [7/30], Step [830/1250], Loss: 0.6022\n",
            "Epoch [7/30], Step [840/1250], Loss: 0.9275\n",
            "Epoch [7/30], Step [850/1250], Loss: 0.6727\n",
            "Epoch [7/30], Step [860/1250], Loss: 0.9191\n",
            "Epoch [7/30], Step [870/1250], Loss: 0.5053\n",
            "Epoch [7/30], Step [880/1250], Loss: 0.8194\n",
            "Epoch [7/30], Step [890/1250], Loss: 0.5668\n",
            "Epoch [7/30], Step [900/1250], Loss: 1.0008\n",
            "Epoch [7/30], Step [910/1250], Loss: 0.6243\n",
            "Epoch [7/30], Step [920/1250], Loss: 0.9544\n",
            "Epoch [7/30], Step [930/1250], Loss: 0.6044\n",
            "Epoch [7/30], Step [940/1250], Loss: 0.6937\n",
            "Epoch [7/30], Step [950/1250], Loss: 0.8852\n",
            "Epoch [7/30], Step [960/1250], Loss: 0.5189\n",
            "Epoch [7/30], Step [970/1250], Loss: 0.7084\n",
            "Epoch [7/30], Step [980/1250], Loss: 0.4877\n",
            "Epoch [7/30], Step [990/1250], Loss: 0.5558\n",
            "Epoch [7/30], Step [1000/1250], Loss: 0.7471\n",
            "Epoch [7/30], Step [1010/1250], Loss: 0.2885\n",
            "Epoch [7/30], Step [1020/1250], Loss: 0.6815\n",
            "Epoch [7/30], Step [1030/1250], Loss: 0.7273\n",
            "Epoch [7/30], Step [1040/1250], Loss: 0.5593\n",
            "Epoch [7/30], Step [1050/1250], Loss: 0.3061\n",
            "Epoch [7/30], Step [1060/1250], Loss: 0.6140\n",
            "Epoch [7/30], Step [1070/1250], Loss: 0.6287\n",
            "Epoch [7/30], Step [1080/1250], Loss: 0.4703\n",
            "Epoch [7/30], Step [1090/1250], Loss: 0.5800\n",
            "Epoch [7/30], Step [1100/1250], Loss: 0.4449\n",
            "Epoch [7/30], Step [1110/1250], Loss: 0.5753\n",
            "Epoch [7/30], Step [1120/1250], Loss: 0.6004\n",
            "Epoch [7/30], Step [1130/1250], Loss: 0.8487\n",
            "Epoch [7/30], Step [1140/1250], Loss: 0.6422\n",
            "Epoch [7/30], Step [1150/1250], Loss: 0.9113\n",
            "Epoch [7/30], Step [1160/1250], Loss: 0.3693\n",
            "Epoch [7/30], Step [1170/1250], Loss: 0.9536\n",
            "Epoch [7/30], Step [1180/1250], Loss: 0.6538\n",
            "Epoch [7/30], Step [1190/1250], Loss: 0.5121\n",
            "Epoch [7/30], Step [1200/1250], Loss: 0.5390\n",
            "Epoch [7/30], Step [1210/1250], Loss: 0.9689\n",
            "Epoch [7/30], Step [1220/1250], Loss: 0.5328\n",
            "Epoch [7/30], Step [1230/1250], Loss: 0.5058\n",
            "Epoch [7/30], Step [1240/1250], Loss: 0.9023\n",
            "Epoch [7/30], Step [1250/1250], Loss: 0.5481\n",
            "Epoch [8/30], Step [10/1250], Loss: 0.9414\n",
            "Epoch [8/30], Step [20/1250], Loss: 0.5793\n",
            "Epoch [8/30], Step [30/1250], Loss: 0.7829\n",
            "Epoch [8/30], Step [40/1250], Loss: 0.6738\n",
            "Epoch [8/30], Step [50/1250], Loss: 0.3497\n",
            "Epoch [8/30], Step [60/1250], Loss: 0.4863\n",
            "Epoch [8/30], Step [70/1250], Loss: 0.7183\n",
            "Epoch [8/30], Step [80/1250], Loss: 0.3613\n",
            "Epoch [8/30], Step [90/1250], Loss: 0.7034\n",
            "Epoch [8/30], Step [100/1250], Loss: 0.5477\n",
            "Epoch [8/30], Step [110/1250], Loss: 0.6282\n",
            "Epoch [8/30], Step [120/1250], Loss: 0.3241\n",
            "Epoch [8/30], Step [130/1250], Loss: 0.5592\n",
            "Epoch [8/30], Step [140/1250], Loss: 0.5401\n",
            "Epoch [8/30], Step [150/1250], Loss: 0.7452\n",
            "Epoch [8/30], Step [160/1250], Loss: 0.2242\n",
            "Epoch [8/30], Step [170/1250], Loss: 0.4300\n",
            "Epoch [8/30], Step [180/1250], Loss: 0.5549\n",
            "Epoch [8/30], Step [190/1250], Loss: 0.7926\n",
            "Epoch [8/30], Step [200/1250], Loss: 0.5352\n",
            "Epoch [8/30], Step [210/1250], Loss: 0.6611\n",
            "Epoch [8/30], Step [220/1250], Loss: 0.7506\n",
            "Epoch [8/30], Step [230/1250], Loss: 0.4271\n",
            "Epoch [8/30], Step [240/1250], Loss: 0.5456\n",
            "Epoch [8/30], Step [250/1250], Loss: 0.5496\n",
            "Epoch [8/30], Step [260/1250], Loss: 0.7770\n",
            "Epoch [8/30], Step [270/1250], Loss: 0.6032\n",
            "Epoch [8/30], Step [280/1250], Loss: 0.4014\n",
            "Epoch [8/30], Step [290/1250], Loss: 0.8242\n",
            "Epoch [8/30], Step [300/1250], Loss: 0.5028\n",
            "Epoch [8/30], Step [310/1250], Loss: 0.5079\n",
            "Epoch [8/30], Step [320/1250], Loss: 0.5053\n",
            "Epoch [8/30], Step [330/1250], Loss: 0.6086\n",
            "Epoch [8/30], Step [340/1250], Loss: 0.4437\n",
            "Epoch [8/30], Step [350/1250], Loss: 0.4428\n",
            "Epoch [8/30], Step [360/1250], Loss: 0.4452\n",
            "Epoch [8/30], Step [370/1250], Loss: 0.7125\n",
            "Epoch [8/30], Step [380/1250], Loss: 0.4137\n",
            "Epoch [8/30], Step [390/1250], Loss: 0.7327\n",
            "Epoch [8/30], Step [400/1250], Loss: 0.6274\n",
            "Epoch [8/30], Step [410/1250], Loss: 1.1842\n",
            "Epoch [8/30], Step [420/1250], Loss: 0.5425\n",
            "Epoch [8/30], Step [430/1250], Loss: 0.5640\n",
            "Epoch [8/30], Step [440/1250], Loss: 0.7456\n",
            "Epoch [8/30], Step [450/1250], Loss: 0.8139\n",
            "Epoch [8/30], Step [460/1250], Loss: 0.5066\n",
            "Epoch [8/30], Step [470/1250], Loss: 0.5094\n",
            "Epoch [8/30], Step [480/1250], Loss: 0.4511\n",
            "Epoch [8/30], Step [490/1250], Loss: 0.5484\n",
            "Epoch [8/30], Step [500/1250], Loss: 0.6704\n",
            "Epoch [8/30], Step [510/1250], Loss: 0.6078\n",
            "Epoch [8/30], Step [520/1250], Loss: 0.7485\n",
            "Epoch [8/30], Step [530/1250], Loss: 0.2018\n",
            "Epoch [8/30], Step [540/1250], Loss: 0.6206\n",
            "Epoch [8/30], Step [550/1250], Loss: 0.9832\n",
            "Epoch [8/30], Step [560/1250], Loss: 0.4936\n",
            "Epoch [8/30], Step [570/1250], Loss: 0.5010\n",
            "Epoch [8/30], Step [580/1250], Loss: 0.8354\n",
            "Epoch [8/30], Step [590/1250], Loss: 0.5141\n",
            "Epoch [8/30], Step [600/1250], Loss: 0.5770\n",
            "Epoch [8/30], Step [610/1250], Loss: 0.6069\n",
            "Epoch [8/30], Step [620/1250], Loss: 0.4790\n",
            "Epoch [8/30], Step [630/1250], Loss: 0.6507\n",
            "Epoch [8/30], Step [640/1250], Loss: 0.8326\n",
            "Epoch [8/30], Step [650/1250], Loss: 0.8658\n",
            "Epoch [8/30], Step [660/1250], Loss: 0.3798\n",
            "Epoch [8/30], Step [670/1250], Loss: 0.6188\n",
            "Epoch [8/30], Step [680/1250], Loss: 0.7438\n",
            "Epoch [8/30], Step [690/1250], Loss: 0.4277\n",
            "Epoch [8/30], Step [700/1250], Loss: 0.7255\n",
            "Epoch [8/30], Step [710/1250], Loss: 0.6648\n",
            "Epoch [8/30], Step [720/1250], Loss: 0.4608\n",
            "Epoch [8/30], Step [730/1250], Loss: 0.6233\n",
            "Epoch [8/30], Step [740/1250], Loss: 0.5990\n",
            "Epoch [8/30], Step [750/1250], Loss: 0.3127\n",
            "Epoch [8/30], Step [760/1250], Loss: 0.4925\n",
            "Epoch [8/30], Step [770/1250], Loss: 0.6076\n",
            "Epoch [8/30], Step [780/1250], Loss: 0.4011\n",
            "Epoch [8/30], Step [790/1250], Loss: 0.7980\n",
            "Epoch [8/30], Step [800/1250], Loss: 0.4692\n",
            "Epoch [8/30], Step [810/1250], Loss: 0.5456\n",
            "Epoch [8/30], Step [820/1250], Loss: 0.6642\n",
            "Epoch [8/30], Step [830/1250], Loss: 0.4773\n",
            "Epoch [8/30], Step [840/1250], Loss: 0.4829\n",
            "Epoch [8/30], Step [850/1250], Loss: 0.3460\n",
            "Epoch [8/30], Step [860/1250], Loss: 0.5858\n",
            "Epoch [8/30], Step [870/1250], Loss: 0.4820\n",
            "Epoch [8/30], Step [880/1250], Loss: 0.6394\n",
            "Epoch [8/30], Step [890/1250], Loss: 0.6477\n",
            "Epoch [8/30], Step [900/1250], Loss: 0.4073\n",
            "Epoch [8/30], Step [910/1250], Loss: 0.8522\n",
            "Epoch [8/30], Step [920/1250], Loss: 0.6569\n",
            "Epoch [8/30], Step [930/1250], Loss: 0.4111\n",
            "Epoch [8/30], Step [940/1250], Loss: 0.6550\n",
            "Epoch [8/30], Step [950/1250], Loss: 0.3191\n",
            "Epoch [8/30], Step [960/1250], Loss: 0.6361\n",
            "Epoch [8/30], Step [970/1250], Loss: 0.5546\n",
            "Epoch [8/30], Step [980/1250], Loss: 0.5126\n",
            "Epoch [8/30], Step [990/1250], Loss: 0.6345\n",
            "Epoch [8/30], Step [1000/1250], Loss: 0.3975\n",
            "Epoch [8/30], Step [1010/1250], Loss: 0.7193\n",
            "Epoch [8/30], Step [1020/1250], Loss: 0.4194\n",
            "Epoch [8/30], Step [1030/1250], Loss: 0.4563\n",
            "Epoch [8/30], Step [1040/1250], Loss: 0.7746\n",
            "Epoch [8/30], Step [1050/1250], Loss: 0.6551\n",
            "Epoch [8/30], Step [1060/1250], Loss: 0.4182\n",
            "Epoch [8/30], Step [1070/1250], Loss: 0.5727\n",
            "Epoch [8/30], Step [1080/1250], Loss: 0.4701\n",
            "Epoch [8/30], Step [1090/1250], Loss: 0.7133\n",
            "Epoch [8/30], Step [1100/1250], Loss: 0.8257\n",
            "Epoch [8/30], Step [1110/1250], Loss: 0.6054\n",
            "Epoch [8/30], Step [1120/1250], Loss: 0.5071\n",
            "Epoch [8/30], Step [1130/1250], Loss: 0.8608\n",
            "Epoch [8/30], Step [1140/1250], Loss: 0.4904\n",
            "Epoch [8/30], Step [1150/1250], Loss: 0.6772\n",
            "Epoch [8/30], Step [1160/1250], Loss: 0.6262\n",
            "Epoch [8/30], Step [1170/1250], Loss: 0.5327\n",
            "Epoch [8/30], Step [1180/1250], Loss: 0.7418\n",
            "Epoch [8/30], Step [1190/1250], Loss: 0.5757\n",
            "Epoch [8/30], Step [1200/1250], Loss: 0.4454\n",
            "Epoch [8/30], Step [1210/1250], Loss: 0.2613\n",
            "Epoch [8/30], Step [1220/1250], Loss: 0.6375\n",
            "Epoch [8/30], Step [1230/1250], Loss: 0.6808\n",
            "Epoch [8/30], Step [1240/1250], Loss: 0.4531\n",
            "Epoch [8/30], Step [1250/1250], Loss: 0.3307\n",
            "Epoch [9/30], Step [10/1250], Loss: 0.4337\n",
            "Epoch [9/30], Step [20/1250], Loss: 0.5065\n",
            "Epoch [9/30], Step [30/1250], Loss: 0.4145\n",
            "Epoch [9/30], Step [40/1250], Loss: 0.4083\n",
            "Epoch [9/30], Step [50/1250], Loss: 0.4714\n",
            "Epoch [9/30], Step [60/1250], Loss: 0.4553\n",
            "Epoch [9/30], Step [70/1250], Loss: 0.3495\n",
            "Epoch [9/30], Step [80/1250], Loss: 0.1538\n",
            "Epoch [9/30], Step [90/1250], Loss: 0.5081\n",
            "Epoch [9/30], Step [100/1250], Loss: 0.3693\n",
            "Epoch [9/30], Step [110/1250], Loss: 0.3581\n",
            "Epoch [9/30], Step [120/1250], Loss: 0.4631\n",
            "Epoch [9/30], Step [130/1250], Loss: 0.5591\n",
            "Epoch [9/30], Step [140/1250], Loss: 0.3199\n",
            "Epoch [9/30], Step [150/1250], Loss: 0.6552\n",
            "Epoch [9/30], Step [160/1250], Loss: 0.3512\n",
            "Epoch [9/30], Step [170/1250], Loss: 0.6508\n",
            "Epoch [9/30], Step [180/1250], Loss: 0.4202\n",
            "Epoch [9/30], Step [190/1250], Loss: 0.6514\n",
            "Epoch [9/30], Step [200/1250], Loss: 0.5359\n",
            "Epoch [9/30], Step [210/1250], Loss: 0.5224\n",
            "Epoch [9/30], Step [220/1250], Loss: 0.4510\n",
            "Epoch [9/30], Step [230/1250], Loss: 0.4931\n",
            "Epoch [9/30], Step [240/1250], Loss: 0.3940\n",
            "Epoch [9/30], Step [250/1250], Loss: 0.5942\n",
            "Epoch [9/30], Step [260/1250], Loss: 0.2838\n",
            "Epoch [9/30], Step [270/1250], Loss: 0.5123\n",
            "Epoch [9/30], Step [280/1250], Loss: 0.6659\n",
            "Epoch [9/30], Step [290/1250], Loss: 0.4135\n",
            "Epoch [9/30], Step [300/1250], Loss: 0.3187\n",
            "Epoch [9/30], Step [310/1250], Loss: 0.5759\n",
            "Epoch [9/30], Step [320/1250], Loss: 0.3012\n",
            "Epoch [9/30], Step [330/1250], Loss: 0.4392\n",
            "Epoch [9/30], Step [340/1250], Loss: 0.2797\n",
            "Epoch [9/30], Step [350/1250], Loss: 0.3135\n",
            "Epoch [9/30], Step [360/1250], Loss: 0.3622\n",
            "Epoch [9/30], Step [370/1250], Loss: 0.2046\n",
            "Epoch [9/30], Step [380/1250], Loss: 0.5952\n",
            "Epoch [9/30], Step [390/1250], Loss: 0.5411\n",
            "Epoch [9/30], Step [400/1250], Loss: 0.6132\n",
            "Epoch [9/30], Step [410/1250], Loss: 0.2887\n",
            "Epoch [9/30], Step [420/1250], Loss: 0.4437\n",
            "Epoch [9/30], Step [430/1250], Loss: 0.6835\n",
            "Epoch [9/30], Step [440/1250], Loss: 0.4526\n",
            "Epoch [9/30], Step [450/1250], Loss: 0.3435\n",
            "Epoch [9/30], Step [460/1250], Loss: 0.2693\n",
            "Epoch [9/30], Step [470/1250], Loss: 0.5354\n",
            "Epoch [9/30], Step [480/1250], Loss: 0.2726\n",
            "Epoch [9/30], Step [490/1250], Loss: 0.3695\n",
            "Epoch [9/30], Step [500/1250], Loss: 0.3841\n",
            "Epoch [9/30], Step [510/1250], Loss: 0.6666\n",
            "Epoch [9/30], Step [520/1250], Loss: 0.4974\n",
            "Epoch [9/30], Step [530/1250], Loss: 0.6745\n",
            "Epoch [9/30], Step [540/1250], Loss: 0.3774\n",
            "Epoch [9/30], Step [550/1250], Loss: 0.3568\n",
            "Epoch [9/30], Step [560/1250], Loss: 0.3882\n",
            "Epoch [9/30], Step [570/1250], Loss: 0.3448\n",
            "Epoch [9/30], Step [580/1250], Loss: 0.4489\n",
            "Epoch [9/30], Step [590/1250], Loss: 0.3703\n",
            "Epoch [9/30], Step [600/1250], Loss: 0.2881\n",
            "Epoch [9/30], Step [610/1250], Loss: 0.7484\n",
            "Epoch [9/30], Step [620/1250], Loss: 0.3532\n",
            "Epoch [9/30], Step [630/1250], Loss: 0.3381\n",
            "Epoch [9/30], Step [640/1250], Loss: 0.6051\n",
            "Epoch [9/30], Step [650/1250], Loss: 0.5554\n",
            "Epoch [9/30], Step [660/1250], Loss: 0.7065\n",
            "Epoch [9/30], Step [670/1250], Loss: 0.3317\n",
            "Epoch [9/30], Step [680/1250], Loss: 0.4020\n",
            "Epoch [9/30], Step [690/1250], Loss: 0.3938\n",
            "Epoch [9/30], Step [700/1250], Loss: 0.5138\n",
            "Epoch [9/30], Step [710/1250], Loss: 0.3682\n",
            "Epoch [9/30], Step [720/1250], Loss: 0.8218\n",
            "Epoch [9/30], Step [730/1250], Loss: 0.3217\n",
            "Epoch [9/30], Step [740/1250], Loss: 0.5607\n",
            "Epoch [9/30], Step [750/1250], Loss: 0.3625\n",
            "Epoch [9/30], Step [760/1250], Loss: 0.5941\n",
            "Epoch [9/30], Step [770/1250], Loss: 0.3663\n",
            "Epoch [9/30], Step [780/1250], Loss: 0.6088\n",
            "Epoch [9/30], Step [790/1250], Loss: 0.3339\n",
            "Epoch [9/30], Step [800/1250], Loss: 0.3877\n",
            "Epoch [9/30], Step [810/1250], Loss: 0.4866\n",
            "Epoch [9/30], Step [820/1250], Loss: 0.2655\n",
            "Epoch [9/30], Step [830/1250], Loss: 0.2422\n",
            "Epoch [9/30], Step [840/1250], Loss: 0.5418\n",
            "Epoch [9/30], Step [850/1250], Loss: 0.8001\n",
            "Epoch [9/30], Step [860/1250], Loss: 0.3456\n",
            "Epoch [9/30], Step [870/1250], Loss: 0.5992\n",
            "Epoch [9/30], Step [880/1250], Loss: 0.1691\n",
            "Epoch [9/30], Step [890/1250], Loss: 0.5941\n",
            "Epoch [9/30], Step [900/1250], Loss: 0.5766\n",
            "Epoch [9/30], Step [910/1250], Loss: 0.4688\n",
            "Epoch [9/30], Step [920/1250], Loss: 0.7247\n",
            "Epoch [9/30], Step [930/1250], Loss: 0.2928\n",
            "Epoch [9/30], Step [940/1250], Loss: 0.2728\n",
            "Epoch [9/30], Step [950/1250], Loss: 0.5116\n",
            "Epoch [9/30], Step [960/1250], Loss: 0.4417\n",
            "Epoch [9/30], Step [970/1250], Loss: 0.3835\n",
            "Epoch [9/30], Step [980/1250], Loss: 0.5433\n",
            "Epoch [9/30], Step [990/1250], Loss: 0.4286\n",
            "Epoch [9/30], Step [1000/1250], Loss: 0.8958\n",
            "Epoch [9/30], Step [1010/1250], Loss: 0.5133\n",
            "Epoch [9/30], Step [1020/1250], Loss: 0.4760\n",
            "Epoch [9/30], Step [1030/1250], Loss: 0.3342\n",
            "Epoch [9/30], Step [1040/1250], Loss: 0.5796\n",
            "Epoch [9/30], Step [1050/1250], Loss: 0.2404\n",
            "Epoch [9/30], Step [1060/1250], Loss: 0.3525\n",
            "Epoch [9/30], Step [1070/1250], Loss: 0.4903\n",
            "Epoch [9/30], Step [1080/1250], Loss: 0.2894\n",
            "Epoch [9/30], Step [1090/1250], Loss: 0.4339\n",
            "Epoch [9/30], Step [1100/1250], Loss: 0.7144\n",
            "Epoch [9/30], Step [1110/1250], Loss: 0.5727\n",
            "Epoch [9/30], Step [1120/1250], Loss: 0.3477\n",
            "Epoch [9/30], Step [1130/1250], Loss: 0.6230\n",
            "Epoch [9/30], Step [1140/1250], Loss: 0.3479\n",
            "Epoch [9/30], Step [1150/1250], Loss: 0.4598\n",
            "Epoch [9/30], Step [1160/1250], Loss: 0.5282\n",
            "Epoch [9/30], Step [1170/1250], Loss: 0.4490\n",
            "Epoch [9/30], Step [1180/1250], Loss: 0.5146\n",
            "Epoch [9/30], Step [1190/1250], Loss: 0.3759\n",
            "Epoch [9/30], Step [1200/1250], Loss: 0.2224\n",
            "Epoch [9/30], Step [1210/1250], Loss: 0.4836\n",
            "Epoch [9/30], Step [1220/1250], Loss: 0.4531\n",
            "Epoch [9/30], Step [1230/1250], Loss: 0.5450\n",
            "Epoch [9/30], Step [1240/1250], Loss: 0.5052\n",
            "Epoch [9/30], Step [1250/1250], Loss: 0.4588\n",
            "Epoch [10/30], Step [10/1250], Loss: 0.2971\n",
            "Epoch [10/30], Step [20/1250], Loss: 0.3193\n",
            "Epoch [10/30], Step [30/1250], Loss: 0.4643\n",
            "Epoch [10/30], Step [40/1250], Loss: 0.3649\n",
            "Epoch [10/30], Step [50/1250], Loss: 0.3340\n",
            "Epoch [10/30], Step [60/1250], Loss: 0.2742\n",
            "Epoch [10/30], Step [70/1250], Loss: 0.2027\n",
            "Epoch [10/30], Step [80/1250], Loss: 0.2854\n",
            "Epoch [10/30], Step [90/1250], Loss: 0.3969\n",
            "Epoch [10/30], Step [100/1250], Loss: 0.2111\n",
            "Epoch [10/30], Step [110/1250], Loss: 0.2419\n",
            "Epoch [10/30], Step [120/1250], Loss: 0.6442\n",
            "Epoch [10/30], Step [130/1250], Loss: 0.2451\n",
            "Epoch [10/30], Step [140/1250], Loss: 0.1820\n",
            "Epoch [10/30], Step [150/1250], Loss: 0.4169\n",
            "Epoch [10/30], Step [160/1250], Loss: 0.1963\n",
            "Epoch [10/30], Step [170/1250], Loss: 0.3297\n",
            "Epoch [10/30], Step [180/1250], Loss: 0.2426\n",
            "Epoch [10/30], Step [190/1250], Loss: 0.3478\n",
            "Epoch [10/30], Step [200/1250], Loss: 0.2788\n",
            "Epoch [10/30], Step [210/1250], Loss: 0.3284\n",
            "Epoch [10/30], Step [220/1250], Loss: 0.1922\n",
            "Epoch [10/30], Step [230/1250], Loss: 0.2826\n",
            "Epoch [10/30], Step [240/1250], Loss: 0.3968\n",
            "Epoch [10/30], Step [250/1250], Loss: 0.2794\n",
            "Epoch [10/30], Step [260/1250], Loss: 0.1822\n",
            "Epoch [10/30], Step [270/1250], Loss: 0.2610\n",
            "Epoch [10/30], Step [280/1250], Loss: 0.3974\n",
            "Epoch [10/30], Step [290/1250], Loss: 0.2753\n",
            "Epoch [10/30], Step [300/1250], Loss: 0.4382\n",
            "Epoch [10/30], Step [310/1250], Loss: 0.1389\n",
            "Epoch [10/30], Step [320/1250], Loss: 0.4523\n",
            "Epoch [10/30], Step [330/1250], Loss: 0.3745\n",
            "Epoch [10/30], Step [340/1250], Loss: 0.3914\n",
            "Epoch [10/30], Step [350/1250], Loss: 0.3309\n",
            "Epoch [10/30], Step [360/1250], Loss: 0.3952\n",
            "Epoch [10/30], Step [370/1250], Loss: 0.3078\n",
            "Epoch [10/30], Step [380/1250], Loss: 0.4375\n",
            "Epoch [10/30], Step [390/1250], Loss: 0.3661\n",
            "Epoch [10/30], Step [400/1250], Loss: 0.2360\n",
            "Epoch [10/30], Step [410/1250], Loss: 0.4136\n",
            "Epoch [10/30], Step [420/1250], Loss: 0.5128\n",
            "Epoch [10/30], Step [430/1250], Loss: 0.3856\n",
            "Epoch [10/30], Step [440/1250], Loss: 0.3988\n",
            "Epoch [10/30], Step [450/1250], Loss: 0.3662\n",
            "Epoch [10/30], Step [460/1250], Loss: 0.4281\n",
            "Epoch [10/30], Step [470/1250], Loss: 0.4137\n",
            "Epoch [10/30], Step [480/1250], Loss: 0.4303\n",
            "Epoch [10/30], Step [490/1250], Loss: 0.2988\n",
            "Epoch [10/30], Step [500/1250], Loss: 0.3944\n",
            "Epoch [10/30], Step [510/1250], Loss: 0.1517\n",
            "Epoch [10/30], Step [520/1250], Loss: 0.4617\n",
            "Epoch [10/30], Step [530/1250], Loss: 0.4437\n",
            "Epoch [10/30], Step [540/1250], Loss: 0.3082\n",
            "Epoch [10/30], Step [550/1250], Loss: 0.4544\n",
            "Epoch [10/30], Step [560/1250], Loss: 0.4411\n",
            "Epoch [10/30], Step [570/1250], Loss: 0.2915\n",
            "Epoch [10/30], Step [580/1250], Loss: 0.3584\n",
            "Epoch [10/30], Step [590/1250], Loss: 0.2872\n",
            "Epoch [10/30], Step [600/1250], Loss: 0.2677\n",
            "Epoch [10/30], Step [610/1250], Loss: 0.4179\n",
            "Epoch [10/30], Step [620/1250], Loss: 0.3681\n",
            "Epoch [10/30], Step [630/1250], Loss: 0.3383\n",
            "Epoch [10/30], Step [640/1250], Loss: 0.2251\n",
            "Epoch [10/30], Step [650/1250], Loss: 0.3379\n",
            "Epoch [10/30], Step [660/1250], Loss: 0.3811\n",
            "Epoch [10/30], Step [670/1250], Loss: 0.3596\n",
            "Epoch [10/30], Step [680/1250], Loss: 0.3722\n",
            "Epoch [10/30], Step [690/1250], Loss: 0.3088\n",
            "Epoch [10/30], Step [700/1250], Loss: 0.4251\n",
            "Epoch [10/30], Step [710/1250], Loss: 0.1491\n",
            "Epoch [10/30], Step [720/1250], Loss: 0.6865\n",
            "Epoch [10/30], Step [730/1250], Loss: 0.4543\n",
            "Epoch [10/30], Step [740/1250], Loss: 0.4801\n",
            "Epoch [10/30], Step [750/1250], Loss: 0.3180\n",
            "Epoch [10/30], Step [760/1250], Loss: 0.4561\n",
            "Epoch [10/30], Step [770/1250], Loss: 0.4554\n",
            "Epoch [10/30], Step [780/1250], Loss: 0.3020\n",
            "Epoch [10/30], Step [790/1250], Loss: 0.5722\n",
            "Epoch [10/30], Step [800/1250], Loss: 0.3971\n",
            "Epoch [10/30], Step [810/1250], Loss: 0.3927\n",
            "Epoch [10/30], Step [820/1250], Loss: 0.3117\n",
            "Epoch [10/30], Step [830/1250], Loss: 0.3766\n",
            "Epoch [10/30], Step [840/1250], Loss: 0.4114\n",
            "Epoch [10/30], Step [850/1250], Loss: 0.3147\n",
            "Epoch [10/30], Step [860/1250], Loss: 0.3038\n",
            "Epoch [10/30], Step [870/1250], Loss: 0.3210\n",
            "Epoch [10/30], Step [880/1250], Loss: 0.3519\n",
            "Epoch [10/30], Step [890/1250], Loss: 0.4130\n",
            "Epoch [10/30], Step [900/1250], Loss: 0.2028\n",
            "Epoch [10/30], Step [910/1250], Loss: 0.3519\n",
            "Epoch [10/30], Step [920/1250], Loss: 0.5047\n",
            "Epoch [10/30], Step [930/1250], Loss: 0.2586\n",
            "Epoch [10/30], Step [940/1250], Loss: 0.4276\n",
            "Epoch [10/30], Step [950/1250], Loss: 0.4158\n",
            "Epoch [10/30], Step [960/1250], Loss: 0.4750\n",
            "Epoch [10/30], Step [970/1250], Loss: 0.4684\n",
            "Epoch [10/30], Step [980/1250], Loss: 0.4018\n",
            "Epoch [10/30], Step [990/1250], Loss: 0.5180\n",
            "Epoch [10/30], Step [1000/1250], Loss: 0.3184\n",
            "Epoch [10/30], Step [1010/1250], Loss: 0.3908\n",
            "Epoch [10/30], Step [1020/1250], Loss: 0.4297\n",
            "Epoch [10/30], Step [1030/1250], Loss: 0.2755\n",
            "Epoch [10/30], Step [1040/1250], Loss: 0.2200\n",
            "Epoch [10/30], Step [1050/1250], Loss: 0.4432\n",
            "Epoch [10/30], Step [1060/1250], Loss: 0.3236\n",
            "Epoch [10/30], Step [1070/1250], Loss: 0.3112\n",
            "Epoch [10/30], Step [1080/1250], Loss: 0.3255\n",
            "Epoch [10/30], Step [1090/1250], Loss: 0.4677\n",
            "Epoch [10/30], Step [1100/1250], Loss: 0.3931\n",
            "Epoch [10/30], Step [1110/1250], Loss: 0.3354\n",
            "Epoch [10/30], Step [1120/1250], Loss: 0.4320\n",
            "Epoch [10/30], Step [1130/1250], Loss: 0.5864\n",
            "Epoch [10/30], Step [1140/1250], Loss: 0.5802\n",
            "Epoch [10/30], Step [1150/1250], Loss: 0.2346\n",
            "Epoch [10/30], Step [1160/1250], Loss: 0.3668\n",
            "Epoch [10/30], Step [1170/1250], Loss: 0.3679\n",
            "Epoch [10/30], Step [1180/1250], Loss: 0.4232\n",
            "Epoch [10/30], Step [1190/1250], Loss: 0.4994\n",
            "Epoch [10/30], Step [1200/1250], Loss: 0.3816\n",
            "Epoch [10/30], Step [1210/1250], Loss: 0.1941\n",
            "Epoch [10/30], Step [1220/1250], Loss: 0.3855\n",
            "Epoch [10/30], Step [1230/1250], Loss: 0.3007\n",
            "Epoch [10/30], Step [1240/1250], Loss: 0.6251\n",
            "Epoch [10/30], Step [1250/1250], Loss: 0.4680\n",
            "Epoch [11/30], Step [10/1250], Loss: 0.4188\n",
            "Epoch [11/30], Step [20/1250], Loss: 0.1983\n",
            "Epoch [11/30], Step [30/1250], Loss: 0.3854\n",
            "Epoch [11/30], Step [40/1250], Loss: 0.2642\n",
            "Epoch [11/30], Step [50/1250], Loss: 0.3056\n",
            "Epoch [11/30], Step [60/1250], Loss: 0.1446\n",
            "Epoch [11/30], Step [70/1250], Loss: 0.3827\n",
            "Epoch [11/30], Step [80/1250], Loss: 0.5016\n",
            "Epoch [11/30], Step [90/1250], Loss: 0.2952\n",
            "Epoch [11/30], Step [100/1250], Loss: 0.1519\n",
            "Epoch [11/30], Step [110/1250], Loss: 0.3627\n",
            "Epoch [11/30], Step [120/1250], Loss: 0.4347\n",
            "Epoch [11/30], Step [130/1250], Loss: 0.1091\n",
            "Epoch [11/30], Step [140/1250], Loss: 0.3584\n",
            "Epoch [11/30], Step [150/1250], Loss: 0.2381\n",
            "Epoch [11/30], Step [160/1250], Loss: 0.1470\n",
            "Epoch [11/30], Step [170/1250], Loss: 0.2520\n",
            "Epoch [11/30], Step [180/1250], Loss: 0.2596\n",
            "Epoch [11/30], Step [190/1250], Loss: 0.3337\n",
            "Epoch [11/30], Step [200/1250], Loss: 0.3119\n",
            "Epoch [11/30], Step [210/1250], Loss: 0.2617\n",
            "Epoch [11/30], Step [220/1250], Loss: 0.2100\n",
            "Epoch [11/30], Step [230/1250], Loss: 0.3042\n",
            "Epoch [11/30], Step [240/1250], Loss: 0.4686\n",
            "Epoch [11/30], Step [250/1250], Loss: 0.5003\n",
            "Epoch [11/30], Step [260/1250], Loss: 0.1496\n",
            "Epoch [11/30], Step [270/1250], Loss: 0.2446\n",
            "Epoch [11/30], Step [280/1250], Loss: 0.3466\n",
            "Epoch [11/30], Step [290/1250], Loss: 0.5479\n",
            "Epoch [11/30], Step [300/1250], Loss: 0.3175\n",
            "Epoch [11/30], Step [310/1250], Loss: 0.2320\n",
            "Epoch [11/30], Step [320/1250], Loss: 0.3914\n",
            "Epoch [11/30], Step [330/1250], Loss: 0.2907\n",
            "Epoch [11/30], Step [340/1250], Loss: 0.2258\n",
            "Epoch [11/30], Step [350/1250], Loss: 0.1976\n",
            "Epoch [11/30], Step [360/1250], Loss: 0.5637\n",
            "Epoch [11/30], Step [370/1250], Loss: 0.3201\n",
            "Epoch [11/30], Step [380/1250], Loss: 0.4118\n",
            "Epoch [11/30], Step [390/1250], Loss: 0.1657\n",
            "Epoch [11/30], Step [400/1250], Loss: 0.0972\n",
            "Epoch [11/30], Step [410/1250], Loss: 0.3135\n",
            "Epoch [11/30], Step [420/1250], Loss: 0.2885\n",
            "Epoch [11/30], Step [430/1250], Loss: 0.2042\n",
            "Epoch [11/30], Step [440/1250], Loss: 0.4374\n",
            "Epoch [11/30], Step [450/1250], Loss: 0.2148\n",
            "Epoch [11/30], Step [460/1250], Loss: 0.1513\n",
            "Epoch [11/30], Step [470/1250], Loss: 0.2495\n",
            "Epoch [11/30], Step [480/1250], Loss: 0.4094\n",
            "Epoch [11/30], Step [490/1250], Loss: 0.2254\n",
            "Epoch [11/30], Step [500/1250], Loss: 0.3651\n",
            "Epoch [11/30], Step [510/1250], Loss: 0.3042\n",
            "Epoch [11/30], Step [520/1250], Loss: 0.1914\n",
            "Epoch [11/30], Step [530/1250], Loss: 0.2824\n",
            "Epoch [11/30], Step [540/1250], Loss: 0.3829\n",
            "Epoch [11/30], Step [550/1250], Loss: 0.1930\n",
            "Epoch [11/30], Step [560/1250], Loss: 0.3530\n",
            "Epoch [11/30], Step [570/1250], Loss: 0.2400\n",
            "Epoch [11/30], Step [580/1250], Loss: 0.3164\n",
            "Epoch [11/30], Step [590/1250], Loss: 0.3492\n",
            "Epoch [11/30], Step [600/1250], Loss: 0.3027\n",
            "Epoch [11/30], Step [610/1250], Loss: 0.1998\n",
            "Epoch [11/30], Step [620/1250], Loss: 0.2563\n",
            "Epoch [11/30], Step [630/1250], Loss: 0.2684\n",
            "Epoch [11/30], Step [640/1250], Loss: 0.4389\n",
            "Epoch [11/30], Step [650/1250], Loss: 0.1619\n",
            "Epoch [11/30], Step [660/1250], Loss: 0.1688\n",
            "Epoch [11/30], Step [670/1250], Loss: 0.4461\n",
            "Epoch [11/30], Step [680/1250], Loss: 0.1549\n",
            "Epoch [11/30], Step [690/1250], Loss: 0.3735\n",
            "Epoch [11/30], Step [700/1250], Loss: 0.4768\n",
            "Epoch [11/30], Step [710/1250], Loss: 0.2964\n",
            "Epoch [11/30], Step [720/1250], Loss: 0.1581\n",
            "Epoch [11/30], Step [730/1250], Loss: 0.4412\n",
            "Epoch [11/30], Step [740/1250], Loss: 0.4772\n",
            "Epoch [11/30], Step [750/1250], Loss: 0.2127\n",
            "Epoch [11/30], Step [760/1250], Loss: 0.3730\n",
            "Epoch [11/30], Step [770/1250], Loss: 0.2153\n",
            "Epoch [11/30], Step [780/1250], Loss: 0.3604\n",
            "Epoch [11/30], Step [790/1250], Loss: 0.1931\n",
            "Epoch [11/30], Step [800/1250], Loss: 0.3170\n",
            "Epoch [11/30], Step [810/1250], Loss: 0.4860\n",
            "Epoch [11/30], Step [820/1250], Loss: 0.4104\n",
            "Epoch [11/30], Step [830/1250], Loss: 0.2139\n",
            "Epoch [11/30], Step [840/1250], Loss: 0.2644\n",
            "Epoch [11/30], Step [850/1250], Loss: 0.0650\n",
            "Epoch [11/30], Step [860/1250], Loss: 0.2975\n",
            "Epoch [11/30], Step [870/1250], Loss: 0.2687\n",
            "Epoch [11/30], Step [880/1250], Loss: 0.2628\n",
            "Epoch [11/30], Step [890/1250], Loss: 0.3151\n",
            "Epoch [11/30], Step [900/1250], Loss: 0.3990\n",
            "Epoch [11/30], Step [910/1250], Loss: 0.3729\n",
            "Epoch [11/30], Step [920/1250], Loss: 0.3781\n",
            "Epoch [11/30], Step [930/1250], Loss: 0.2510\n",
            "Epoch [11/30], Step [940/1250], Loss: 0.5074\n",
            "Epoch [11/30], Step [950/1250], Loss: 0.3856\n",
            "Epoch [11/30], Step [960/1250], Loss: 0.3136\n",
            "Epoch [11/30], Step [970/1250], Loss: 0.3570\n",
            "Epoch [11/30], Step [980/1250], Loss: 0.4035\n",
            "Epoch [11/30], Step [990/1250], Loss: 0.5479\n",
            "Epoch [11/30], Step [1000/1250], Loss: 0.2521\n",
            "Epoch [11/30], Step [1010/1250], Loss: 0.3612\n",
            "Epoch [11/30], Step [1020/1250], Loss: 0.2478\n",
            "Epoch [11/30], Step [1030/1250], Loss: 0.0775\n",
            "Epoch [11/30], Step [1040/1250], Loss: 0.3205\n",
            "Epoch [11/30], Step [1050/1250], Loss: 0.1915\n",
            "Epoch [11/30], Step [1060/1250], Loss: 0.3645\n",
            "Epoch [11/30], Step [1070/1250], Loss: 0.3265\n",
            "Epoch [11/30], Step [1080/1250], Loss: 0.3511\n",
            "Epoch [11/30], Step [1090/1250], Loss: 0.2788\n",
            "Epoch [11/30], Step [1100/1250], Loss: 0.5302\n",
            "Epoch [11/30], Step [1110/1250], Loss: 0.4549\n",
            "Epoch [11/30], Step [1120/1250], Loss: 0.1561\n",
            "Epoch [11/30], Step [1130/1250], Loss: 0.2261\n",
            "Epoch [11/30], Step [1140/1250], Loss: 0.2967\n",
            "Epoch [11/30], Step [1150/1250], Loss: 0.4413\n",
            "Epoch [11/30], Step [1160/1250], Loss: 0.3844\n",
            "Epoch [11/30], Step [1170/1250], Loss: 0.4006\n",
            "Epoch [11/30], Step [1180/1250], Loss: 0.2562\n",
            "Epoch [11/30], Step [1190/1250], Loss: 0.2330\n",
            "Epoch [11/30], Step [1200/1250], Loss: 0.1776\n",
            "Epoch [11/30], Step [1210/1250], Loss: 0.2411\n",
            "Epoch [11/30], Step [1220/1250], Loss: 0.3510\n",
            "Epoch [11/30], Step [1230/1250], Loss: 0.5330\n",
            "Epoch [11/30], Step [1240/1250], Loss: 0.4867\n",
            "Epoch [11/30], Step [1250/1250], Loss: 0.3087\n",
            "Epoch [12/30], Step [10/1250], Loss: 0.2216\n",
            "Epoch [12/30], Step [20/1250], Loss: 0.1180\n",
            "Epoch [12/30], Step [30/1250], Loss: 0.2165\n",
            "Epoch [12/30], Step [40/1250], Loss: 0.1749\n",
            "Epoch [12/30], Step [50/1250], Loss: 0.2962\n",
            "Epoch [12/30], Step [60/1250], Loss: 0.2282\n",
            "Epoch [12/30], Step [70/1250], Loss: 0.0953\n",
            "Epoch [12/30], Step [80/1250], Loss: 0.2726\n",
            "Epoch [12/30], Step [90/1250], Loss: 0.2766\n",
            "Epoch [12/30], Step [100/1250], Loss: 0.1303\n",
            "Epoch [12/30], Step [110/1250], Loss: 0.2142\n",
            "Epoch [12/30], Step [120/1250], Loss: 0.1613\n",
            "Epoch [12/30], Step [130/1250], Loss: 0.1798\n",
            "Epoch [12/30], Step [140/1250], Loss: 0.1185\n",
            "Epoch [12/30], Step [150/1250], Loss: 0.3004\n",
            "Epoch [12/30], Step [160/1250], Loss: 0.1702\n",
            "Epoch [12/30], Step [170/1250], Loss: 0.2618\n",
            "Epoch [12/30], Step [180/1250], Loss: 0.2094\n",
            "Epoch [12/30], Step [190/1250], Loss: 0.1980\n",
            "Epoch [12/30], Step [200/1250], Loss: 0.3604\n",
            "Epoch [12/30], Step [210/1250], Loss: 0.2853\n",
            "Epoch [12/30], Step [220/1250], Loss: 0.1111\n",
            "Epoch [12/30], Step [230/1250], Loss: 0.0939\n",
            "Epoch [12/30], Step [240/1250], Loss: 0.4545\n",
            "Epoch [12/30], Step [250/1250], Loss: 0.1758\n",
            "Epoch [12/30], Step [260/1250], Loss: 0.0898\n",
            "Epoch [12/30], Step [270/1250], Loss: 0.0802\n",
            "Epoch [12/30], Step [280/1250], Loss: 0.1897\n",
            "Epoch [12/30], Step [290/1250], Loss: 0.2573\n",
            "Epoch [12/30], Step [300/1250], Loss: 0.3713\n",
            "Epoch [12/30], Step [310/1250], Loss: 0.1575\n",
            "Epoch [12/30], Step [320/1250], Loss: 0.1275\n",
            "Epoch [12/30], Step [330/1250], Loss: 0.1557\n",
            "Epoch [12/30], Step [340/1250], Loss: 0.1112\n",
            "Epoch [12/30], Step [350/1250], Loss: 0.2373\n",
            "Epoch [12/30], Step [360/1250], Loss: 0.2993\n",
            "Epoch [12/30], Step [370/1250], Loss: 0.1946\n",
            "Epoch [12/30], Step [380/1250], Loss: 0.0771\n",
            "Epoch [12/30], Step [390/1250], Loss: 0.1414\n",
            "Epoch [12/30], Step [400/1250], Loss: 0.2655\n",
            "Epoch [12/30], Step [410/1250], Loss: 0.2043\n",
            "Epoch [12/30], Step [420/1250], Loss: 0.2584\n",
            "Epoch [12/30], Step [430/1250], Loss: 0.1850\n",
            "Epoch [12/30], Step [440/1250], Loss: 0.3587\n",
            "Epoch [12/30], Step [450/1250], Loss: 0.1814\n",
            "Epoch [12/30], Step [460/1250], Loss: 0.1926\n",
            "Epoch [12/30], Step [470/1250], Loss: 0.1483\n",
            "Epoch [12/30], Step [480/1250], Loss: 0.3443\n",
            "Epoch [12/30], Step [490/1250], Loss: 0.1904\n",
            "Epoch [12/30], Step [500/1250], Loss: 0.2618\n",
            "Epoch [12/30], Step [510/1250], Loss: 0.3269\n",
            "Epoch [12/30], Step [520/1250], Loss: 0.2235\n",
            "Epoch [12/30], Step [530/1250], Loss: 0.3776\n",
            "Epoch [12/30], Step [540/1250], Loss: 0.2074\n",
            "Epoch [12/30], Step [550/1250], Loss: 0.2345\n",
            "Epoch [12/30], Step [560/1250], Loss: 0.2206\n",
            "Epoch [12/30], Step [570/1250], Loss: 0.1467\n",
            "Epoch [12/30], Step [580/1250], Loss: 0.1037\n",
            "Epoch [12/30], Step [590/1250], Loss: 0.2425\n",
            "Epoch [12/30], Step [600/1250], Loss: 0.3935\n",
            "Epoch [12/30], Step [610/1250], Loss: 0.2760\n",
            "Epoch [12/30], Step [620/1250], Loss: 0.3337\n",
            "Epoch [12/30], Step [630/1250], Loss: 0.4128\n",
            "Epoch [12/30], Step [640/1250], Loss: 0.3073\n",
            "Epoch [12/30], Step [650/1250], Loss: 0.2252\n",
            "Epoch [12/30], Step [660/1250], Loss: 0.1856\n",
            "Epoch [12/30], Step [670/1250], Loss: 0.2154\n",
            "Epoch [12/30], Step [680/1250], Loss: 0.1734\n",
            "Epoch [12/30], Step [690/1250], Loss: 0.2114\n",
            "Epoch [12/30], Step [700/1250], Loss: 0.1847\n",
            "Epoch [12/30], Step [710/1250], Loss: 0.2769\n",
            "Epoch [12/30], Step [720/1250], Loss: 0.2809\n",
            "Epoch [12/30], Step [730/1250], Loss: 0.2475\n",
            "Epoch [12/30], Step [740/1250], Loss: 0.1134\n",
            "Epoch [12/30], Step [750/1250], Loss: 0.1596\n",
            "Epoch [12/30], Step [760/1250], Loss: 0.2405\n",
            "Epoch [12/30], Step [770/1250], Loss: 0.1749\n",
            "Epoch [12/30], Step [780/1250], Loss: 0.1565\n",
            "Epoch [12/30], Step [790/1250], Loss: 0.2341\n",
            "Epoch [12/30], Step [800/1250], Loss: 0.4477\n",
            "Epoch [12/30], Step [810/1250], Loss: 0.3467\n",
            "Epoch [12/30], Step [820/1250], Loss: 0.4175\n",
            "Epoch [12/30], Step [830/1250], Loss: 0.1730\n",
            "Epoch [12/30], Step [840/1250], Loss: 0.3646\n",
            "Epoch [12/30], Step [850/1250], Loss: 0.2167\n",
            "Epoch [12/30], Step [860/1250], Loss: 0.2761\n",
            "Epoch [12/30], Step [870/1250], Loss: 0.2926\n",
            "Epoch [12/30], Step [880/1250], Loss: 0.1336\n",
            "Epoch [12/30], Step [890/1250], Loss: 0.1460\n",
            "Epoch [12/30], Step [900/1250], Loss: 0.3685\n",
            "Epoch [12/30], Step [910/1250], Loss: 0.1929\n",
            "Epoch [12/30], Step [920/1250], Loss: 0.3323\n",
            "Epoch [12/30], Step [930/1250], Loss: 0.2912\n",
            "Epoch [12/30], Step [940/1250], Loss: 0.1363\n",
            "Epoch [12/30], Step [950/1250], Loss: 0.2228\n",
            "Epoch [12/30], Step [960/1250], Loss: 0.1488\n",
            "Epoch [12/30], Step [970/1250], Loss: 0.2425\n",
            "Epoch [12/30], Step [980/1250], Loss: 0.1299\n",
            "Epoch [12/30], Step [990/1250], Loss: 0.2899\n",
            "Epoch [12/30], Step [1000/1250], Loss: 0.3130\n",
            "Epoch [12/30], Step [1010/1250], Loss: 0.3105\n",
            "Epoch [12/30], Step [1020/1250], Loss: 0.3726\n",
            "Epoch [12/30], Step [1030/1250], Loss: 0.2780\n",
            "Epoch [12/30], Step [1040/1250], Loss: 0.3333\n",
            "Epoch [12/30], Step [1050/1250], Loss: 0.3158\n",
            "Epoch [12/30], Step [1060/1250], Loss: 0.1536\n",
            "Epoch [12/30], Step [1070/1250], Loss: 0.1437\n",
            "Epoch [12/30], Step [1080/1250], Loss: 0.4143\n",
            "Epoch [12/30], Step [1090/1250], Loss: 0.1733\n",
            "Epoch [12/30], Step [1100/1250], Loss: 0.2860\n",
            "Epoch [12/30], Step [1110/1250], Loss: 0.3458\n",
            "Epoch [12/30], Step [1120/1250], Loss: 0.1320\n",
            "Epoch [12/30], Step [1130/1250], Loss: 0.1892\n",
            "Epoch [12/30], Step [1140/1250], Loss: 0.4101\n",
            "Epoch [12/30], Step [1150/1250], Loss: 0.2606\n",
            "Epoch [12/30], Step [1160/1250], Loss: 0.1226\n",
            "Epoch [12/30], Step [1170/1250], Loss: 0.3548\n",
            "Epoch [12/30], Step [1180/1250], Loss: 0.2310\n",
            "Epoch [12/30], Step [1190/1250], Loss: 0.2691\n",
            "Epoch [12/30], Step [1200/1250], Loss: 0.3816\n",
            "Epoch [12/30], Step [1210/1250], Loss: 0.1699\n",
            "Epoch [12/30], Step [1220/1250], Loss: 0.5940\n",
            "Epoch [12/30], Step [1230/1250], Loss: 0.1083\n",
            "Epoch [12/30], Step [1240/1250], Loss: 0.3396\n",
            "Epoch [12/30], Step [1250/1250], Loss: 0.2491\n",
            "Epoch [13/30], Step [10/1250], Loss: 0.1193\n",
            "Epoch [13/30], Step [20/1250], Loss: 0.1676\n",
            "Epoch [13/30], Step [30/1250], Loss: 0.1714\n",
            "Epoch [13/30], Step [40/1250], Loss: 0.1773\n",
            "Epoch [13/30], Step [50/1250], Loss: 0.0662\n",
            "Epoch [13/30], Step [60/1250], Loss: 0.5209\n",
            "Epoch [13/30], Step [70/1250], Loss: 0.2298\n",
            "Epoch [13/30], Step [80/1250], Loss: 0.1225\n",
            "Epoch [13/30], Step [90/1250], Loss: 0.1374\n",
            "Epoch [13/30], Step [100/1250], Loss: 0.2173\n",
            "Epoch [13/30], Step [110/1250], Loss: 0.2263\n",
            "Epoch [13/30], Step [120/1250], Loss: 0.0492\n",
            "Epoch [13/30], Step [130/1250], Loss: 0.0633\n",
            "Epoch [13/30], Step [140/1250], Loss: 0.1327\n",
            "Epoch [13/30], Step [150/1250], Loss: 0.1263\n",
            "Epoch [13/30], Step [160/1250], Loss: 0.1367\n",
            "Epoch [13/30], Step [170/1250], Loss: 0.1705\n",
            "Epoch [13/30], Step [180/1250], Loss: 0.1422\n",
            "Epoch [13/30], Step [190/1250], Loss: 0.0971\n",
            "Epoch [13/30], Step [200/1250], Loss: 0.0967\n",
            "Epoch [13/30], Step [210/1250], Loss: 0.1002\n",
            "Epoch [13/30], Step [220/1250], Loss: 0.1807\n",
            "Epoch [13/30], Step [230/1250], Loss: 0.2248\n",
            "Epoch [13/30], Step [240/1250], Loss: 0.2532\n",
            "Epoch [13/30], Step [250/1250], Loss: 0.1346\n",
            "Epoch [13/30], Step [260/1250], Loss: 0.1608\n",
            "Epoch [13/30], Step [270/1250], Loss: 0.1340\n",
            "Epoch [13/30], Step [280/1250], Loss: 0.0391\n",
            "Epoch [13/30], Step [290/1250], Loss: 0.2287\n",
            "Epoch [13/30], Step [300/1250], Loss: 0.1803\n",
            "Epoch [13/30], Step [310/1250], Loss: 0.2237\n",
            "Epoch [13/30], Step [320/1250], Loss: 0.2025\n",
            "Epoch [13/30], Step [330/1250], Loss: 0.1110\n",
            "Epoch [13/30], Step [340/1250], Loss: 0.2175\n",
            "Epoch [13/30], Step [350/1250], Loss: 0.2122\n",
            "Epoch [13/30], Step [360/1250], Loss: 0.2719\n",
            "Epoch [13/30], Step [370/1250], Loss: 0.1379\n",
            "Epoch [13/30], Step [380/1250], Loss: 0.2906\n",
            "Epoch [13/30], Step [390/1250], Loss: 0.3467\n",
            "Epoch [13/30], Step [400/1250], Loss: 0.0994\n",
            "Epoch [13/30], Step [410/1250], Loss: 0.0864\n",
            "Epoch [13/30], Step [420/1250], Loss: 0.1657\n",
            "Epoch [13/30], Step [430/1250], Loss: 0.3107\n",
            "Epoch [13/30], Step [440/1250], Loss: 0.2191\n",
            "Epoch [13/30], Step [450/1250], Loss: 0.1614\n",
            "Epoch [13/30], Step [460/1250], Loss: 0.1269\n",
            "Epoch [13/30], Step [470/1250], Loss: 0.1230\n",
            "Epoch [13/30], Step [480/1250], Loss: 0.1391\n",
            "Epoch [13/30], Step [490/1250], Loss: 0.3097\n",
            "Epoch [13/30], Step [500/1250], Loss: 0.2906\n",
            "Epoch [13/30], Step [510/1250], Loss: 0.1152\n",
            "Epoch [13/30], Step [520/1250], Loss: 0.0859\n",
            "Epoch [13/30], Step [530/1250], Loss: 0.2716\n",
            "Epoch [13/30], Step [540/1250], Loss: 0.2040\n",
            "Epoch [13/30], Step [550/1250], Loss: 0.2566\n",
            "Epoch [13/30], Step [560/1250], Loss: 0.2108\n",
            "Epoch [13/30], Step [570/1250], Loss: 0.1239\n",
            "Epoch [13/30], Step [580/1250], Loss: 0.4052\n",
            "Epoch [13/30], Step [590/1250], Loss: 0.1848\n",
            "Epoch [13/30], Step [600/1250], Loss: 0.1939\n",
            "Epoch [13/30], Step [610/1250], Loss: 0.1197\n",
            "Epoch [13/30], Step [620/1250], Loss: 0.4787\n",
            "Epoch [13/30], Step [630/1250], Loss: 0.2880\n",
            "Epoch [13/30], Step [640/1250], Loss: 0.1228\n",
            "Epoch [13/30], Step [650/1250], Loss: 0.1345\n",
            "Epoch [13/30], Step [660/1250], Loss: 0.2389\n",
            "Epoch [13/30], Step [670/1250], Loss: 0.3293\n",
            "Epoch [13/30], Step [680/1250], Loss: 0.2697\n",
            "Epoch [13/30], Step [690/1250], Loss: 0.2015\n",
            "Epoch [13/30], Step [700/1250], Loss: 0.2127\n",
            "Epoch [13/30], Step [710/1250], Loss: 0.4167\n",
            "Epoch [13/30], Step [720/1250], Loss: 0.2315\n",
            "Epoch [13/30], Step [730/1250], Loss: 0.2098\n",
            "Epoch [13/30], Step [740/1250], Loss: 0.1333\n",
            "Epoch [13/30], Step [750/1250], Loss: 0.2059\n",
            "Epoch [13/30], Step [760/1250], Loss: 0.1263\n",
            "Epoch [13/30], Step [770/1250], Loss: 0.1420\n",
            "Epoch [13/30], Step [780/1250], Loss: 0.2484\n",
            "Epoch [13/30], Step [790/1250], Loss: 0.2789\n",
            "Epoch [13/30], Step [800/1250], Loss: 0.1439\n",
            "Epoch [13/30], Step [810/1250], Loss: 0.2884\n",
            "Epoch [13/30], Step [820/1250], Loss: 0.1285\n",
            "Epoch [13/30], Step [830/1250], Loss: 0.0798\n",
            "Epoch [13/30], Step [840/1250], Loss: 0.2412\n",
            "Epoch [13/30], Step [850/1250], Loss: 0.2877\n",
            "Epoch [13/30], Step [860/1250], Loss: 0.1601\n",
            "Epoch [13/30], Step [870/1250], Loss: 0.1327\n",
            "Epoch [13/30], Step [880/1250], Loss: 0.1412\n",
            "Epoch [13/30], Step [890/1250], Loss: 0.1378\n",
            "Epoch [13/30], Step [900/1250], Loss: 0.1790\n",
            "Epoch [13/30], Step [910/1250], Loss: 0.3839\n",
            "Epoch [13/30], Step [920/1250], Loss: 0.0933\n",
            "Epoch [13/30], Step [930/1250], Loss: 0.2380\n",
            "Epoch [13/30], Step [940/1250], Loss: 0.1178\n",
            "Epoch [13/30], Step [950/1250], Loss: 0.0644\n",
            "Epoch [13/30], Step [960/1250], Loss: 0.1745\n",
            "Epoch [13/30], Step [970/1250], Loss: 0.2348\n",
            "Epoch [13/30], Step [980/1250], Loss: 0.2745\n",
            "Epoch [13/30], Step [990/1250], Loss: 0.2841\n",
            "Epoch [13/30], Step [1000/1250], Loss: 0.3268\n",
            "Epoch [13/30], Step [1010/1250], Loss: 0.3251\n",
            "Epoch [13/30], Step [1020/1250], Loss: 0.3305\n",
            "Epoch [13/30], Step [1030/1250], Loss: 0.4005\n",
            "Epoch [13/30], Step [1040/1250], Loss: 0.2982\n",
            "Epoch [13/30], Step [1050/1250], Loss: 0.2005\n",
            "Epoch [13/30], Step [1060/1250], Loss: 0.1698\n",
            "Epoch [13/30], Step [1070/1250], Loss: 0.2597\n",
            "Epoch [13/30], Step [1080/1250], Loss: 0.2548\n",
            "Epoch [13/30], Step [1090/1250], Loss: 0.0866\n",
            "Epoch [13/30], Step [1100/1250], Loss: 0.2014\n",
            "Epoch [13/30], Step [1110/1250], Loss: 0.2210\n",
            "Epoch [13/30], Step [1120/1250], Loss: 0.4107\n",
            "Epoch [13/30], Step [1130/1250], Loss: 0.2550\n",
            "Epoch [13/30], Step [1140/1250], Loss: 0.1736\n",
            "Epoch [13/30], Step [1150/1250], Loss: 0.1819\n",
            "Epoch [13/30], Step [1160/1250], Loss: 0.0765\n",
            "Epoch [13/30], Step [1170/1250], Loss: 0.1480\n",
            "Epoch [13/30], Step [1180/1250], Loss: 0.3932\n",
            "Epoch [13/30], Step [1190/1250], Loss: 0.0589\n",
            "Epoch [13/30], Step [1200/1250], Loss: 0.1871\n",
            "Epoch [13/30], Step [1210/1250], Loss: 0.0856\n",
            "Epoch [13/30], Step [1220/1250], Loss: 0.2452\n",
            "Epoch [13/30], Step [1230/1250], Loss: 0.1361\n",
            "Epoch [13/30], Step [1240/1250], Loss: 0.3585\n",
            "Epoch [13/30], Step [1250/1250], Loss: 0.2237\n",
            "Epoch [14/30], Step [10/1250], Loss: 0.3095\n",
            "Epoch [14/30], Step [20/1250], Loss: 0.2429\n",
            "Epoch [14/30], Step [30/1250], Loss: 0.1032\n",
            "Epoch [14/30], Step [40/1250], Loss: 0.1923\n",
            "Epoch [14/30], Step [50/1250], Loss: 0.0436\n",
            "Epoch [14/30], Step [60/1250], Loss: 0.1006\n",
            "Epoch [14/30], Step [70/1250], Loss: 0.0995\n",
            "Epoch [14/30], Step [80/1250], Loss: 0.0345\n",
            "Epoch [14/30], Step [90/1250], Loss: 0.1774\n",
            "Epoch [14/30], Step [100/1250], Loss: 0.2419\n",
            "Epoch [14/30], Step [110/1250], Loss: 0.2086\n",
            "Epoch [14/30], Step [120/1250], Loss: 0.1807\n",
            "Epoch [14/30], Step [130/1250], Loss: 0.1789\n",
            "Epoch [14/30], Step [140/1250], Loss: 0.0938\n",
            "Epoch [14/30], Step [150/1250], Loss: 0.1634\n",
            "Epoch [14/30], Step [160/1250], Loss: 0.2425\n",
            "Epoch [14/30], Step [170/1250], Loss: 0.3234\n",
            "Epoch [14/30], Step [180/1250], Loss: 0.2175\n",
            "Epoch [14/30], Step [190/1250], Loss: 0.1081\n",
            "Epoch [14/30], Step [200/1250], Loss: 0.1221\n",
            "Epoch [14/30], Step [210/1250], Loss: 0.2989\n",
            "Epoch [14/30], Step [220/1250], Loss: 0.1633\n",
            "Epoch [14/30], Step [230/1250], Loss: 0.0740\n",
            "Epoch [14/30], Step [240/1250], Loss: 0.1953\n",
            "Epoch [14/30], Step [250/1250], Loss: 0.1650\n",
            "Epoch [14/30], Step [260/1250], Loss: 0.2277\n",
            "Epoch [14/30], Step [270/1250], Loss: 0.1007\n",
            "Epoch [14/30], Step [280/1250], Loss: 0.0493\n",
            "Epoch [14/30], Step [290/1250], Loss: 0.1437\n",
            "Epoch [14/30], Step [300/1250], Loss: 0.3157\n",
            "Epoch [14/30], Step [310/1250], Loss: 0.1392\n",
            "Epoch [14/30], Step [320/1250], Loss: 0.0269\n",
            "Epoch [14/30], Step [330/1250], Loss: 0.1545\n",
            "Epoch [14/30], Step [340/1250], Loss: 0.1545\n",
            "Epoch [14/30], Step [350/1250], Loss: 0.0834\n",
            "Epoch [14/30], Step [360/1250], Loss: 0.0534\n",
            "Epoch [14/30], Step [370/1250], Loss: 0.0362\n",
            "Epoch [14/30], Step [380/1250], Loss: 0.1857\n",
            "Epoch [14/30], Step [390/1250], Loss: 0.0429\n",
            "Epoch [14/30], Step [400/1250], Loss: 0.1517\n",
            "Epoch [14/30], Step [410/1250], Loss: 0.0857\n",
            "Epoch [14/30], Step [420/1250], Loss: 0.0306\n",
            "Epoch [14/30], Step [430/1250], Loss: 0.3992\n",
            "Epoch [14/30], Step [440/1250], Loss: 0.0987\n",
            "Epoch [14/30], Step [450/1250], Loss: 0.1396\n",
            "Epoch [14/30], Step [460/1250], Loss: 0.0657\n",
            "Epoch [14/30], Step [470/1250], Loss: 0.2877\n",
            "Epoch [14/30], Step [480/1250], Loss: 0.1229\n",
            "Epoch [14/30], Step [490/1250], Loss: 0.1679\n",
            "Epoch [14/30], Step [500/1250], Loss: 0.0849\n",
            "Epoch [14/30], Step [510/1250], Loss: 0.1527\n",
            "Epoch [14/30], Step [520/1250], Loss: 0.1669\n",
            "Epoch [14/30], Step [530/1250], Loss: 0.1147\n",
            "Epoch [14/30], Step [540/1250], Loss: 0.2081\n",
            "Epoch [14/30], Step [550/1250], Loss: 0.2277\n",
            "Epoch [14/30], Step [560/1250], Loss: 0.1213\n",
            "Epoch [14/30], Step [570/1250], Loss: 0.0958\n",
            "Epoch [14/30], Step [580/1250], Loss: 0.2304\n",
            "Epoch [14/30], Step [590/1250], Loss: 0.1902\n",
            "Epoch [14/30], Step [600/1250], Loss: 0.1433\n",
            "Epoch [14/30], Step [610/1250], Loss: 0.0841\n",
            "Epoch [14/30], Step [620/1250], Loss: 0.1056\n",
            "Epoch [14/30], Step [630/1250], Loss: 0.1454\n",
            "Epoch [14/30], Step [640/1250], Loss: 0.2390\n",
            "Epoch [14/30], Step [650/1250], Loss: 0.1254\n",
            "Epoch [14/30], Step [660/1250], Loss: 0.1254\n",
            "Epoch [14/30], Step [670/1250], Loss: 0.0715\n",
            "Epoch [14/30], Step [680/1250], Loss: 0.2718\n",
            "Epoch [14/30], Step [690/1250], Loss: 0.0935\n",
            "Epoch [14/30], Step [700/1250], Loss: 0.1588\n",
            "Epoch [14/30], Step [710/1250], Loss: 0.0687\n",
            "Epoch [14/30], Step [720/1250], Loss: 0.3689\n",
            "Epoch [14/30], Step [730/1250], Loss: 0.2771\n",
            "Epoch [14/30], Step [740/1250], Loss: 0.0462\n",
            "Epoch [14/30], Step [750/1250], Loss: 0.2030\n",
            "Epoch [14/30], Step [760/1250], Loss: 0.1889\n",
            "Epoch [14/30], Step [770/1250], Loss: 0.0865\n",
            "Epoch [14/30], Step [780/1250], Loss: 0.0962\n",
            "Epoch [14/30], Step [790/1250], Loss: 0.1586\n",
            "Epoch [14/30], Step [800/1250], Loss: 0.2478\n",
            "Epoch [14/30], Step [810/1250], Loss: 0.1492\n",
            "Epoch [14/30], Step [820/1250], Loss: 0.1355\n",
            "Epoch [14/30], Step [830/1250], Loss: 0.1141\n",
            "Epoch [14/30], Step [840/1250], Loss: 0.0808\n",
            "Epoch [14/30], Step [850/1250], Loss: 0.1691\n",
            "Epoch [14/30], Step [860/1250], Loss: 0.0394\n",
            "Epoch [14/30], Step [870/1250], Loss: 0.0586\n",
            "Epoch [14/30], Step [880/1250], Loss: 0.1141\n",
            "Epoch [14/30], Step [890/1250], Loss: 0.0725\n",
            "Epoch [14/30], Step [900/1250], Loss: 0.1628\n",
            "Epoch [14/30], Step [910/1250], Loss: 0.1345\n",
            "Epoch [14/30], Step [920/1250], Loss: 0.1639\n",
            "Epoch [14/30], Step [930/1250], Loss: 0.0778\n",
            "Epoch [14/30], Step [940/1250], Loss: 0.1160\n",
            "Epoch [14/30], Step [950/1250], Loss: 0.1439\n",
            "Epoch [14/30], Step [960/1250], Loss: 0.1736\n",
            "Epoch [14/30], Step [970/1250], Loss: 0.1783\n",
            "Epoch [14/30], Step [980/1250], Loss: 0.1335\n",
            "Epoch [14/30], Step [990/1250], Loss: 0.1794\n",
            "Epoch [14/30], Step [1000/1250], Loss: 0.0750\n",
            "Epoch [14/30], Step [1010/1250], Loss: 0.2356\n",
            "Epoch [14/30], Step [1020/1250], Loss: 0.2260\n",
            "Epoch [14/30], Step [1030/1250], Loss: 0.0529\n",
            "Epoch [14/30], Step [1040/1250], Loss: 0.1760\n",
            "Epoch [14/30], Step [1050/1250], Loss: 0.1212\n",
            "Epoch [14/30], Step [1060/1250], Loss: 0.3249\n",
            "Epoch [14/30], Step [1070/1250], Loss: 0.2185\n",
            "Epoch [14/30], Step [1080/1250], Loss: 0.0943\n",
            "Epoch [14/30], Step [1090/1250], Loss: 0.1754\n",
            "Epoch [14/30], Step [1100/1250], Loss: 0.1276\n",
            "Epoch [14/30], Step [1110/1250], Loss: 0.0573\n",
            "Epoch [14/30], Step [1120/1250], Loss: 0.1299\n",
            "Epoch [14/30], Step [1130/1250], Loss: 0.1764\n",
            "Epoch [14/30], Step [1140/1250], Loss: 0.2087\n",
            "Epoch [14/30], Step [1150/1250], Loss: 0.2946\n",
            "Epoch [14/30], Step [1160/1250], Loss: 0.3637\n",
            "Epoch [14/30], Step [1170/1250], Loss: 0.1378\n",
            "Epoch [14/30], Step [1180/1250], Loss: 0.2070\n",
            "Epoch [14/30], Step [1190/1250], Loss: 0.1132\n",
            "Epoch [14/30], Step [1200/1250], Loss: 0.3709\n",
            "Epoch [14/30], Step [1210/1250], Loss: 0.3634\n",
            "Epoch [14/30], Step [1220/1250], Loss: 0.1127\n",
            "Epoch [14/30], Step [1230/1250], Loss: 0.0619\n",
            "Epoch [14/30], Step [1240/1250], Loss: 0.0957\n",
            "Epoch [14/30], Step [1250/1250], Loss: 0.0448\n",
            "Epoch [15/30], Step [10/1250], Loss: 0.2174\n",
            "Epoch [15/30], Step [20/1250], Loss: 0.0853\n",
            "Epoch [15/30], Step [30/1250], Loss: 0.0413\n",
            "Epoch [15/30], Step [40/1250], Loss: 0.0367\n",
            "Epoch [15/30], Step [50/1250], Loss: 0.0248\n",
            "Epoch [15/30], Step [60/1250], Loss: 0.1300\n",
            "Epoch [15/30], Step [70/1250], Loss: 0.1988\n",
            "Epoch [15/30], Step [80/1250], Loss: 0.1722\n",
            "Epoch [15/30], Step [90/1250], Loss: 0.3067\n",
            "Epoch [15/30], Step [100/1250], Loss: 0.1701\n",
            "Epoch [15/30], Step [110/1250], Loss: 0.1215\n",
            "Epoch [15/30], Step [120/1250], Loss: 0.0348\n",
            "Epoch [15/30], Step [130/1250], Loss: 0.0573\n",
            "Epoch [15/30], Step [140/1250], Loss: 0.1329\n",
            "Epoch [15/30], Step [150/1250], Loss: 0.0743\n",
            "Epoch [15/30], Step [160/1250], Loss: 0.1329\n",
            "Epoch [15/30], Step [170/1250], Loss: 0.1791\n",
            "Epoch [15/30], Step [180/1250], Loss: 0.3167\n",
            "Epoch [15/30], Step [190/1250], Loss: 0.0987\n",
            "Epoch [15/30], Step [200/1250], Loss: 0.1378\n",
            "Epoch [15/30], Step [210/1250], Loss: 0.1307\n",
            "Epoch [15/30], Step [220/1250], Loss: 0.0829\n",
            "Epoch [15/30], Step [230/1250], Loss: 0.0914\n",
            "Epoch [15/30], Step [240/1250], Loss: 0.1025\n",
            "Epoch [15/30], Step [250/1250], Loss: 0.0864\n",
            "Epoch [15/30], Step [260/1250], Loss: 0.0601\n",
            "Epoch [15/30], Step [270/1250], Loss: 0.0686\n",
            "Epoch [15/30], Step [280/1250], Loss: 0.0284\n",
            "Epoch [15/30], Step [290/1250], Loss: 0.0691\n",
            "Epoch [15/30], Step [300/1250], Loss: 0.0442\n",
            "Epoch [15/30], Step [310/1250], Loss: 0.1238\n",
            "Epoch [15/30], Step [320/1250], Loss: 0.0329\n",
            "Epoch [15/30], Step [330/1250], Loss: 0.0189\n",
            "Epoch [15/30], Step [340/1250], Loss: 0.2399\n",
            "Epoch [15/30], Step [350/1250], Loss: 0.1512\n",
            "Epoch [15/30], Step [360/1250], Loss: 0.1207\n",
            "Epoch [15/30], Step [370/1250], Loss: 0.3099\n",
            "Epoch [15/30], Step [380/1250], Loss: 0.2462\n",
            "Epoch [15/30], Step [390/1250], Loss: 0.1782\n",
            "Epoch [15/30], Step [400/1250], Loss: 0.1335\n",
            "Epoch [15/30], Step [410/1250], Loss: 0.0176\n",
            "Epoch [15/30], Step [420/1250], Loss: 0.1089\n",
            "Epoch [15/30], Step [430/1250], Loss: 0.2111\n",
            "Epoch [15/30], Step [440/1250], Loss: 0.0859\n",
            "Epoch [15/30], Step [450/1250], Loss: 0.0828\n",
            "Epoch [15/30], Step [460/1250], Loss: 0.0929\n",
            "Epoch [15/30], Step [470/1250], Loss: 0.1275\n",
            "Epoch [15/30], Step [480/1250], Loss: 0.2825\n",
            "Epoch [15/30], Step [490/1250], Loss: 0.0933\n",
            "Epoch [15/30], Step [500/1250], Loss: 0.0412\n",
            "Epoch [15/30], Step [510/1250], Loss: 0.0840\n",
            "Epoch [15/30], Step [520/1250], Loss: 0.0807\n",
            "Epoch [15/30], Step [530/1250], Loss: 0.1109\n",
            "Epoch [15/30], Step [540/1250], Loss: 0.0713\n",
            "Epoch [15/30], Step [550/1250], Loss: 0.0248\n",
            "Epoch [15/30], Step [560/1250], Loss: 0.0531\n",
            "Epoch [15/30], Step [570/1250], Loss: 0.0331\n",
            "Epoch [15/30], Step [580/1250], Loss: 0.0912\n",
            "Epoch [15/30], Step [590/1250], Loss: 0.0433\n",
            "Epoch [15/30], Step [600/1250], Loss: 0.0535\n",
            "Epoch [15/30], Step [610/1250], Loss: 0.3969\n",
            "Epoch [15/30], Step [620/1250], Loss: 0.0896\n",
            "Epoch [15/30], Step [630/1250], Loss: 0.1343\n",
            "Epoch [15/30], Step [640/1250], Loss: 0.0819\n",
            "Epoch [15/30], Step [650/1250], Loss: 0.1203\n",
            "Epoch [15/30], Step [660/1250], Loss: 0.1934\n",
            "Epoch [15/30], Step [670/1250], Loss: 0.1136\n",
            "Epoch [15/30], Step [680/1250], Loss: 0.0931\n",
            "Epoch [15/30], Step [690/1250], Loss: 0.1932\n",
            "Epoch [15/30], Step [700/1250], Loss: 0.0784\n",
            "Epoch [15/30], Step [710/1250], Loss: 0.1414\n",
            "Epoch [15/30], Step [720/1250], Loss: 0.0936\n",
            "Epoch [15/30], Step [730/1250], Loss: 0.1108\n",
            "Epoch [15/30], Step [740/1250], Loss: 0.0768\n",
            "Epoch [15/30], Step [750/1250], Loss: 0.0980\n",
            "Epoch [15/30], Step [760/1250], Loss: 0.1372\n",
            "Epoch [15/30], Step [770/1250], Loss: 0.0966\n",
            "Epoch [15/30], Step [780/1250], Loss: 0.1295\n",
            "Epoch [15/30], Step [790/1250], Loss: 0.0310\n",
            "Epoch [15/30], Step [800/1250], Loss: 0.1163\n",
            "Epoch [15/30], Step [810/1250], Loss: 0.0912\n",
            "Epoch [15/30], Step [820/1250], Loss: 0.2761\n",
            "Epoch [15/30], Step [830/1250], Loss: 0.2120\n",
            "Epoch [15/30], Step [840/1250], Loss: 0.1464\n",
            "Epoch [15/30], Step [850/1250], Loss: 0.1403\n",
            "Epoch [15/30], Step [860/1250], Loss: 0.1356\n",
            "Epoch [15/30], Step [870/1250], Loss: 0.2276\n",
            "Epoch [15/30], Step [880/1250], Loss: 0.2313\n",
            "Epoch [15/30], Step [890/1250], Loss: 0.0229\n",
            "Epoch [15/30], Step [900/1250], Loss: 0.2097\n",
            "Epoch [15/30], Step [910/1250], Loss: 0.2894\n",
            "Epoch [15/30], Step [920/1250], Loss: 0.1006\n",
            "Epoch [15/30], Step [930/1250], Loss: 0.0996\n",
            "Epoch [15/30], Step [940/1250], Loss: 0.0677\n",
            "Epoch [15/30], Step [950/1250], Loss: 0.1115\n",
            "Epoch [15/30], Step [960/1250], Loss: 0.2227\n",
            "Epoch [15/30], Step [970/1250], Loss: 0.0393\n",
            "Epoch [15/30], Step [980/1250], Loss: 0.0398\n",
            "Epoch [15/30], Step [990/1250], Loss: 0.1942\n",
            "Epoch [15/30], Step [1000/1250], Loss: 0.0878\n",
            "Epoch [15/30], Step [1010/1250], Loss: 0.0321\n",
            "Epoch [15/30], Step [1020/1250], Loss: 0.2085\n",
            "Epoch [15/30], Step [1030/1250], Loss: 0.1152\n",
            "Epoch [15/30], Step [1040/1250], Loss: 0.1021\n",
            "Epoch [15/30], Step [1050/1250], Loss: 0.0599\n",
            "Epoch [15/30], Step [1060/1250], Loss: 0.0514\n",
            "Epoch [15/30], Step [1070/1250], Loss: 0.1589\n",
            "Epoch [15/30], Step [1080/1250], Loss: 0.0489\n",
            "Epoch [15/30], Step [1090/1250], Loss: 0.1124\n",
            "Epoch [15/30], Step [1100/1250], Loss: 0.2703\n",
            "Epoch [15/30], Step [1110/1250], Loss: 0.1190\n",
            "Epoch [15/30], Step [1120/1250], Loss: 0.1155\n",
            "Epoch [15/30], Step [1130/1250], Loss: 0.1128\n",
            "Epoch [15/30], Step [1140/1250], Loss: 0.2875\n",
            "Epoch [15/30], Step [1150/1250], Loss: 0.0528\n",
            "Epoch [15/30], Step [1160/1250], Loss: 0.1174\n",
            "Epoch [15/30], Step [1170/1250], Loss: 0.1490\n",
            "Epoch [15/30], Step [1180/1250], Loss: 0.0375\n",
            "Epoch [15/30], Step [1190/1250], Loss: 0.2014\n",
            "Epoch [15/30], Step [1200/1250], Loss: 0.1048\n",
            "Epoch [15/30], Step [1210/1250], Loss: 0.1144\n",
            "Epoch [15/30], Step [1220/1250], Loss: 0.1754\n",
            "Epoch [15/30], Step [1230/1250], Loss: 0.1294\n",
            "Epoch [15/30], Step [1240/1250], Loss: 0.1493\n",
            "Epoch [15/30], Step [1250/1250], Loss: 0.2256\n",
            "Epoch [16/30], Step [10/1250], Loss: 0.0570\n",
            "Epoch [16/30], Step [20/1250], Loss: 0.0088\n",
            "Epoch [16/30], Step [30/1250], Loss: 0.0562\n",
            "Epoch [16/30], Step [40/1250], Loss: 0.3068\n",
            "Epoch [16/30], Step [50/1250], Loss: 0.0478\n",
            "Epoch [16/30], Step [60/1250], Loss: 0.0839\n",
            "Epoch [16/30], Step [70/1250], Loss: 0.1311\n",
            "Epoch [16/30], Step [80/1250], Loss: 0.0412\n",
            "Epoch [16/30], Step [90/1250], Loss: 0.0420\n",
            "Epoch [16/30], Step [100/1250], Loss: 0.0993\n",
            "Epoch [16/30], Step [110/1250], Loss: 0.1004\n",
            "Epoch [16/30], Step [120/1250], Loss: 0.0629\n",
            "Epoch [16/30], Step [130/1250], Loss: 0.0551\n",
            "Epoch [16/30], Step [140/1250], Loss: 0.1228\n",
            "Epoch [16/30], Step [150/1250], Loss: 0.2222\n",
            "Epoch [16/30], Step [160/1250], Loss: 0.0982\n",
            "Epoch [16/30], Step [170/1250], Loss: 0.0455\n",
            "Epoch [16/30], Step [180/1250], Loss: 0.0069\n",
            "Epoch [16/30], Step [190/1250], Loss: 0.0976\n",
            "Epoch [16/30], Step [200/1250], Loss: 0.0814\n",
            "Epoch [16/30], Step [210/1250], Loss: 0.0222\n",
            "Epoch [16/30], Step [220/1250], Loss: 0.1072\n",
            "Epoch [16/30], Step [230/1250], Loss: 0.1756\n",
            "Epoch [16/30], Step [240/1250], Loss: 0.0559\n",
            "Epoch [16/30], Step [250/1250], Loss: 0.1438\n",
            "Epoch [16/30], Step [260/1250], Loss: 0.0608\n",
            "Epoch [16/30], Step [270/1250], Loss: 0.0995\n",
            "Epoch [16/30], Step [280/1250], Loss: 0.0172\n",
            "Epoch [16/30], Step [290/1250], Loss: 0.0908\n",
            "Epoch [16/30], Step [300/1250], Loss: 0.0978\n",
            "Epoch [16/30], Step [310/1250], Loss: 0.0652\n",
            "Epoch [16/30], Step [320/1250], Loss: 0.0485\n",
            "Epoch [16/30], Step [330/1250], Loss: 0.0314\n",
            "Epoch [16/30], Step [340/1250], Loss: 0.2861\n",
            "Epoch [16/30], Step [350/1250], Loss: 0.1997\n",
            "Epoch [16/30], Step [360/1250], Loss: 0.2383\n",
            "Epoch [16/30], Step [370/1250], Loss: 0.0850\n",
            "Epoch [16/30], Step [380/1250], Loss: 0.0671\n",
            "Epoch [16/30], Step [390/1250], Loss: 0.1213\n",
            "Epoch [16/30], Step [400/1250], Loss: 0.1560\n",
            "Epoch [16/30], Step [410/1250], Loss: 0.0451\n",
            "Epoch [16/30], Step [420/1250], Loss: 0.0765\n",
            "Epoch [16/30], Step [430/1250], Loss: 0.0676\n",
            "Epoch [16/30], Step [440/1250], Loss: 0.2076\n",
            "Epoch [16/30], Step [450/1250], Loss: 0.2080\n",
            "Epoch [16/30], Step [460/1250], Loss: 0.0389\n",
            "Epoch [16/30], Step [470/1250], Loss: 0.0211\n",
            "Epoch [16/30], Step [480/1250], Loss: 0.0541\n",
            "Epoch [16/30], Step [490/1250], Loss: 0.2830\n",
            "Epoch [16/30], Step [500/1250], Loss: 0.0796\n",
            "Epoch [16/30], Step [510/1250], Loss: 0.1463\n",
            "Epoch [16/30], Step [520/1250], Loss: 0.1265\n",
            "Epoch [16/30], Step [530/1250], Loss: 0.0282\n",
            "Epoch [16/30], Step [540/1250], Loss: 0.0882\n",
            "Epoch [16/30], Step [550/1250], Loss: 0.1766\n",
            "Epoch [16/30], Step [560/1250], Loss: 0.0655\n",
            "Epoch [16/30], Step [570/1250], Loss: 0.1198\n",
            "Epoch [16/30], Step [580/1250], Loss: 0.1025\n",
            "Epoch [16/30], Step [590/1250], Loss: 0.0939\n",
            "Epoch [16/30], Step [600/1250], Loss: 0.1405\n",
            "Epoch [16/30], Step [610/1250], Loss: 0.2268\n",
            "Epoch [16/30], Step [620/1250], Loss: 0.1339\n",
            "Epoch [16/30], Step [630/1250], Loss: 0.1948\n",
            "Epoch [16/30], Step [640/1250], Loss: 0.1155\n",
            "Epoch [16/30], Step [650/1250], Loss: 0.1296\n",
            "Epoch [16/30], Step [660/1250], Loss: 0.0244\n",
            "Epoch [16/30], Step [670/1250], Loss: 0.0907\n",
            "Epoch [16/30], Step [680/1250], Loss: 0.1497\n",
            "Epoch [16/30], Step [690/1250], Loss: 0.1406\n",
            "Epoch [16/30], Step [700/1250], Loss: 0.0351\n",
            "Epoch [16/30], Step [710/1250], Loss: 0.1449\n",
            "Epoch [16/30], Step [720/1250], Loss: 0.0131\n",
            "Epoch [16/30], Step [730/1250], Loss: 0.1394\n",
            "Epoch [16/30], Step [740/1250], Loss: 0.3211\n",
            "Epoch [16/30], Step [750/1250], Loss: 0.1074\n",
            "Epoch [16/30], Step [760/1250], Loss: 0.1206\n",
            "Epoch [16/30], Step [770/1250], Loss: 0.0581\n",
            "Epoch [16/30], Step [780/1250], Loss: 0.0193\n",
            "Epoch [16/30], Step [790/1250], Loss: 0.0605\n",
            "Epoch [16/30], Step [800/1250], Loss: 0.0747\n",
            "Epoch [16/30], Step [810/1250], Loss: 0.1172\n",
            "Epoch [16/30], Step [820/1250], Loss: 0.0357\n",
            "Epoch [16/30], Step [830/1250], Loss: 0.2528\n",
            "Epoch [16/30], Step [840/1250], Loss: 0.0965\n",
            "Epoch [16/30], Step [850/1250], Loss: 0.1065\n",
            "Epoch [16/30], Step [860/1250], Loss: 0.0219\n",
            "Epoch [16/30], Step [870/1250], Loss: 0.0890\n",
            "Epoch [16/30], Step [880/1250], Loss: 0.0982\n",
            "Epoch [16/30], Step [890/1250], Loss: 0.0701\n",
            "Epoch [16/30], Step [900/1250], Loss: 0.0615\n",
            "Epoch [16/30], Step [910/1250], Loss: 0.0680\n",
            "Epoch [16/30], Step [920/1250], Loss: 0.0717\n",
            "Epoch [16/30], Step [930/1250], Loss: 0.0476\n",
            "Epoch [16/30], Step [940/1250], Loss: 0.1648\n",
            "Epoch [16/30], Step [950/1250], Loss: 0.0368\n",
            "Epoch [16/30], Step [960/1250], Loss: 0.1398\n",
            "Epoch [16/30], Step [970/1250], Loss: 0.1078\n",
            "Epoch [16/30], Step [980/1250], Loss: 0.0982\n",
            "Epoch [16/30], Step [990/1250], Loss: 0.1125\n",
            "Epoch [16/30], Step [1000/1250], Loss: 0.0393\n",
            "Epoch [16/30], Step [1010/1250], Loss: 0.1800\n",
            "Epoch [16/30], Step [1020/1250], Loss: 0.2061\n",
            "Epoch [16/30], Step [1030/1250], Loss: 0.1366\n",
            "Epoch [16/30], Step [1040/1250], Loss: 0.1526\n",
            "Epoch [16/30], Step [1050/1250], Loss: 0.0120\n",
            "Epoch [16/30], Step [1060/1250], Loss: 0.0312\n",
            "Epoch [16/30], Step [1070/1250], Loss: 0.1625\n",
            "Epoch [16/30], Step [1080/1250], Loss: 0.0761\n",
            "Epoch [16/30], Step [1090/1250], Loss: 0.1226\n",
            "Epoch [16/30], Step [1100/1250], Loss: 0.0812\n",
            "Epoch [16/30], Step [1110/1250], Loss: 0.0827\n",
            "Epoch [16/30], Step [1120/1250], Loss: 0.0762\n",
            "Epoch [16/30], Step [1130/1250], Loss: 0.1671\n",
            "Epoch [16/30], Step [1140/1250], Loss: 0.2122\n",
            "Epoch [16/30], Step [1150/1250], Loss: 0.0594\n",
            "Epoch [16/30], Step [1160/1250], Loss: 0.0964\n",
            "Epoch [16/30], Step [1170/1250], Loss: 0.1254\n",
            "Epoch [16/30], Step [1180/1250], Loss: 0.1116\n",
            "Epoch [16/30], Step [1190/1250], Loss: 0.0572\n",
            "Epoch [16/30], Step [1200/1250], Loss: 0.1486\n",
            "Epoch [16/30], Step [1210/1250], Loss: 0.0501\n",
            "Epoch [16/30], Step [1220/1250], Loss: 0.2229\n",
            "Epoch [16/30], Step [1230/1250], Loss: 0.0531\n",
            "Epoch [16/30], Step [1240/1250], Loss: 0.0257\n",
            "Epoch [16/30], Step [1250/1250], Loss: 0.1377\n",
            "Epoch [17/30], Step [10/1250], Loss: 0.0746\n",
            "Epoch [17/30], Step [20/1250], Loss: 0.0310\n",
            "Epoch [17/30], Step [30/1250], Loss: 0.0197\n",
            "Epoch [17/30], Step [40/1250], Loss: 0.0385\n",
            "Epoch [17/30], Step [50/1250], Loss: 0.0791\n",
            "Epoch [17/30], Step [60/1250], Loss: 0.0118\n",
            "Epoch [17/30], Step [70/1250], Loss: 0.0274\n",
            "Epoch [17/30], Step [80/1250], Loss: 0.0148\n",
            "Epoch [17/30], Step [90/1250], Loss: 0.0888\n",
            "Epoch [17/30], Step [100/1250], Loss: 0.0597\n",
            "Epoch [17/30], Step [110/1250], Loss: 0.0495\n",
            "Epoch [17/30], Step [120/1250], Loss: 0.0200\n",
            "Epoch [17/30], Step [130/1250], Loss: 0.2162\n",
            "Epoch [17/30], Step [140/1250], Loss: 0.1091\n",
            "Epoch [17/30], Step [150/1250], Loss: 0.0575\n",
            "Epoch [17/30], Step [160/1250], Loss: 0.0837\n",
            "Epoch [17/30], Step [170/1250], Loss: 0.0129\n",
            "Epoch [17/30], Step [180/1250], Loss: 0.0546\n",
            "Epoch [17/30], Step [190/1250], Loss: 0.0228\n",
            "Epoch [17/30], Step [200/1250], Loss: 0.0214\n",
            "Epoch [17/30], Step [210/1250], Loss: 0.0351\n",
            "Epoch [17/30], Step [220/1250], Loss: 0.0142\n",
            "Epoch [17/30], Step [230/1250], Loss: 0.0322\n",
            "Epoch [17/30], Step [240/1250], Loss: 0.1089\n",
            "Epoch [17/30], Step [250/1250], Loss: 0.0308\n",
            "Epoch [17/30], Step [260/1250], Loss: 0.0661\n",
            "Epoch [17/30], Step [270/1250], Loss: 0.0823\n",
            "Epoch [17/30], Step [280/1250], Loss: 0.0212\n",
            "Epoch [17/30], Step [290/1250], Loss: 0.0142\n",
            "Epoch [17/30], Step [300/1250], Loss: 0.0583\n",
            "Epoch [17/30], Step [310/1250], Loss: 0.0194\n",
            "Epoch [17/30], Step [320/1250], Loss: 0.0345\n",
            "Epoch [17/30], Step [330/1250], Loss: 0.0284\n",
            "Epoch [17/30], Step [340/1250], Loss: 0.4809\n",
            "Epoch [17/30], Step [350/1250], Loss: 0.0688\n",
            "Epoch [17/30], Step [360/1250], Loss: 0.0870\n",
            "Epoch [17/30], Step [370/1250], Loss: 0.0257\n",
            "Epoch [17/30], Step [380/1250], Loss: 0.0612\n",
            "Epoch [17/30], Step [390/1250], Loss: 0.0858\n",
            "Epoch [17/30], Step [400/1250], Loss: 0.0410\n",
            "Epoch [17/30], Step [410/1250], Loss: 0.2844\n",
            "Epoch [17/30], Step [420/1250], Loss: 0.0910\n",
            "Epoch [17/30], Step [430/1250], Loss: 0.1928\n",
            "Epoch [17/30], Step [440/1250], Loss: 0.0541\n",
            "Epoch [17/30], Step [450/1250], Loss: 0.0910\n",
            "Epoch [17/30], Step [460/1250], Loss: 0.0591\n",
            "Epoch [17/30], Step [470/1250], Loss: 0.0974\n",
            "Epoch [17/30], Step [480/1250], Loss: 0.1850\n",
            "Epoch [17/30], Step [490/1250], Loss: 0.0397\n",
            "Epoch [17/30], Step [500/1250], Loss: 0.0346\n",
            "Epoch [17/30], Step [510/1250], Loss: 0.0238\n",
            "Epoch [17/30], Step [520/1250], Loss: 0.1696\n",
            "Epoch [17/30], Step [530/1250], Loss: 0.0417\n",
            "Epoch [17/30], Step [540/1250], Loss: 0.1829\n",
            "Epoch [17/30], Step [550/1250], Loss: 0.0080\n",
            "Epoch [17/30], Step [560/1250], Loss: 0.0689\n",
            "Epoch [17/30], Step [570/1250], Loss: 0.1391\n",
            "Epoch [17/30], Step [580/1250], Loss: 0.0704\n",
            "Epoch [17/30], Step [590/1250], Loss: 0.0993\n",
            "Epoch [17/30], Step [600/1250], Loss: 0.2325\n",
            "Epoch [17/30], Step [610/1250], Loss: 0.0557\n",
            "Epoch [17/30], Step [620/1250], Loss: 0.0634\n",
            "Epoch [17/30], Step [630/1250], Loss: 0.0093\n",
            "Epoch [17/30], Step [640/1250], Loss: 0.0552\n",
            "Epoch [17/30], Step [650/1250], Loss: 0.0759\n",
            "Epoch [17/30], Step [660/1250], Loss: 0.0148\n",
            "Epoch [17/30], Step [670/1250], Loss: 0.0895\n",
            "Epoch [17/30], Step [680/1250], Loss: 0.2384\n",
            "Epoch [17/30], Step [690/1250], Loss: 0.1340\n",
            "Epoch [17/30], Step [700/1250], Loss: 0.2824\n",
            "Epoch [17/30], Step [710/1250], Loss: 0.1251\n",
            "Epoch [17/30], Step [720/1250], Loss: 0.0200\n",
            "Epoch [17/30], Step [730/1250], Loss: 0.1019\n",
            "Epoch [17/30], Step [740/1250], Loss: 0.0835\n",
            "Epoch [17/30], Step [750/1250], Loss: 0.0637\n",
            "Epoch [17/30], Step [760/1250], Loss: 0.2476\n",
            "Epoch [17/30], Step [770/1250], Loss: 0.1242\n",
            "Epoch [17/30], Step [780/1250], Loss: 0.0866\n",
            "Epoch [17/30], Step [790/1250], Loss: 0.0940\n",
            "Epoch [17/30], Step [800/1250], Loss: 0.0679\n",
            "Epoch [17/30], Step [810/1250], Loss: 0.0409\n",
            "Epoch [17/30], Step [820/1250], Loss: 0.0961\n",
            "Epoch [17/30], Step [830/1250], Loss: 0.0964\n",
            "Epoch [17/30], Step [840/1250], Loss: 0.1067\n",
            "Epoch [17/30], Step [850/1250], Loss: 0.0495\n",
            "Epoch [17/30], Step [860/1250], Loss: 0.0480\n",
            "Epoch [17/30], Step [870/1250], Loss: 0.0365\n",
            "Epoch [17/30], Step [880/1250], Loss: 0.0603\n",
            "Epoch [17/30], Step [890/1250], Loss: 0.0926\n",
            "Epoch [17/30], Step [900/1250], Loss: 0.0322\n",
            "Epoch [17/30], Step [910/1250], Loss: 0.1515\n",
            "Epoch [17/30], Step [920/1250], Loss: 0.0496\n",
            "Epoch [17/30], Step [930/1250], Loss: 0.0916\n",
            "Epoch [17/30], Step [940/1250], Loss: 0.1829\n",
            "Epoch [17/30], Step [950/1250], Loss: 0.0559\n",
            "Epoch [17/30], Step [960/1250], Loss: 0.1053\n",
            "Epoch [17/30], Step [970/1250], Loss: 0.0256\n",
            "Epoch [17/30], Step [980/1250], Loss: 0.0922\n",
            "Epoch [17/30], Step [990/1250], Loss: 0.0272\n",
            "Epoch [17/30], Step [1000/1250], Loss: 0.0664\n",
            "Epoch [17/30], Step [1010/1250], Loss: 0.0605\n",
            "Epoch [17/30], Step [1020/1250], Loss: 0.1614\n",
            "Epoch [17/30], Step [1030/1250], Loss: 0.0225\n",
            "Epoch [17/30], Step [1040/1250], Loss: 0.1278\n",
            "Epoch [17/30], Step [1050/1250], Loss: 0.0931\n",
            "Epoch [17/30], Step [1060/1250], Loss: 0.0826\n",
            "Epoch [17/30], Step [1070/1250], Loss: 0.2408\n",
            "Epoch [17/30], Step [1080/1250], Loss: 0.0211\n",
            "Epoch [17/30], Step [1090/1250], Loss: 0.0463\n",
            "Epoch [17/30], Step [1100/1250], Loss: 0.1530\n",
            "Epoch [17/30], Step [1110/1250], Loss: 0.1217\n",
            "Epoch [17/30], Step [1120/1250], Loss: 0.0678\n",
            "Epoch [17/30], Step [1130/1250], Loss: 0.0742\n",
            "Epoch [17/30], Step [1140/1250], Loss: 0.1000\n",
            "Epoch [17/30], Step [1150/1250], Loss: 0.2128\n",
            "Epoch [17/30], Step [1160/1250], Loss: 0.0081\n",
            "Epoch [17/30], Step [1170/1250], Loss: 0.0470\n",
            "Epoch [17/30], Step [1180/1250], Loss: 0.0540\n",
            "Epoch [17/30], Step [1190/1250], Loss: 0.1218\n",
            "Epoch [17/30], Step [1200/1250], Loss: 0.0607\n",
            "Epoch [17/30], Step [1210/1250], Loss: 0.1058\n",
            "Epoch [17/30], Step [1220/1250], Loss: 0.0753\n",
            "Epoch [17/30], Step [1230/1250], Loss: 0.2212\n",
            "Epoch [17/30], Step [1240/1250], Loss: 0.1145\n",
            "Epoch [17/30], Step [1250/1250], Loss: 0.0243\n",
            "Epoch [18/30], Step [10/1250], Loss: 0.1094\n",
            "Epoch [18/30], Step [20/1250], Loss: 0.0719\n",
            "Epoch [18/30], Step [30/1250], Loss: 0.1426\n",
            "Epoch [18/30], Step [40/1250], Loss: 0.0316\n",
            "Epoch [18/30], Step [50/1250], Loss: 0.1036\n",
            "Epoch [18/30], Step [60/1250], Loss: 0.0836\n",
            "Epoch [18/30], Step [70/1250], Loss: 0.0574\n",
            "Epoch [18/30], Step [80/1250], Loss: 0.0423\n",
            "Epoch [18/30], Step [90/1250], Loss: 0.0254\n",
            "Epoch [18/30], Step [100/1250], Loss: 0.0387\n",
            "Epoch [18/30], Step [110/1250], Loss: 0.0947\n",
            "Epoch [18/30], Step [120/1250], Loss: 0.0292\n",
            "Epoch [18/30], Step [130/1250], Loss: 0.0322\n",
            "Epoch [18/30], Step [140/1250], Loss: 0.0191\n",
            "Epoch [18/30], Step [150/1250], Loss: 0.1487\n",
            "Epoch [18/30], Step [160/1250], Loss: 0.0480\n",
            "Epoch [18/30], Step [170/1250], Loss: 0.1687\n",
            "Epoch [18/30], Step [180/1250], Loss: 0.0316\n",
            "Epoch [18/30], Step [190/1250], Loss: 0.1037\n",
            "Epoch [18/30], Step [200/1250], Loss: 0.0982\n",
            "Epoch [18/30], Step [210/1250], Loss: 0.1126\n",
            "Epoch [18/30], Step [220/1250], Loss: 0.0774\n",
            "Epoch [18/30], Step [230/1250], Loss: 0.1488\n",
            "Epoch [18/30], Step [240/1250], Loss: 0.0130\n",
            "Epoch [18/30], Step [250/1250], Loss: 0.0211\n",
            "Epoch [18/30], Step [260/1250], Loss: 0.0289\n",
            "Epoch [18/30], Step [270/1250], Loss: 0.1107\n",
            "Epoch [18/30], Step [280/1250], Loss: 0.0073\n",
            "Epoch [18/30], Step [290/1250], Loss: 0.0179\n",
            "Epoch [18/30], Step [300/1250], Loss: 0.0467\n",
            "Epoch [18/30], Step [310/1250], Loss: 0.0144\n",
            "Epoch [18/30], Step [320/1250], Loss: 0.0483\n",
            "Epoch [18/30], Step [330/1250], Loss: 0.1500\n",
            "Epoch [18/30], Step [340/1250], Loss: 0.1227\n",
            "Epoch [18/30], Step [350/1250], Loss: 0.0287\n",
            "Epoch [18/30], Step [360/1250], Loss: 0.1083\n",
            "Epoch [18/30], Step [370/1250], Loss: 0.0169\n",
            "Epoch [18/30], Step [380/1250], Loss: 0.0181\n",
            "Epoch [18/30], Step [390/1250], Loss: 0.1343\n",
            "Epoch [18/30], Step [400/1250], Loss: 0.0134\n",
            "Epoch [18/30], Step [410/1250], Loss: 0.0226\n",
            "Epoch [18/30], Step [420/1250], Loss: 0.1244\n",
            "Epoch [18/30], Step [430/1250], Loss: 0.0426\n",
            "Epoch [18/30], Step [440/1250], Loss: 0.0225\n",
            "Epoch [18/30], Step [450/1250], Loss: 0.0828\n",
            "Epoch [18/30], Step [460/1250], Loss: 0.0197\n",
            "Epoch [18/30], Step [470/1250], Loss: 0.0591\n",
            "Epoch [18/30], Step [480/1250], Loss: 0.0661\n",
            "Epoch [18/30], Step [490/1250], Loss: 0.0303\n",
            "Epoch [18/30], Step [500/1250], Loss: 0.0111\n",
            "Epoch [18/30], Step [510/1250], Loss: 0.0520\n",
            "Epoch [18/30], Step [520/1250], Loss: 0.0973\n",
            "Epoch [18/30], Step [530/1250], Loss: 0.0674\n",
            "Epoch [18/30], Step [540/1250], Loss: 0.1950\n",
            "Epoch [18/30], Step [550/1250], Loss: 0.0059\n",
            "Epoch [18/30], Step [560/1250], Loss: 0.0537\n",
            "Epoch [18/30], Step [570/1250], Loss: 0.1129\n",
            "Epoch [18/30], Step [580/1250], Loss: 0.0787\n",
            "Epoch [18/30], Step [590/1250], Loss: 0.2182\n",
            "Epoch [18/30], Step [600/1250], Loss: 0.1115\n",
            "Epoch [18/30], Step [610/1250], Loss: 0.1400\n",
            "Epoch [18/30], Step [620/1250], Loss: 0.0729\n",
            "Epoch [18/30], Step [630/1250], Loss: 0.0266\n",
            "Epoch [18/30], Step [640/1250], Loss: 0.1348\n",
            "Epoch [18/30], Step [650/1250], Loss: 0.2397\n",
            "Epoch [18/30], Step [660/1250], Loss: 0.0237\n",
            "Epoch [18/30], Step [670/1250], Loss: 0.0520\n",
            "Epoch [18/30], Step [680/1250], Loss: 0.0583\n",
            "Epoch [18/30], Step [690/1250], Loss: 0.0702\n",
            "Epoch [18/30], Step [700/1250], Loss: 0.0527\n",
            "Epoch [18/30], Step [710/1250], Loss: 0.0357\n",
            "Epoch [18/30], Step [720/1250], Loss: 0.0190\n",
            "Epoch [18/30], Step [730/1250], Loss: 0.0678\n",
            "Epoch [18/30], Step [740/1250], Loss: 0.1418\n",
            "Epoch [18/30], Step [750/1250], Loss: 0.0569\n",
            "Epoch [18/30], Step [760/1250], Loss: 0.0517\n",
            "Epoch [18/30], Step [770/1250], Loss: 0.3123\n",
            "Epoch [18/30], Step [780/1250], Loss: 0.0380\n",
            "Epoch [18/30], Step [790/1250], Loss: 0.0131\n",
            "Epoch [18/30], Step [800/1250], Loss: 0.1405\n",
            "Epoch [18/30], Step [810/1250], Loss: 0.0588\n",
            "Epoch [18/30], Step [820/1250], Loss: 0.0756\n",
            "Epoch [18/30], Step [830/1250], Loss: 0.1055\n",
            "Epoch [18/30], Step [840/1250], Loss: 0.0230\n",
            "Epoch [18/30], Step [850/1250], Loss: 0.2863\n",
            "Epoch [18/30], Step [860/1250], Loss: 0.2414\n",
            "Epoch [18/30], Step [870/1250], Loss: 0.0730\n",
            "Epoch [18/30], Step [880/1250], Loss: 0.0630\n",
            "Epoch [18/30], Step [890/1250], Loss: 0.0322\n",
            "Epoch [18/30], Step [900/1250], Loss: 0.0465\n",
            "Epoch [18/30], Step [910/1250], Loss: 0.0186\n",
            "Epoch [18/30], Step [920/1250], Loss: 0.0737\n",
            "Epoch [18/30], Step [930/1250], Loss: 0.0205\n",
            "Epoch [18/30], Step [940/1250], Loss: 0.1491\n",
            "Epoch [18/30], Step [950/1250], Loss: 0.1488\n",
            "Epoch [18/30], Step [960/1250], Loss: 0.1440\n",
            "Epoch [18/30], Step [970/1250], Loss: 0.0405\n",
            "Epoch [18/30], Step [980/1250], Loss: 0.0223\n",
            "Epoch [18/30], Step [990/1250], Loss: 0.1288\n",
            "Epoch [18/30], Step [1000/1250], Loss: 0.0501\n",
            "Epoch [18/30], Step [1010/1250], Loss: 0.1277\n",
            "Epoch [18/30], Step [1020/1250], Loss: 0.0221\n",
            "Epoch [18/30], Step [1030/1250], Loss: 0.0742\n",
            "Epoch [18/30], Step [1040/1250], Loss: 0.0567\n",
            "Epoch [18/30], Step [1050/1250], Loss: 0.0192\n",
            "Epoch [18/30], Step [1060/1250], Loss: 0.0277\n",
            "Epoch [18/30], Step [1070/1250], Loss: 0.0968\n",
            "Epoch [18/30], Step [1080/1250], Loss: 0.0525\n",
            "Epoch [18/30], Step [1090/1250], Loss: 0.0289\n",
            "Epoch [18/30], Step [1100/1250], Loss: 0.0042\n",
            "Epoch [18/30], Step [1110/1250], Loss: 0.0725\n",
            "Epoch [18/30], Step [1120/1250], Loss: 0.0079\n",
            "Epoch [18/30], Step [1130/1250], Loss: 0.0136\n",
            "Epoch [18/30], Step [1140/1250], Loss: 0.0811\n",
            "Epoch [18/30], Step [1150/1250], Loss: 0.1085\n",
            "Epoch [18/30], Step [1160/1250], Loss: 0.0132\n",
            "Epoch [18/30], Step [1170/1250], Loss: 0.0373\n",
            "Epoch [18/30], Step [1180/1250], Loss: 0.0904\n",
            "Epoch [18/30], Step [1190/1250], Loss: 0.3199\n",
            "Epoch [18/30], Step [1200/1250], Loss: 0.1030\n",
            "Epoch [18/30], Step [1210/1250], Loss: 0.1069\n",
            "Epoch [18/30], Step [1220/1250], Loss: 0.0258\n",
            "Epoch [18/30], Step [1230/1250], Loss: 0.1018\n",
            "Epoch [18/30], Step [1240/1250], Loss: 0.0874\n",
            "Epoch [18/30], Step [1250/1250], Loss: 0.0407\n",
            "Epoch [19/30], Step [10/1250], Loss: 0.0450\n",
            "Epoch [19/30], Step [20/1250], Loss: 0.0794\n",
            "Epoch [19/30], Step [30/1250], Loss: 0.0473\n",
            "Epoch [19/30], Step [40/1250], Loss: 0.0498\n",
            "Epoch [19/30], Step [50/1250], Loss: 0.1578\n",
            "Epoch [19/30], Step [60/1250], Loss: 0.0912\n",
            "Epoch [19/30], Step [70/1250], Loss: 0.0998\n",
            "Epoch [19/30], Step [80/1250], Loss: 0.0860\n",
            "Epoch [19/30], Step [90/1250], Loss: 0.1336\n",
            "Epoch [19/30], Step [100/1250], Loss: 0.0216\n",
            "Epoch [19/30], Step [110/1250], Loss: 0.0297\n",
            "Epoch [19/30], Step [120/1250], Loss: 0.0826\n",
            "Epoch [19/30], Step [130/1250], Loss: 0.0167\n",
            "Epoch [19/30], Step [140/1250], Loss: 0.0583\n",
            "Epoch [19/30], Step [150/1250], Loss: 0.0900\n",
            "Epoch [19/30], Step [160/1250], Loss: 0.0305\n",
            "Epoch [19/30], Step [170/1250], Loss: 0.0503\n",
            "Epoch [19/30], Step [180/1250], Loss: 0.0371\n",
            "Epoch [19/30], Step [190/1250], Loss: 0.0876\n",
            "Epoch [19/30], Step [200/1250], Loss: 0.0398\n",
            "Epoch [19/30], Step [210/1250], Loss: 0.0459\n",
            "Epoch [19/30], Step [220/1250], Loss: 0.1059\n",
            "Epoch [19/30], Step [230/1250], Loss: 0.0203\n",
            "Epoch [19/30], Step [240/1250], Loss: 0.0273\n",
            "Epoch [19/30], Step [250/1250], Loss: 0.1753\n",
            "Epoch [19/30], Step [260/1250], Loss: 0.0088\n",
            "Epoch [19/30], Step [270/1250], Loss: 0.1139\n",
            "Epoch [19/30], Step [280/1250], Loss: 0.1268\n",
            "Epoch [19/30], Step [290/1250], Loss: 0.0329\n",
            "Epoch [19/30], Step [300/1250], Loss: 0.0077\n",
            "Epoch [19/30], Step [310/1250], Loss: 0.0296\n",
            "Epoch [19/30], Step [320/1250], Loss: 0.0155\n",
            "Epoch [19/30], Step [330/1250], Loss: 0.0537\n",
            "Epoch [19/30], Step [340/1250], Loss: 0.0099\n",
            "Epoch [19/30], Step [350/1250], Loss: 0.0809\n",
            "Epoch [19/30], Step [360/1250], Loss: 0.1500\n",
            "Epoch [19/30], Step [370/1250], Loss: 0.0056\n",
            "Epoch [19/30], Step [380/1250], Loss: 0.0695\n",
            "Epoch [19/30], Step [390/1250], Loss: 0.2145\n",
            "Epoch [19/30], Step [400/1250], Loss: 0.1085\n",
            "Epoch [19/30], Step [410/1250], Loss: 0.0645\n",
            "Epoch [19/30], Step [420/1250], Loss: 0.1651\n",
            "Epoch [19/30], Step [430/1250], Loss: 0.0222\n",
            "Epoch [19/30], Step [440/1250], Loss: 0.0156\n",
            "Epoch [19/30], Step [450/1250], Loss: 0.0085\n",
            "Epoch [19/30], Step [460/1250], Loss: 0.0532\n",
            "Epoch [19/30], Step [470/1250], Loss: 0.0651\n",
            "Epoch [19/30], Step [480/1250], Loss: 0.0248\n",
            "Epoch [19/30], Step [490/1250], Loss: 0.0192\n",
            "Epoch [19/30], Step [500/1250], Loss: 0.1655\n",
            "Epoch [19/30], Step [510/1250], Loss: 0.0255\n",
            "Epoch [19/30], Step [520/1250], Loss: 0.0353\n",
            "Epoch [19/30], Step [530/1250], Loss: 0.0262\n",
            "Epoch [19/30], Step [540/1250], Loss: 0.0265\n",
            "Epoch [19/30], Step [550/1250], Loss: 0.0149\n",
            "Epoch [19/30], Step [560/1250], Loss: 0.0826\n",
            "Epoch [19/30], Step [570/1250], Loss: 0.0533\n",
            "Epoch [19/30], Step [580/1250], Loss: 0.0339\n",
            "Epoch [19/30], Step [590/1250], Loss: 0.0372\n",
            "Epoch [19/30], Step [600/1250], Loss: 0.0061\n",
            "Epoch [19/30], Step [610/1250], Loss: 0.0158\n",
            "Epoch [19/30], Step [620/1250], Loss: 0.1511\n",
            "Epoch [19/30], Step [630/1250], Loss: 0.0215\n",
            "Epoch [19/30], Step [640/1250], Loss: 0.0668\n",
            "Epoch [19/30], Step [650/1250], Loss: 0.0764\n",
            "Epoch [19/30], Step [660/1250], Loss: 0.0372\n",
            "Epoch [19/30], Step [670/1250], Loss: 0.0127\n",
            "Epoch [19/30], Step [680/1250], Loss: 0.0322\n",
            "Epoch [19/30], Step [690/1250], Loss: 0.0257\n",
            "Epoch [19/30], Step [700/1250], Loss: 0.0546\n",
            "Epoch [19/30], Step [710/1250], Loss: 0.0532\n",
            "Epoch [19/30], Step [720/1250], Loss: 0.0533\n",
            "Epoch [19/30], Step [730/1250], Loss: 0.1719\n",
            "Epoch [19/30], Step [740/1250], Loss: 0.0205\n",
            "Epoch [19/30], Step [750/1250], Loss: 0.0114\n",
            "Epoch [19/30], Step [760/1250], Loss: 0.0210\n",
            "Epoch [19/30], Step [770/1250], Loss: 0.1242\n",
            "Epoch [19/30], Step [780/1250], Loss: 0.1404\n",
            "Epoch [19/30], Step [790/1250], Loss: 0.0869\n",
            "Epoch [19/30], Step [800/1250], Loss: 0.0228\n",
            "Epoch [19/30], Step [810/1250], Loss: 0.0863\n",
            "Epoch [19/30], Step [820/1250], Loss: 0.1219\n",
            "Epoch [19/30], Step [830/1250], Loss: 0.0522\n",
            "Epoch [19/30], Step [840/1250], Loss: 0.0262\n",
            "Epoch [19/30], Step [850/1250], Loss: 0.1298\n",
            "Epoch [19/30], Step [860/1250], Loss: 0.0135\n",
            "Epoch [19/30], Step [870/1250], Loss: 0.0142\n",
            "Epoch [19/30], Step [880/1250], Loss: 0.0363\n",
            "Epoch [19/30], Step [890/1250], Loss: 0.0969\n",
            "Epoch [19/30], Step [900/1250], Loss: 0.0204\n",
            "Epoch [19/30], Step [910/1250], Loss: 0.0499\n",
            "Epoch [19/30], Step [920/1250], Loss: 0.0272\n",
            "Epoch [19/30], Step [930/1250], Loss: 0.0794\n",
            "Epoch [19/30], Step [940/1250], Loss: 0.0376\n",
            "Epoch [19/30], Step [950/1250], Loss: 0.0513\n",
            "Epoch [19/30], Step [960/1250], Loss: 0.0129\n",
            "Epoch [19/30], Step [970/1250], Loss: 0.0431\n",
            "Epoch [19/30], Step [980/1250], Loss: 0.0195\n",
            "Epoch [19/30], Step [990/1250], Loss: 0.0664\n",
            "Epoch [19/30], Step [1000/1250], Loss: 0.0033\n",
            "Epoch [19/30], Step [1010/1250], Loss: 0.1833\n",
            "Epoch [19/30], Step [1020/1250], Loss: 0.0093\n",
            "Epoch [19/30], Step [1030/1250], Loss: 0.1589\n",
            "Epoch [19/30], Step [1040/1250], Loss: 0.0257\n",
            "Epoch [19/30], Step [1050/1250], Loss: 0.1955\n",
            "Epoch [19/30], Step [1060/1250], Loss: 0.2219\n",
            "Epoch [19/30], Step [1070/1250], Loss: 0.1133\n",
            "Epoch [19/30], Step [1080/1250], Loss: 0.0593\n",
            "Epoch [19/30], Step [1090/1250], Loss: 0.0844\n",
            "Epoch [19/30], Step [1100/1250], Loss: 0.0154\n",
            "Epoch [19/30], Step [1110/1250], Loss: 0.1394\n",
            "Epoch [19/30], Step [1120/1250], Loss: 0.0412\n",
            "Epoch [19/30], Step [1130/1250], Loss: 0.0121\n",
            "Epoch [19/30], Step [1140/1250], Loss: 0.0895\n",
            "Epoch [19/30], Step [1150/1250], Loss: 0.2207\n",
            "Epoch [19/30], Step [1160/1250], Loss: 0.0314\n",
            "Epoch [19/30], Step [1170/1250], Loss: 0.0150\n",
            "Epoch [19/30], Step [1180/1250], Loss: 0.0723\n",
            "Epoch [19/30], Step [1190/1250], Loss: 0.0072\n",
            "Epoch [19/30], Step [1200/1250], Loss: 0.0413\n",
            "Epoch [19/30], Step [1210/1250], Loss: 0.1760\n",
            "Epoch [19/30], Step [1220/1250], Loss: 0.0448\n",
            "Epoch [19/30], Step [1230/1250], Loss: 0.1404\n",
            "Epoch [19/30], Step [1240/1250], Loss: 0.0542\n",
            "Epoch [19/30], Step [1250/1250], Loss: 0.0281\n",
            "Epoch [20/30], Step [10/1250], Loss: 0.0846\n",
            "Epoch [20/30], Step [20/1250], Loss: 0.2089\n",
            "Epoch [20/30], Step [30/1250], Loss: 0.1115\n",
            "Epoch [20/30], Step [40/1250], Loss: 0.1439\n",
            "Epoch [20/30], Step [50/1250], Loss: 0.0222\n",
            "Epoch [20/30], Step [60/1250], Loss: 0.0224\n",
            "Epoch [20/30], Step [70/1250], Loss: 0.1938\n",
            "Epoch [20/30], Step [80/1250], Loss: 0.0583\n",
            "Epoch [20/30], Step [90/1250], Loss: 0.1061\n",
            "Epoch [20/30], Step [100/1250], Loss: 0.0406\n",
            "Epoch [20/30], Step [110/1250], Loss: 0.0154\n",
            "Epoch [20/30], Step [120/1250], Loss: 0.0165\n",
            "Epoch [20/30], Step [130/1250], Loss: 0.0292\n",
            "Epoch [20/30], Step [140/1250], Loss: 0.0289\n",
            "Epoch [20/30], Step [150/1250], Loss: 0.1006\n",
            "Epoch [20/30], Step [160/1250], Loss: 0.0126\n",
            "Epoch [20/30], Step [170/1250], Loss: 0.0019\n",
            "Epoch [20/30], Step [180/1250], Loss: 0.1609\n",
            "Epoch [20/30], Step [190/1250], Loss: 0.0954\n",
            "Epoch [20/30], Step [200/1250], Loss: 0.0622\n",
            "Epoch [20/30], Step [210/1250], Loss: 0.0812\n",
            "Epoch [20/30], Step [220/1250], Loss: 0.0075\n",
            "Epoch [20/30], Step [230/1250], Loss: 0.0321\n",
            "Epoch [20/30], Step [240/1250], Loss: 0.0048\n",
            "Epoch [20/30], Step [250/1250], Loss: 0.0154\n",
            "Epoch [20/30], Step [260/1250], Loss: 0.0184\n",
            "Epoch [20/30], Step [270/1250], Loss: 0.1241\n",
            "Epoch [20/30], Step [280/1250], Loss: 0.0034\n",
            "Epoch [20/30], Step [290/1250], Loss: 0.0843\n",
            "Epoch [20/30], Step [300/1250], Loss: 0.0515\n",
            "Epoch [20/30], Step [310/1250], Loss: 0.1150\n",
            "Epoch [20/30], Step [320/1250], Loss: 0.0172\n",
            "Epoch [20/30], Step [330/1250], Loss: 0.0532\n",
            "Epoch [20/30], Step [340/1250], Loss: 0.0359\n",
            "Epoch [20/30], Step [350/1250], Loss: 0.0704\n",
            "Epoch [20/30], Step [360/1250], Loss: 0.0341\n",
            "Epoch [20/30], Step [370/1250], Loss: 0.0262\n",
            "Epoch [20/30], Step [380/1250], Loss: 0.0148\n",
            "Epoch [20/30], Step [390/1250], Loss: 0.1977\n",
            "Epoch [20/30], Step [400/1250], Loss: 0.0173\n",
            "Epoch [20/30], Step [410/1250], Loss: 0.0707\n",
            "Epoch [20/30], Step [420/1250], Loss: 0.0127\n",
            "Epoch [20/30], Step [430/1250], Loss: 0.0541\n",
            "Epoch [20/30], Step [440/1250], Loss: 0.0097\n",
            "Epoch [20/30], Step [450/1250], Loss: 0.0015\n",
            "Epoch [20/30], Step [460/1250], Loss: 0.0143\n",
            "Epoch [20/30], Step [470/1250], Loss: 0.0054\n",
            "Epoch [20/30], Step [480/1250], Loss: 0.2172\n",
            "Epoch [20/30], Step [490/1250], Loss: 0.0484\n",
            "Epoch [20/30], Step [500/1250], Loss: 0.1681\n",
            "Epoch [20/30], Step [510/1250], Loss: 0.0084\n",
            "Epoch [20/30], Step [520/1250], Loss: 0.0872\n",
            "Epoch [20/30], Step [530/1250], Loss: 0.0293\n",
            "Epoch [20/30], Step [540/1250], Loss: 0.0494\n",
            "Epoch [20/30], Step [550/1250], Loss: 0.0558\n",
            "Epoch [20/30], Step [560/1250], Loss: 0.0620\n",
            "Epoch [20/30], Step [570/1250], Loss: 0.0394\n",
            "Epoch [20/30], Step [580/1250], Loss: 0.1110\n",
            "Epoch [20/30], Step [590/1250], Loss: 0.1946\n",
            "Epoch [20/30], Step [600/1250], Loss: 0.0206\n",
            "Epoch [20/30], Step [610/1250], Loss: 0.0087\n",
            "Epoch [20/30], Step [620/1250], Loss: 0.0409\n",
            "Epoch [20/30], Step [630/1250], Loss: 0.0147\n",
            "Epoch [20/30], Step [640/1250], Loss: 0.1018\n",
            "Epoch [20/30], Step [650/1250], Loss: 0.1881\n",
            "Epoch [20/30], Step [660/1250], Loss: 0.0206\n",
            "Epoch [20/30], Step [670/1250], Loss: 0.0267\n",
            "Epoch [20/30], Step [680/1250], Loss: 0.0654\n",
            "Epoch [20/30], Step [690/1250], Loss: 0.0862\n",
            "Epoch [20/30], Step [700/1250], Loss: 0.0007\n",
            "Epoch [20/30], Step [710/1250], Loss: 0.0297\n",
            "Epoch [20/30], Step [720/1250], Loss: 0.0175\n",
            "Epoch [20/30], Step [730/1250], Loss: 0.0148\n",
            "Epoch [20/30], Step [740/1250], Loss: 0.0636\n",
            "Epoch [20/30], Step [750/1250], Loss: 0.0195\n",
            "Epoch [20/30], Step [760/1250], Loss: 0.0200\n",
            "Epoch [20/30], Step [770/1250], Loss: 0.0366\n",
            "Epoch [20/30], Step [780/1250], Loss: 0.0096\n",
            "Epoch [20/30], Step [790/1250], Loss: 0.0086\n",
            "Epoch [20/30], Step [800/1250], Loss: 0.0891\n",
            "Epoch [20/30], Step [810/1250], Loss: 0.0781\n",
            "Epoch [20/30], Step [820/1250], Loss: 0.1116\n",
            "Epoch [20/30], Step [830/1250], Loss: 0.0949\n",
            "Epoch [20/30], Step [840/1250], Loss: 0.1310\n",
            "Epoch [20/30], Step [850/1250], Loss: 0.2297\n",
            "Epoch [20/30], Step [860/1250], Loss: 0.0685\n",
            "Epoch [20/30], Step [870/1250], Loss: 0.0365\n",
            "Epoch [20/30], Step [880/1250], Loss: 0.0337\n",
            "Epoch [20/30], Step [890/1250], Loss: 0.0066\n",
            "Epoch [20/30], Step [900/1250], Loss: 0.0733\n",
            "Epoch [20/30], Step [910/1250], Loss: 0.0184\n",
            "Epoch [20/30], Step [920/1250], Loss: 0.0940\n",
            "Epoch [20/30], Step [930/1250], Loss: 0.0367\n",
            "Epoch [20/30], Step [940/1250], Loss: 0.0490\n",
            "Epoch [20/30], Step [950/1250], Loss: 0.0144\n",
            "Epoch [20/30], Step [960/1250], Loss: 0.0245\n",
            "Epoch [20/30], Step [970/1250], Loss: 0.0802\n",
            "Epoch [20/30], Step [980/1250], Loss: 0.0262\n",
            "Epoch [20/30], Step [990/1250], Loss: 0.0431\n",
            "Epoch [20/30], Step [1000/1250], Loss: 0.0061\n",
            "Epoch [20/30], Step [1010/1250], Loss: 0.2974\n",
            "Epoch [20/30], Step [1020/1250], Loss: 0.0235\n",
            "Epoch [20/30], Step [1030/1250], Loss: 0.0043\n",
            "Epoch [20/30], Step [1040/1250], Loss: 0.1386\n",
            "Epoch [20/30], Step [1050/1250], Loss: 0.0073\n",
            "Epoch [20/30], Step [1060/1250], Loss: 0.0064\n",
            "Epoch [20/30], Step [1070/1250], Loss: 0.1435\n",
            "Epoch [20/30], Step [1080/1250], Loss: 0.0343\n",
            "Epoch [20/30], Step [1090/1250], Loss: 0.0296\n",
            "Epoch [20/30], Step [1100/1250], Loss: 0.0492\n",
            "Epoch [20/30], Step [1110/1250], Loss: 0.2161\n",
            "Epoch [20/30], Step [1120/1250], Loss: 0.0184\n",
            "Epoch [20/30], Step [1130/1250], Loss: 0.0096\n",
            "Epoch [20/30], Step [1140/1250], Loss: 0.0980\n",
            "Epoch [20/30], Step [1150/1250], Loss: 0.0066\n",
            "Epoch [20/30], Step [1160/1250], Loss: 0.0895\n",
            "Epoch [20/30], Step [1170/1250], Loss: 0.0308\n",
            "Epoch [20/30], Step [1180/1250], Loss: 0.0747\n",
            "Epoch [20/30], Step [1190/1250], Loss: 0.1147\n",
            "Epoch [20/30], Step [1200/1250], Loss: 0.0254\n",
            "Epoch [20/30], Step [1210/1250], Loss: 0.1165\n",
            "Epoch [20/30], Step [1220/1250], Loss: 0.0589\n",
            "Epoch [20/30], Step [1230/1250], Loss: 0.1610\n",
            "Epoch [20/30], Step [1240/1250], Loss: 0.0627\n",
            "Epoch [20/30], Step [1250/1250], Loss: 0.0464\n",
            "Epoch [21/30], Step [10/1250], Loss: 0.0825\n",
            "Epoch [21/30], Step [20/1250], Loss: 0.0403\n",
            "Epoch [21/30], Step [30/1250], Loss: 0.1402\n",
            "Epoch [21/30], Step [40/1250], Loss: 0.0332\n",
            "Epoch [21/30], Step [50/1250], Loss: 0.0072\n",
            "Epoch [21/30], Step [60/1250], Loss: 0.0802\n",
            "Epoch [21/30], Step [70/1250], Loss: 0.0077\n",
            "Epoch [21/30], Step [80/1250], Loss: 0.0148\n",
            "Epoch [21/30], Step [90/1250], Loss: 0.0924\n",
            "Epoch [21/30], Step [100/1250], Loss: 0.0307\n",
            "Epoch [21/30], Step [110/1250], Loss: 0.0533\n",
            "Epoch [21/30], Step [120/1250], Loss: 0.0214\n",
            "Epoch [21/30], Step [130/1250], Loss: 0.0118\n",
            "Epoch [21/30], Step [140/1250], Loss: 0.0291\n",
            "Epoch [21/30], Step [150/1250], Loss: 0.0046\n",
            "Epoch [21/30], Step [160/1250], Loss: 0.1132\n",
            "Epoch [21/30], Step [170/1250], Loss: 0.0557\n",
            "Epoch [21/30], Step [180/1250], Loss: 0.1733\n",
            "Epoch [21/30], Step [190/1250], Loss: 0.0202\n",
            "Epoch [21/30], Step [200/1250], Loss: 0.0142\n",
            "Epoch [21/30], Step [210/1250], Loss: 0.0526\n",
            "Epoch [21/30], Step [220/1250], Loss: 0.0300\n",
            "Epoch [21/30], Step [230/1250], Loss: 0.0167\n",
            "Epoch [21/30], Step [240/1250], Loss: 0.0092\n",
            "Epoch [21/30], Step [250/1250], Loss: 0.1509\n",
            "Epoch [21/30], Step [260/1250], Loss: 0.0557\n",
            "Epoch [21/30], Step [270/1250], Loss: 0.0073\n",
            "Epoch [21/30], Step [280/1250], Loss: 0.0070\n",
            "Epoch [21/30], Step [290/1250], Loss: 0.0766\n",
            "Epoch [21/30], Step [300/1250], Loss: 0.0184\n",
            "Epoch [21/30], Step [310/1250], Loss: 0.0149\n",
            "Epoch [21/30], Step [320/1250], Loss: 0.0279\n",
            "Epoch [21/30], Step [330/1250], Loss: 0.0312\n",
            "Epoch [21/30], Step [340/1250], Loss: 0.0052\n",
            "Epoch [21/30], Step [350/1250], Loss: 0.0407\n",
            "Epoch [21/30], Step [360/1250], Loss: 0.0041\n",
            "Epoch [21/30], Step [370/1250], Loss: 0.0108\n",
            "Epoch [21/30], Step [380/1250], Loss: 0.1629\n",
            "Epoch [21/30], Step [390/1250], Loss: 0.0065\n",
            "Epoch [21/30], Step [400/1250], Loss: 0.0181\n",
            "Epoch [21/30], Step [410/1250], Loss: 0.0280\n",
            "Epoch [21/30], Step [420/1250], Loss: 0.0234\n",
            "Epoch [21/30], Step [430/1250], Loss: 0.0624\n",
            "Epoch [21/30], Step [440/1250], Loss: 0.0332\n",
            "Epoch [21/30], Step [450/1250], Loss: 0.0094\n",
            "Epoch [21/30], Step [460/1250], Loss: 0.1124\n",
            "Epoch [21/30], Step [470/1250], Loss: 0.0052\n",
            "Epoch [21/30], Step [480/1250], Loss: 0.0393\n",
            "Epoch [21/30], Step [490/1250], Loss: 0.0026\n",
            "Epoch [21/30], Step [500/1250], Loss: 0.0473\n",
            "Epoch [21/30], Step [510/1250], Loss: 0.1347\n",
            "Epoch [21/30], Step [520/1250], Loss: 0.0086\n",
            "Epoch [21/30], Step [530/1250], Loss: 0.0137\n",
            "Epoch [21/30], Step [540/1250], Loss: 0.0027\n",
            "Epoch [21/30], Step [550/1250], Loss: 0.1139\n",
            "Epoch [21/30], Step [560/1250], Loss: 0.0791\n",
            "Epoch [21/30], Step [570/1250], Loss: 0.0799\n",
            "Epoch [21/30], Step [580/1250], Loss: 0.0194\n",
            "Epoch [21/30], Step [590/1250], Loss: 0.0230\n",
            "Epoch [21/30], Step [600/1250], Loss: 0.0504\n",
            "Epoch [21/30], Step [610/1250], Loss: 0.0247\n",
            "Epoch [21/30], Step [620/1250], Loss: 0.0306\n",
            "Epoch [21/30], Step [630/1250], Loss: 0.0156\n",
            "Epoch [21/30], Step [640/1250], Loss: 0.0839\n",
            "Epoch [21/30], Step [650/1250], Loss: 0.0387\n",
            "Epoch [21/30], Step [660/1250], Loss: 0.1465\n",
            "Epoch [21/30], Step [670/1250], Loss: 0.0537\n",
            "Epoch [21/30], Step [680/1250], Loss: 0.0171\n",
            "Epoch [21/30], Step [690/1250], Loss: 0.0158\n",
            "Epoch [21/30], Step [700/1250], Loss: 0.0638\n",
            "Epoch [21/30], Step [710/1250], Loss: 0.0066\n",
            "Epoch [21/30], Step [720/1250], Loss: 0.1414\n",
            "Epoch [21/30], Step [730/1250], Loss: 0.0014\n",
            "Epoch [21/30], Step [740/1250], Loss: 0.0205\n",
            "Epoch [21/30], Step [750/1250], Loss: 0.0132\n",
            "Epoch [21/30], Step [760/1250], Loss: 0.1121\n",
            "Epoch [21/30], Step [770/1250], Loss: 0.0844\n",
            "Epoch [21/30], Step [780/1250], Loss: 0.1548\n",
            "Epoch [21/30], Step [790/1250], Loss: 0.1135\n",
            "Epoch [21/30], Step [800/1250], Loss: 0.0237\n",
            "Epoch [21/30], Step [810/1250], Loss: 0.0318\n",
            "Epoch [21/30], Step [820/1250], Loss: 0.0102\n",
            "Epoch [21/30], Step [830/1250], Loss: 0.1223\n",
            "Epoch [21/30], Step [840/1250], Loss: 0.0909\n",
            "Epoch [21/30], Step [850/1250], Loss: 0.0401\n",
            "Epoch [21/30], Step [860/1250], Loss: 0.0092\n",
            "Epoch [21/30], Step [870/1250], Loss: 0.0522\n",
            "Epoch [21/30], Step [880/1250], Loss: 0.0302\n",
            "Epoch [21/30], Step [890/1250], Loss: 0.0137\n",
            "Epoch [21/30], Step [900/1250], Loss: 0.0509\n",
            "Epoch [21/30], Step [910/1250], Loss: 0.0448\n",
            "Epoch [21/30], Step [920/1250], Loss: 0.0303\n",
            "Epoch [21/30], Step [930/1250], Loss: 0.0061\n",
            "Epoch [21/30], Step [940/1250], Loss: 0.0124\n",
            "Epoch [21/30], Step [950/1250], Loss: 0.0803\n",
            "Epoch [21/30], Step [960/1250], Loss: 0.0628\n",
            "Epoch [21/30], Step [970/1250], Loss: 0.0914\n",
            "Epoch [21/30], Step [980/1250], Loss: 0.0797\n",
            "Epoch [21/30], Step [990/1250], Loss: 0.1307\n",
            "Epoch [21/30], Step [1000/1250], Loss: 0.0293\n",
            "Epoch [21/30], Step [1010/1250], Loss: 0.0378\n",
            "Epoch [21/30], Step [1020/1250], Loss: 0.1530\n",
            "Epoch [21/30], Step [1030/1250], Loss: 0.0411\n",
            "Epoch [21/30], Step [1040/1250], Loss: 0.0418\n",
            "Epoch [21/30], Step [1050/1250], Loss: 0.0254\n",
            "Epoch [21/30], Step [1060/1250], Loss: 0.0136\n",
            "Epoch [21/30], Step [1070/1250], Loss: 0.1715\n",
            "Epoch [21/30], Step [1080/1250], Loss: 0.0205\n",
            "Epoch [21/30], Step [1090/1250], Loss: 0.0402\n",
            "Epoch [21/30], Step [1100/1250], Loss: 0.0563\n",
            "Epoch [21/30], Step [1110/1250], Loss: 0.0778\n",
            "Epoch [21/30], Step [1120/1250], Loss: 0.0645\n",
            "Epoch [21/30], Step [1130/1250], Loss: 0.0883\n",
            "Epoch [21/30], Step [1140/1250], Loss: 0.0231\n",
            "Epoch [21/30], Step [1150/1250], Loss: 0.0256\n",
            "Epoch [21/30], Step [1160/1250], Loss: 0.0168\n",
            "Epoch [21/30], Step [1170/1250], Loss: 0.0033\n",
            "Epoch [21/30], Step [1180/1250], Loss: 0.0389\n",
            "Epoch [21/30], Step [1190/1250], Loss: 0.0760\n",
            "Epoch [21/30], Step [1200/1250], Loss: 0.0329\n",
            "Epoch [21/30], Step [1210/1250], Loss: 0.0255\n",
            "Epoch [21/30], Step [1220/1250], Loss: 0.0538\n",
            "Epoch [21/30], Step [1230/1250], Loss: 0.0280\n",
            "Epoch [21/30], Step [1240/1250], Loss: 0.1351\n",
            "Epoch [21/30], Step [1250/1250], Loss: 0.0305\n",
            "Epoch [22/30], Step [10/1250], Loss: 0.0512\n",
            "Epoch [22/30], Step [20/1250], Loss: 0.0151\n",
            "Epoch [22/30], Step [30/1250], Loss: 0.0165\n",
            "Epoch [22/30], Step [40/1250], Loss: 0.0299\n",
            "Epoch [22/30], Step [50/1250], Loss: 0.0588\n",
            "Epoch [22/30], Step [60/1250], Loss: 0.0138\n",
            "Epoch [22/30], Step [70/1250], Loss: 0.1344\n",
            "Epoch [22/30], Step [80/1250], Loss: 0.0281\n",
            "Epoch [22/30], Step [90/1250], Loss: 0.0315\n",
            "Epoch [22/30], Step [100/1250], Loss: 0.0024\n",
            "Epoch [22/30], Step [110/1250], Loss: 0.0597\n",
            "Epoch [22/30], Step [120/1250], Loss: 0.0011\n",
            "Epoch [22/30], Step [130/1250], Loss: 0.0039\n",
            "Epoch [22/30], Step [140/1250], Loss: 0.0016\n",
            "Epoch [22/30], Step [150/1250], Loss: 0.0140\n",
            "Epoch [22/30], Step [160/1250], Loss: 0.0038\n",
            "Epoch [22/30], Step [170/1250], Loss: 0.0968\n",
            "Epoch [22/30], Step [180/1250], Loss: 0.0170\n",
            "Epoch [22/30], Step [190/1250], Loss: 0.0016\n",
            "Epoch [22/30], Step [200/1250], Loss: 0.0799\n",
            "Epoch [22/30], Step [210/1250], Loss: 0.1003\n",
            "Epoch [22/30], Step [220/1250], Loss: 0.0404\n",
            "Epoch [22/30], Step [230/1250], Loss: 0.0135\n",
            "Epoch [22/30], Step [240/1250], Loss: 0.0251\n",
            "Epoch [22/30], Step [250/1250], Loss: 0.3397\n",
            "Epoch [22/30], Step [260/1250], Loss: 0.0114\n",
            "Epoch [22/30], Step [270/1250], Loss: 0.0312\n",
            "Epoch [22/30], Step [280/1250], Loss: 0.0142\n",
            "Epoch [22/30], Step [290/1250], Loss: 0.0501\n",
            "Epoch [22/30], Step [300/1250], Loss: 0.1683\n",
            "Epoch [22/30], Step [310/1250], Loss: 0.0088\n",
            "Epoch [22/30], Step [320/1250], Loss: 0.0089\n",
            "Epoch [22/30], Step [330/1250], Loss: 0.1070\n",
            "Epoch [22/30], Step [340/1250], Loss: 0.0055\n",
            "Epoch [22/30], Step [350/1250], Loss: 0.0031\n",
            "Epoch [22/30], Step [360/1250], Loss: 0.0089\n",
            "Epoch [22/30], Step [370/1250], Loss: 0.0316\n",
            "Epoch [22/30], Step [380/1250], Loss: 0.0005\n",
            "Epoch [22/30], Step [390/1250], Loss: 0.0161\n",
            "Epoch [22/30], Step [400/1250], Loss: 0.0557\n",
            "Epoch [22/30], Step [410/1250], Loss: 0.0288\n",
            "Epoch [22/30], Step [420/1250], Loss: 0.0413\n",
            "Epoch [22/30], Step [430/1250], Loss: 0.0341\n",
            "Epoch [22/30], Step [440/1250], Loss: 0.0229\n",
            "Epoch [22/30], Step [450/1250], Loss: 0.0378\n",
            "Epoch [22/30], Step [460/1250], Loss: 0.0393\n",
            "Epoch [22/30], Step [470/1250], Loss: 0.0069\n",
            "Epoch [22/30], Step [480/1250], Loss: 0.1573\n",
            "Epoch [22/30], Step [490/1250], Loss: 0.0699\n",
            "Epoch [22/30], Step [500/1250], Loss: 0.0023\n",
            "Epoch [22/30], Step [510/1250], Loss: 0.0584\n",
            "Epoch [22/30], Step [520/1250], Loss: 0.0139\n",
            "Epoch [22/30], Step [530/1250], Loss: 0.0031\n",
            "Epoch [22/30], Step [540/1250], Loss: 0.0747\n",
            "Epoch [22/30], Step [550/1250], Loss: 0.0204\n",
            "Epoch [22/30], Step [560/1250], Loss: 0.0609\n",
            "Epoch [22/30], Step [570/1250], Loss: 0.1625\n",
            "Epoch [22/30], Step [580/1250], Loss: 0.0234\n",
            "Epoch [22/30], Step [590/1250], Loss: 0.0535\n",
            "Epoch [22/30], Step [600/1250], Loss: 0.2313\n",
            "Epoch [22/30], Step [610/1250], Loss: 0.1137\n",
            "Epoch [22/30], Step [620/1250], Loss: 0.1527\n",
            "Epoch [22/30], Step [630/1250], Loss: 0.0334\n",
            "Epoch [22/30], Step [640/1250], Loss: 0.1017\n",
            "Epoch [22/30], Step [650/1250], Loss: 0.0442\n",
            "Epoch [22/30], Step [660/1250], Loss: 0.0817\n",
            "Epoch [22/30], Step [670/1250], Loss: 0.0198\n",
            "Epoch [22/30], Step [680/1250], Loss: 0.0339\n",
            "Epoch [22/30], Step [690/1250], Loss: 0.1185\n",
            "Epoch [22/30], Step [700/1250], Loss: 0.0072\n",
            "Epoch [22/30], Step [710/1250], Loss: 0.1103\n",
            "Epoch [22/30], Step [720/1250], Loss: 0.0163\n",
            "Epoch [22/30], Step [730/1250], Loss: 0.0262\n",
            "Epoch [22/30], Step [740/1250], Loss: 0.0247\n",
            "Epoch [22/30], Step [750/1250], Loss: 0.0057\n",
            "Epoch [22/30], Step [760/1250], Loss: 0.0258\n",
            "Epoch [22/30], Step [770/1250], Loss: 0.0203\n",
            "Epoch [22/30], Step [780/1250], Loss: 0.0282\n",
            "Epoch [22/30], Step [790/1250], Loss: 0.0064\n",
            "Epoch [22/30], Step [800/1250], Loss: 0.0325\n",
            "Epoch [22/30], Step [810/1250], Loss: 0.0496\n",
            "Epoch [22/30], Step [820/1250], Loss: 0.0369\n",
            "Epoch [22/30], Step [830/1250], Loss: 0.0253\n",
            "Epoch [22/30], Step [840/1250], Loss: 0.0212\n",
            "Epoch [22/30], Step [850/1250], Loss: 0.1025\n",
            "Epoch [22/30], Step [860/1250], Loss: 0.0720\n",
            "Epoch [22/30], Step [870/1250], Loss: 0.0035\n",
            "Epoch [22/30], Step [880/1250], Loss: 0.0212\n",
            "Epoch [22/30], Step [890/1250], Loss: 0.0573\n",
            "Epoch [22/30], Step [900/1250], Loss: 0.0206\n",
            "Epoch [22/30], Step [910/1250], Loss: 0.0204\n",
            "Epoch [22/30], Step [920/1250], Loss: 0.0077\n",
            "Epoch [22/30], Step [930/1250], Loss: 0.0415\n",
            "Epoch [22/30], Step [940/1250], Loss: 0.1945\n",
            "Epoch [22/30], Step [950/1250], Loss: 0.1521\n",
            "Epoch [22/30], Step [960/1250], Loss: 0.0297\n",
            "Epoch [22/30], Step [970/1250], Loss: 0.0845\n",
            "Epoch [22/30], Step [980/1250], Loss: 0.0164\n",
            "Epoch [22/30], Step [990/1250], Loss: 0.0071\n",
            "Epoch [22/30], Step [1000/1250], Loss: 0.0149\n",
            "Epoch [22/30], Step [1010/1250], Loss: 0.1146\n",
            "Epoch [22/30], Step [1020/1250], Loss: 0.0088\n",
            "Epoch [22/30], Step [1030/1250], Loss: 0.0171\n",
            "Epoch [22/30], Step [1040/1250], Loss: 0.0330\n",
            "Epoch [22/30], Step [1050/1250], Loss: 0.0018\n",
            "Epoch [22/30], Step [1060/1250], Loss: 0.0248\n",
            "Epoch [22/30], Step [1070/1250], Loss: 0.0345\n",
            "Epoch [22/30], Step [1080/1250], Loss: 0.2278\n",
            "Epoch [22/30], Step [1090/1250], Loss: 0.1195\n",
            "Epoch [22/30], Step [1100/1250], Loss: 0.0005\n",
            "Epoch [22/30], Step [1110/1250], Loss: 0.0587\n",
            "Epoch [22/30], Step [1120/1250], Loss: 0.0401\n",
            "Epoch [22/30], Step [1130/1250], Loss: 0.1355\n",
            "Epoch [22/30], Step [1140/1250], Loss: 0.0091\n",
            "Epoch [22/30], Step [1150/1250], Loss: 0.0772\n",
            "Epoch [22/30], Step [1160/1250], Loss: 0.0079\n",
            "Epoch [22/30], Step [1170/1250], Loss: 0.0216\n",
            "Epoch [22/30], Step [1180/1250], Loss: 0.0625\n",
            "Epoch [22/30], Step [1190/1250], Loss: 0.0511\n",
            "Epoch [22/30], Step [1200/1250], Loss: 0.1791\n",
            "Epoch [22/30], Step [1210/1250], Loss: 0.0391\n",
            "Epoch [22/30], Step [1220/1250], Loss: 0.0072\n",
            "Epoch [22/30], Step [1230/1250], Loss: 0.0306\n",
            "Epoch [22/30], Step [1240/1250], Loss: 0.0537\n",
            "Epoch [22/30], Step [1250/1250], Loss: 0.2238\n",
            "Epoch [23/30], Step [10/1250], Loss: 0.0038\n",
            "Epoch [23/30], Step [20/1250], Loss: 0.4344\n",
            "Epoch [23/30], Step [30/1250], Loss: 0.1269\n",
            "Epoch [23/30], Step [40/1250], Loss: 0.1894\n",
            "Epoch [23/30], Step [50/1250], Loss: 0.0419\n",
            "Epoch [23/30], Step [60/1250], Loss: 0.0162\n",
            "Epoch [23/30], Step [70/1250], Loss: 0.0634\n",
            "Epoch [23/30], Step [80/1250], Loss: 0.1194\n",
            "Epoch [23/30], Step [90/1250], Loss: 0.0021\n",
            "Epoch [23/30], Step [100/1250], Loss: 0.0599\n",
            "Epoch [23/30], Step [110/1250], Loss: 0.1480\n",
            "Epoch [23/30], Step [120/1250], Loss: 0.0385\n",
            "Epoch [23/30], Step [130/1250], Loss: 0.0486\n",
            "Epoch [23/30], Step [140/1250], Loss: 0.0914\n",
            "Epoch [23/30], Step [150/1250], Loss: 0.0279\n",
            "Epoch [23/30], Step [160/1250], Loss: 0.0182\n",
            "Epoch [23/30], Step [170/1250], Loss: 0.1763\n",
            "Epoch [23/30], Step [180/1250], Loss: 0.0308\n",
            "Epoch [23/30], Step [190/1250], Loss: 0.0070\n",
            "Epoch [23/30], Step [200/1250], Loss: 0.0397\n",
            "Epoch [23/30], Step [210/1250], Loss: 0.0097\n",
            "Epoch [23/30], Step [220/1250], Loss: 0.0034\n",
            "Epoch [23/30], Step [230/1250], Loss: 0.0352\n",
            "Epoch [23/30], Step [240/1250], Loss: 0.0212\n",
            "Epoch [23/30], Step [250/1250], Loss: 0.0474\n",
            "Epoch [23/30], Step [260/1250], Loss: 0.0534\n",
            "Epoch [23/30], Step [270/1250], Loss: 0.0589\n",
            "Epoch [23/30], Step [280/1250], Loss: 0.0773\n",
            "Epoch [23/30], Step [290/1250], Loss: 0.0458\n",
            "Epoch [23/30], Step [300/1250], Loss: 0.0791\n",
            "Epoch [23/30], Step [310/1250], Loss: 0.0115\n",
            "Epoch [23/30], Step [320/1250], Loss: 0.0851\n",
            "Epoch [23/30], Step [330/1250], Loss: 0.0133\n",
            "Epoch [23/30], Step [340/1250], Loss: 0.0023\n",
            "Epoch [23/30], Step [350/1250], Loss: 0.0010\n",
            "Epoch [23/30], Step [360/1250], Loss: 0.0065\n",
            "Epoch [23/30], Step [370/1250], Loss: 0.1430\n",
            "Epoch [23/30], Step [380/1250], Loss: 0.0832\n",
            "Epoch [23/30], Step [390/1250], Loss: 0.0037\n",
            "Epoch [23/30], Step [400/1250], Loss: 0.0007\n",
            "Epoch [23/30], Step [410/1250], Loss: 0.0141\n",
            "Epoch [23/30], Step [420/1250], Loss: 0.0070\n",
            "Epoch [23/30], Step [430/1250], Loss: 0.0075\n",
            "Epoch [23/30], Step [440/1250], Loss: 0.0152\n",
            "Epoch [23/30], Step [450/1250], Loss: 0.0100\n",
            "Epoch [23/30], Step [460/1250], Loss: 0.0001\n",
            "Epoch [23/30], Step [470/1250], Loss: 0.0135\n",
            "Epoch [23/30], Step [480/1250], Loss: 0.0019\n",
            "Epoch [23/30], Step [490/1250], Loss: 0.0970\n",
            "Epoch [23/30], Step [500/1250], Loss: 0.0365\n",
            "Epoch [23/30], Step [510/1250], Loss: 0.0555\n",
            "Epoch [23/30], Step [520/1250], Loss: 0.0159\n",
            "Epoch [23/30], Step [530/1250], Loss: 0.1802\n",
            "Epoch [23/30], Step [540/1250], Loss: 0.0018\n",
            "Epoch [23/30], Step [550/1250], Loss: 0.0371\n",
            "Epoch [23/30], Step [560/1250], Loss: 0.0072\n",
            "Epoch [23/30], Step [570/1250], Loss: 0.0099\n",
            "Epoch [23/30], Step [580/1250], Loss: 0.0103\n",
            "Epoch [23/30], Step [590/1250], Loss: 0.0291\n",
            "Epoch [23/30], Step [600/1250], Loss: 0.0101\n",
            "Epoch [23/30], Step [610/1250], Loss: 0.0205\n",
            "Epoch [23/30], Step [620/1250], Loss: 0.0223\n",
            "Epoch [23/30], Step [630/1250], Loss: 0.0685\n",
            "Epoch [23/30], Step [640/1250], Loss: 0.0218\n",
            "Epoch [23/30], Step [650/1250], Loss: 0.0134\n",
            "Epoch [23/30], Step [660/1250], Loss: 0.0012\n",
            "Epoch [23/30], Step [670/1250], Loss: 0.0347\n",
            "Epoch [23/30], Step [680/1250], Loss: 0.1744\n",
            "Epoch [23/30], Step [690/1250], Loss: 0.0249\n",
            "Epoch [23/30], Step [700/1250], Loss: 0.0348\n",
            "Epoch [23/30], Step [710/1250], Loss: 0.0025\n",
            "Epoch [23/30], Step [720/1250], Loss: 0.0071\n",
            "Epoch [23/30], Step [730/1250], Loss: 0.0971\n",
            "Epoch [23/30], Step [740/1250], Loss: 0.0193\n",
            "Epoch [23/30], Step [750/1250], Loss: 0.0046\n",
            "Epoch [23/30], Step [760/1250], Loss: 0.0842\n",
            "Epoch [23/30], Step [770/1250], Loss: 0.0103\n",
            "Epoch [23/30], Step [780/1250], Loss: 0.0120\n",
            "Epoch [23/30], Step [790/1250], Loss: 0.0027\n",
            "Epoch [23/30], Step [800/1250], Loss: 0.0329\n",
            "Epoch [23/30], Step [810/1250], Loss: 0.0469\n",
            "Epoch [23/30], Step [820/1250], Loss: 0.0073\n",
            "Epoch [23/30], Step [830/1250], Loss: 0.0394\n",
            "Epoch [23/30], Step [840/1250], Loss: 0.0020\n",
            "Epoch [23/30], Step [850/1250], Loss: 0.0306\n",
            "Epoch [23/30], Step [860/1250], Loss: 0.0293\n",
            "Epoch [23/30], Step [870/1250], Loss: 0.0278\n",
            "Epoch [23/30], Step [880/1250], Loss: 0.0555\n",
            "Epoch [23/30], Step [890/1250], Loss: 0.0101\n",
            "Epoch [23/30], Step [900/1250], Loss: 0.0547\n",
            "Epoch [23/30], Step [910/1250], Loss: 0.0587\n",
            "Epoch [23/30], Step [920/1250], Loss: 0.0698\n",
            "Epoch [23/30], Step [930/1250], Loss: 0.0471\n",
            "Epoch [23/30], Step [940/1250], Loss: 0.0360\n",
            "Epoch [23/30], Step [950/1250], Loss: 0.0409\n",
            "Epoch [23/30], Step [960/1250], Loss: 0.0843\n",
            "Epoch [23/30], Step [970/1250], Loss: 0.0328\n",
            "Epoch [23/30], Step [980/1250], Loss: 0.0288\n",
            "Epoch [23/30], Step [990/1250], Loss: 0.0184\n",
            "Epoch [23/30], Step [1000/1250], Loss: 0.0098\n",
            "Epoch [23/30], Step [1010/1250], Loss: 0.1264\n",
            "Epoch [23/30], Step [1020/1250], Loss: 0.0643\n",
            "Epoch [23/30], Step [1030/1250], Loss: 0.0296\n",
            "Epoch [23/30], Step [1040/1250], Loss: 0.0117\n",
            "Epoch [23/30], Step [1050/1250], Loss: 0.0633\n",
            "Epoch [23/30], Step [1060/1250], Loss: 0.0098\n",
            "Epoch [23/30], Step [1070/1250], Loss: 0.0012\n",
            "Epoch [23/30], Step [1080/1250], Loss: 0.0491\n",
            "Epoch [23/30], Step [1090/1250], Loss: 0.0159\n",
            "Epoch [23/30], Step [1100/1250], Loss: 0.0284\n",
            "Epoch [23/30], Step [1110/1250], Loss: 0.0522\n",
            "Epoch [23/30], Step [1120/1250], Loss: 0.0695\n",
            "Epoch [23/30], Step [1130/1250], Loss: 0.0585\n",
            "Epoch [23/30], Step [1140/1250], Loss: 0.0387\n",
            "Epoch [23/30], Step [1150/1250], Loss: 0.0385\n",
            "Epoch [23/30], Step [1160/1250], Loss: 0.1000\n",
            "Epoch [23/30], Step [1170/1250], Loss: 0.0322\n",
            "Epoch [23/30], Step [1180/1250], Loss: 0.1221\n",
            "Epoch [23/30], Step [1190/1250], Loss: 0.1026\n",
            "Epoch [23/30], Step [1200/1250], Loss: 0.0083\n",
            "Epoch [23/30], Step [1210/1250], Loss: 0.0474\n",
            "Epoch [23/30], Step [1220/1250], Loss: 0.0059\n",
            "Epoch [23/30], Step [1230/1250], Loss: 0.0241\n",
            "Epoch [23/30], Step [1240/1250], Loss: 0.0048\n",
            "Epoch [23/30], Step [1250/1250], Loss: 0.0113\n",
            "Epoch [24/30], Step [10/1250], Loss: 0.0015\n",
            "Epoch [24/30], Step [20/1250], Loss: 0.0068\n",
            "Epoch [24/30], Step [30/1250], Loss: 0.0875\n",
            "Epoch [24/30], Step [40/1250], Loss: 0.0614\n",
            "Epoch [24/30], Step [50/1250], Loss: 0.0435\n",
            "Epoch [24/30], Step [60/1250], Loss: 0.1705\n",
            "Epoch [24/30], Step [70/1250], Loss: 0.0427\n",
            "Epoch [24/30], Step [80/1250], Loss: 0.1217\n",
            "Epoch [24/30], Step [90/1250], Loss: 0.0143\n",
            "Epoch [24/30], Step [100/1250], Loss: 0.1115\n",
            "Epoch [24/30], Step [110/1250], Loss: 0.0045\n",
            "Epoch [24/30], Step [120/1250], Loss: 0.0084\n",
            "Epoch [24/30], Step [130/1250], Loss: 0.0232\n",
            "Epoch [24/30], Step [140/1250], Loss: 0.0161\n",
            "Epoch [24/30], Step [150/1250], Loss: 0.0063\n",
            "Epoch [24/30], Step [160/1250], Loss: 0.0664\n",
            "Epoch [24/30], Step [170/1250], Loss: 0.0853\n",
            "Epoch [24/30], Step [180/1250], Loss: 0.0366\n",
            "Epoch [24/30], Step [190/1250], Loss: 0.0022\n",
            "Epoch [24/30], Step [200/1250], Loss: 0.0205\n",
            "Epoch [24/30], Step [210/1250], Loss: 0.0024\n",
            "Epoch [24/30], Step [220/1250], Loss: 0.0156\n",
            "Epoch [24/30], Step [230/1250], Loss: 0.0615\n",
            "Epoch [24/30], Step [240/1250], Loss: 0.0206\n",
            "Epoch [24/30], Step [250/1250], Loss: 0.0113\n",
            "Epoch [24/30], Step [260/1250], Loss: 0.0085\n",
            "Epoch [24/30], Step [270/1250], Loss: 0.0058\n",
            "Epoch [24/30], Step [280/1250], Loss: 0.0031\n",
            "Epoch [24/30], Step [290/1250], Loss: 0.0271\n",
            "Epoch [24/30], Step [300/1250], Loss: 0.1067\n",
            "Epoch [24/30], Step [310/1250], Loss: 0.0143\n",
            "Epoch [24/30], Step [320/1250], Loss: 0.0553\n",
            "Epoch [24/30], Step [330/1250], Loss: 0.0902\n",
            "Epoch [24/30], Step [340/1250], Loss: 0.0632\n",
            "Epoch [24/30], Step [350/1250], Loss: 0.0275\n",
            "Epoch [24/30], Step [360/1250], Loss: 0.0336\n",
            "Epoch [24/30], Step [370/1250], Loss: 0.0680\n",
            "Epoch [24/30], Step [380/1250], Loss: 0.0117\n",
            "Epoch [24/30], Step [390/1250], Loss: 0.0011\n",
            "Epoch [24/30], Step [400/1250], Loss: 0.0557\n",
            "Epoch [24/30], Step [410/1250], Loss: 0.0021\n",
            "Epoch [24/30], Step [420/1250], Loss: 0.0042\n",
            "Epoch [24/30], Step [430/1250], Loss: 0.0268\n",
            "Epoch [24/30], Step [440/1250], Loss: 0.0038\n",
            "Epoch [24/30], Step [450/1250], Loss: 0.0301\n",
            "Epoch [24/30], Step [460/1250], Loss: 0.1610\n",
            "Epoch [24/30], Step [470/1250], Loss: 0.0008\n",
            "Epoch [24/30], Step [480/1250], Loss: 0.0295\n",
            "Epoch [24/30], Step [490/1250], Loss: 0.0395\n",
            "Epoch [24/30], Step [500/1250], Loss: 0.0049\n",
            "Epoch [24/30], Step [510/1250], Loss: 0.1562\n",
            "Epoch [24/30], Step [520/1250], Loss: 0.0754\n",
            "Epoch [24/30], Step [530/1250], Loss: 0.0057\n",
            "Epoch [24/30], Step [540/1250], Loss: 0.0959\n",
            "Epoch [24/30], Step [550/1250], Loss: 0.0267\n",
            "Epoch [24/30], Step [560/1250], Loss: 0.0235\n",
            "Epoch [24/30], Step [570/1250], Loss: 0.0627\n",
            "Epoch [24/30], Step [580/1250], Loss: 0.0014\n",
            "Epoch [24/30], Step [590/1250], Loss: 0.0421\n",
            "Epoch [24/30], Step [600/1250], Loss: 0.0026\n",
            "Epoch [24/30], Step [610/1250], Loss: 0.0643\n",
            "Epoch [24/30], Step [620/1250], Loss: 0.0726\n",
            "Epoch [24/30], Step [630/1250], Loss: 0.0057\n",
            "Epoch [24/30], Step [640/1250], Loss: 0.0084\n",
            "Epoch [24/30], Step [650/1250], Loss: 0.0094\n",
            "Epoch [24/30], Step [660/1250], Loss: 0.0274\n",
            "Epoch [24/30], Step [670/1250], Loss: 0.0499\n",
            "Epoch [24/30], Step [680/1250], Loss: 0.0344\n",
            "Epoch [24/30], Step [690/1250], Loss: 0.0268\n",
            "Epoch [24/30], Step [700/1250], Loss: 0.0087\n",
            "Epoch [24/30], Step [710/1250], Loss: 0.0844\n",
            "Epoch [24/30], Step [720/1250], Loss: 0.0574\n",
            "Epoch [24/30], Step [730/1250], Loss: 0.0065\n",
            "Epoch [24/30], Step [740/1250], Loss: 0.0069\n",
            "Epoch [24/30], Step [750/1250], Loss: 0.0135\n",
            "Epoch [24/30], Step [760/1250], Loss: 0.0068\n",
            "Epoch [24/30], Step [770/1250], Loss: 0.0471\n",
            "Epoch [24/30], Step [780/1250], Loss: 0.0013\n",
            "Epoch [24/30], Step [790/1250], Loss: 0.0399\n",
            "Epoch [24/30], Step [800/1250], Loss: 0.0109\n",
            "Epoch [24/30], Step [810/1250], Loss: 0.0805\n",
            "Epoch [24/30], Step [820/1250], Loss: 0.0140\n",
            "Epoch [24/30], Step [830/1250], Loss: 0.0308\n",
            "Epoch [24/30], Step [840/1250], Loss: 0.0015\n",
            "Epoch [24/30], Step [850/1250], Loss: 0.0128\n",
            "Epoch [24/30], Step [860/1250], Loss: 0.1232\n",
            "Epoch [24/30], Step [870/1250], Loss: 0.2167\n",
            "Epoch [24/30], Step [880/1250], Loss: 0.0108\n",
            "Epoch [24/30], Step [890/1250], Loss: 0.0074\n",
            "Epoch [24/30], Step [900/1250], Loss: 0.0010\n",
            "Epoch [24/30], Step [910/1250], Loss: 0.0210\n",
            "Epoch [24/30], Step [920/1250], Loss: 0.0084\n",
            "Epoch [24/30], Step [930/1250], Loss: 0.0560\n",
            "Epoch [24/30], Step [940/1250], Loss: 0.0131\n",
            "Epoch [24/30], Step [950/1250], Loss: 0.0028\n",
            "Epoch [24/30], Step [960/1250], Loss: 0.0538\n",
            "Epoch [24/30], Step [970/1250], Loss: 0.0115\n",
            "Epoch [24/30], Step [980/1250], Loss: 0.0113\n",
            "Epoch [24/30], Step [990/1250], Loss: 0.0092\n",
            "Epoch [24/30], Step [1000/1250], Loss: 0.0134\n",
            "Epoch [24/30], Step [1010/1250], Loss: 0.0434\n",
            "Epoch [24/30], Step [1020/1250], Loss: 0.1159\n",
            "Epoch [24/30], Step [1030/1250], Loss: 0.0478\n",
            "Epoch [24/30], Step [1040/1250], Loss: 0.0019\n",
            "Epoch [24/30], Step [1050/1250], Loss: 0.0054\n",
            "Epoch [24/30], Step [1060/1250], Loss: 0.0077\n",
            "Epoch [24/30], Step [1070/1250], Loss: 0.1375\n",
            "Epoch [24/30], Step [1080/1250], Loss: 0.0072\n",
            "Epoch [24/30], Step [1090/1250], Loss: 0.0031\n",
            "Epoch [24/30], Step [1100/1250], Loss: 0.0028\n",
            "Epoch [24/30], Step [1110/1250], Loss: 0.0190\n",
            "Epoch [24/30], Step [1120/1250], Loss: 0.0029\n",
            "Epoch [24/30], Step [1130/1250], Loss: 0.1785\n",
            "Epoch [24/30], Step [1140/1250], Loss: 0.1533\n",
            "Epoch [24/30], Step [1150/1250], Loss: 0.0568\n",
            "Epoch [24/30], Step [1160/1250], Loss: 0.1179\n",
            "Epoch [24/30], Step [1170/1250], Loss: 0.0099\n",
            "Epoch [24/30], Step [1180/1250], Loss: 0.0960\n",
            "Epoch [24/30], Step [1190/1250], Loss: 0.2469\n",
            "Epoch [24/30], Step [1200/1250], Loss: 0.0323\n",
            "Epoch [24/30], Step [1210/1250], Loss: 0.0041\n",
            "Epoch [24/30], Step [1220/1250], Loss: 0.0195\n",
            "Epoch [24/30], Step [1230/1250], Loss: 0.0265\n",
            "Epoch [24/30], Step [1240/1250], Loss: 0.0756\n",
            "Epoch [24/30], Step [1250/1250], Loss: 0.0137\n",
            "Epoch [25/30], Step [10/1250], Loss: 0.0058\n",
            "Epoch [25/30], Step [20/1250], Loss: 0.0117\n",
            "Epoch [25/30], Step [30/1250], Loss: 0.0534\n",
            "Epoch [25/30], Step [40/1250], Loss: 0.0010\n",
            "Epoch [25/30], Step [50/1250], Loss: 0.0353\n",
            "Epoch [25/30], Step [60/1250], Loss: 0.0391\n",
            "Epoch [25/30], Step [70/1250], Loss: 0.0080\n",
            "Epoch [25/30], Step [80/1250], Loss: 0.0040\n",
            "Epoch [25/30], Step [90/1250], Loss: 0.0178\n",
            "Epoch [25/30], Step [100/1250], Loss: 0.0071\n",
            "Epoch [25/30], Step [110/1250], Loss: 0.0330\n",
            "Epoch [25/30], Step [120/1250], Loss: 0.0106\n",
            "Epoch [25/30], Step [130/1250], Loss: 0.0707\n",
            "Epoch [25/30], Step [140/1250], Loss: 0.0071\n",
            "Epoch [25/30], Step [150/1250], Loss: 0.0163\n",
            "Epoch [25/30], Step [160/1250], Loss: 0.0228\n",
            "Epoch [25/30], Step [170/1250], Loss: 0.0669\n",
            "Epoch [25/30], Step [180/1250], Loss: 0.0038\n",
            "Epoch [25/30], Step [190/1250], Loss: 0.0277\n",
            "Epoch [25/30], Step [200/1250], Loss: 0.0098\n",
            "Epoch [25/30], Step [210/1250], Loss: 0.0074\n",
            "Epoch [25/30], Step [220/1250], Loss: 0.0082\n",
            "Epoch [25/30], Step [230/1250], Loss: 0.0311\n",
            "Epoch [25/30], Step [240/1250], Loss: 0.0045\n",
            "Epoch [25/30], Step [250/1250], Loss: 0.0406\n",
            "Epoch [25/30], Step [260/1250], Loss: 0.0032\n",
            "Epoch [25/30], Step [270/1250], Loss: 0.0039\n",
            "Epoch [25/30], Step [280/1250], Loss: 0.0024\n",
            "Epoch [25/30], Step [290/1250], Loss: 0.0087\n",
            "Epoch [25/30], Step [300/1250], Loss: 0.0218\n",
            "Epoch [25/30], Step [310/1250], Loss: 0.0085\n",
            "Epoch [25/30], Step [320/1250], Loss: 0.1448\n",
            "Epoch [25/30], Step [330/1250], Loss: 0.0030\n",
            "Epoch [25/30], Step [340/1250], Loss: 0.0123\n",
            "Epoch [25/30], Step [350/1250], Loss: 0.0251\n",
            "Epoch [25/30], Step [360/1250], Loss: 0.0003\n",
            "Epoch [25/30], Step [370/1250], Loss: 0.0221\n",
            "Epoch [25/30], Step [380/1250], Loss: 0.0103\n",
            "Epoch [25/30], Step [390/1250], Loss: 0.0081\n",
            "Epoch [25/30], Step [400/1250], Loss: 0.0124\n",
            "Epoch [25/30], Step [410/1250], Loss: 0.0031\n",
            "Epoch [25/30], Step [420/1250], Loss: 0.0135\n",
            "Epoch [25/30], Step [430/1250], Loss: 0.0037\n",
            "Epoch [25/30], Step [440/1250], Loss: 0.0410\n",
            "Epoch [25/30], Step [450/1250], Loss: 0.0265\n",
            "Epoch [25/30], Step [460/1250], Loss: 0.0006\n",
            "Epoch [25/30], Step [470/1250], Loss: 0.0592\n",
            "Epoch [25/30], Step [480/1250], Loss: 0.0065\n",
            "Epoch [25/30], Step [490/1250], Loss: 0.0312\n",
            "Epoch [25/30], Step [500/1250], Loss: 0.0890\n",
            "Epoch [25/30], Step [510/1250], Loss: 0.0030\n",
            "Epoch [25/30], Step [520/1250], Loss: 0.0313\n",
            "Epoch [25/30], Step [530/1250], Loss: 0.0620\n",
            "Epoch [25/30], Step [540/1250], Loss: 0.0458\n",
            "Epoch [25/30], Step [550/1250], Loss: 0.0239\n",
            "Epoch [25/30], Step [560/1250], Loss: 0.0188\n",
            "Epoch [25/30], Step [570/1250], Loss: 0.0085\n",
            "Epoch [25/30], Step [580/1250], Loss: 0.0122\n",
            "Epoch [25/30], Step [590/1250], Loss: 0.0427\n",
            "Epoch [25/30], Step [600/1250], Loss: 0.0050\n",
            "Epoch [25/30], Step [610/1250], Loss: 0.0435\n",
            "Epoch [25/30], Step [620/1250], Loss: 0.0084\n",
            "Epoch [25/30], Step [630/1250], Loss: 0.0186\n",
            "Epoch [25/30], Step [640/1250], Loss: 0.0462\n",
            "Epoch [25/30], Step [650/1250], Loss: 0.0372\n",
            "Epoch [25/30], Step [660/1250], Loss: 0.0585\n",
            "Epoch [25/30], Step [670/1250], Loss: 0.0218\n",
            "Epoch [25/30], Step [680/1250], Loss: 0.0441\n",
            "Epoch [25/30], Step [690/1250], Loss: 0.0243\n",
            "Epoch [25/30], Step [700/1250], Loss: 0.0107\n",
            "Epoch [25/30], Step [710/1250], Loss: 0.0060\n",
            "Epoch [25/30], Step [720/1250], Loss: 0.0162\n",
            "Epoch [25/30], Step [730/1250], Loss: 0.0298\n",
            "Epoch [25/30], Step [740/1250], Loss: 0.0367\n",
            "Epoch [25/30], Step [750/1250], Loss: 0.0377\n",
            "Epoch [25/30], Step [760/1250], Loss: 0.0437\n",
            "Epoch [25/30], Step [770/1250], Loss: 0.0234\n",
            "Epoch [25/30], Step [780/1250], Loss: 0.0073\n",
            "Epoch [25/30], Step [790/1250], Loss: 0.0054\n",
            "Epoch [25/30], Step [800/1250], Loss: 0.3137\n",
            "Epoch [25/30], Step [810/1250], Loss: 0.0024\n",
            "Epoch [25/30], Step [820/1250], Loss: 0.0560\n",
            "Epoch [25/30], Step [830/1250], Loss: 0.0016\n",
            "Epoch [25/30], Step [840/1250], Loss: 0.0028\n",
            "Epoch [25/30], Step [850/1250], Loss: 0.0043\n",
            "Epoch [25/30], Step [860/1250], Loss: 0.0504\n",
            "Epoch [25/30], Step [870/1250], Loss: 0.0794\n",
            "Epoch [25/30], Step [880/1250], Loss: 0.0014\n",
            "Epoch [25/30], Step [890/1250], Loss: 0.0036\n",
            "Epoch [25/30], Step [900/1250], Loss: 0.0173\n",
            "Epoch [25/30], Step [910/1250], Loss: 0.1713\n",
            "Epoch [25/30], Step [920/1250], Loss: 0.0096\n",
            "Epoch [25/30], Step [930/1250], Loss: 0.1582\n",
            "Epoch [25/30], Step [940/1250], Loss: 0.1163\n",
            "Epoch [25/30], Step [950/1250], Loss: 0.0370\n",
            "Epoch [25/30], Step [960/1250], Loss: 0.0218\n",
            "Epoch [25/30], Step [970/1250], Loss: 0.0053\n",
            "Epoch [25/30], Step [980/1250], Loss: 0.0184\n",
            "Epoch [25/30], Step [990/1250], Loss: 0.0408\n",
            "Epoch [25/30], Step [1000/1250], Loss: 0.0045\n",
            "Epoch [25/30], Step [1010/1250], Loss: 0.0056\n",
            "Epoch [25/30], Step [1020/1250], Loss: 0.0037\n",
            "Epoch [25/30], Step [1030/1250], Loss: 0.0653\n",
            "Epoch [25/30], Step [1040/1250], Loss: 0.0080\n",
            "Epoch [25/30], Step [1050/1250], Loss: 0.1901\n",
            "Epoch [25/30], Step [1060/1250], Loss: 0.0176\n",
            "Epoch [25/30], Step [1070/1250], Loss: 0.0050\n",
            "Epoch [25/30], Step [1080/1250], Loss: 0.0098\n",
            "Epoch [25/30], Step [1090/1250], Loss: 0.0421\n",
            "Epoch [25/30], Step [1100/1250], Loss: 0.0058\n",
            "Epoch [25/30], Step [1110/1250], Loss: 0.0277\n",
            "Epoch [25/30], Step [1120/1250], Loss: 0.0077\n",
            "Epoch [25/30], Step [1130/1250], Loss: 0.1658\n",
            "Epoch [25/30], Step [1140/1250], Loss: 0.0066\n",
            "Epoch [25/30], Step [1150/1250], Loss: 0.0247\n",
            "Epoch [25/30], Step [1160/1250], Loss: 0.0151\n",
            "Epoch [25/30], Step [1170/1250], Loss: 0.0054\n",
            "Epoch [25/30], Step [1180/1250], Loss: 0.0595\n",
            "Epoch [25/30], Step [1190/1250], Loss: 0.0222\n",
            "Epoch [25/30], Step [1200/1250], Loss: 0.0140\n",
            "Epoch [25/30], Step [1210/1250], Loss: 0.1110\n",
            "Epoch [25/30], Step [1220/1250], Loss: 0.0006\n",
            "Epoch [25/30], Step [1230/1250], Loss: 0.0309\n",
            "Epoch [25/30], Step [1240/1250], Loss: 0.0108\n",
            "Epoch [25/30], Step [1250/1250], Loss: 0.0166\n",
            "Epoch [26/30], Step [10/1250], Loss: 0.0419\n",
            "Epoch [26/30], Step [20/1250], Loss: 0.0107\n",
            "Epoch [26/30], Step [30/1250], Loss: 0.0135\n",
            "Epoch [26/30], Step [40/1250], Loss: 0.0081\n",
            "Epoch [26/30], Step [50/1250], Loss: 0.0212\n",
            "Epoch [26/30], Step [60/1250], Loss: 0.0415\n",
            "Epoch [26/30], Step [70/1250], Loss: 0.0029\n",
            "Epoch [26/30], Step [80/1250], Loss: 0.0291\n",
            "Epoch [26/30], Step [90/1250], Loss: 0.2265\n",
            "Epoch [26/30], Step [100/1250], Loss: 0.0222\n",
            "Epoch [26/30], Step [110/1250], Loss: 0.0075\n",
            "Epoch [26/30], Step [120/1250], Loss: 0.0067\n",
            "Epoch [26/30], Step [130/1250], Loss: 0.0334\n",
            "Epoch [26/30], Step [140/1250], Loss: 0.0047\n",
            "Epoch [26/30], Step [150/1250], Loss: 0.0207\n",
            "Epoch [26/30], Step [160/1250], Loss: 0.0034\n",
            "Epoch [26/30], Step [170/1250], Loss: 0.0288\n",
            "Epoch [26/30], Step [180/1250], Loss: 0.0275\n",
            "Epoch [26/30], Step [190/1250], Loss: 0.1339\n",
            "Epoch [26/30], Step [200/1250], Loss: 0.0446\n",
            "Epoch [26/30], Step [210/1250], Loss: 0.1856\n",
            "Epoch [26/30], Step [220/1250], Loss: 0.0106\n",
            "Epoch [26/30], Step [230/1250], Loss: 0.0613\n",
            "Epoch [26/30], Step [240/1250], Loss: 0.1047\n",
            "Epoch [26/30], Step [250/1250], Loss: 0.0147\n",
            "Epoch [26/30], Step [260/1250], Loss: 0.0121\n",
            "Epoch [26/30], Step [270/1250], Loss: 0.0162\n",
            "Epoch [26/30], Step [280/1250], Loss: 0.0162\n",
            "Epoch [26/30], Step [290/1250], Loss: 0.0258\n",
            "Epoch [26/30], Step [300/1250], Loss: 0.0105\n",
            "Epoch [26/30], Step [310/1250], Loss: 0.0023\n",
            "Epoch [26/30], Step [320/1250], Loss: 0.0389\n",
            "Epoch [26/30], Step [330/1250], Loss: 0.0181\n",
            "Epoch [26/30], Step [340/1250], Loss: 0.0834\n",
            "Epoch [26/30], Step [350/1250], Loss: 0.0165\n",
            "Epoch [26/30], Step [360/1250], Loss: 0.0041\n",
            "Epoch [26/30], Step [370/1250], Loss: 0.0013\n",
            "Epoch [26/30], Step [380/1250], Loss: 0.0224\n",
            "Epoch [26/30], Step [390/1250], Loss: 0.0020\n",
            "Epoch [26/30], Step [400/1250], Loss: 0.0007\n",
            "Epoch [26/30], Step [410/1250], Loss: 0.1379\n",
            "Epoch [26/30], Step [420/1250], Loss: 0.1342\n",
            "Epoch [26/30], Step [430/1250], Loss: 0.0133\n",
            "Epoch [26/30], Step [440/1250], Loss: 0.0018\n",
            "Epoch [26/30], Step [450/1250], Loss: 0.0040\n",
            "Epoch [26/30], Step [460/1250], Loss: 0.0094\n",
            "Epoch [26/30], Step [470/1250], Loss: 0.0025\n",
            "Epoch [26/30], Step [480/1250], Loss: 0.0391\n",
            "Epoch [26/30], Step [490/1250], Loss: 0.0125\n",
            "Epoch [26/30], Step [500/1250], Loss: 0.0186\n",
            "Epoch [26/30], Step [510/1250], Loss: 0.0064\n",
            "Epoch [26/30], Step [520/1250], Loss: 0.0027\n",
            "Epoch [26/30], Step [530/1250], Loss: 0.0182\n",
            "Epoch [26/30], Step [540/1250], Loss: 0.0031\n",
            "Epoch [26/30], Step [550/1250], Loss: 0.0031\n",
            "Epoch [26/30], Step [560/1250], Loss: 0.0270\n",
            "Epoch [26/30], Step [570/1250], Loss: 0.0357\n",
            "Epoch [26/30], Step [580/1250], Loss: 0.0053\n",
            "Epoch [26/30], Step [590/1250], Loss: 0.0448\n",
            "Epoch [26/30], Step [600/1250], Loss: 0.0552\n",
            "Epoch [26/30], Step [610/1250], Loss: 0.0071\n",
            "Epoch [26/30], Step [620/1250], Loss: 0.0119\n",
            "Epoch [26/30], Step [630/1250], Loss: 0.0014\n",
            "Epoch [26/30], Step [640/1250], Loss: 0.0140\n",
            "Epoch [26/30], Step [650/1250], Loss: 0.0394\n",
            "Epoch [26/30], Step [660/1250], Loss: 0.1028\n",
            "Epoch [26/30], Step [670/1250], Loss: 0.0363\n",
            "Epoch [26/30], Step [680/1250], Loss: 0.0040\n",
            "Epoch [26/30], Step [690/1250], Loss: 0.0552\n",
            "Epoch [26/30], Step [700/1250], Loss: 0.0101\n",
            "Epoch [26/30], Step [710/1250], Loss: 0.0537\n",
            "Epoch [26/30], Step [720/1250], Loss: 0.0185\n",
            "Epoch [26/30], Step [730/1250], Loss: 0.2023\n",
            "Epoch [26/30], Step [740/1250], Loss: 0.0245\n",
            "Epoch [26/30], Step [750/1250], Loss: 0.0048\n",
            "Epoch [26/30], Step [760/1250], Loss: 0.0214\n",
            "Epoch [26/30], Step [770/1250], Loss: 0.0023\n",
            "Epoch [26/30], Step [780/1250], Loss: 0.0063\n",
            "Epoch [26/30], Step [790/1250], Loss: 0.0600\n",
            "Epoch [26/30], Step [800/1250], Loss: 0.0208\n",
            "Epoch [26/30], Step [810/1250], Loss: 0.0218\n",
            "Epoch [26/30], Step [820/1250], Loss: 0.0096\n",
            "Epoch [26/30], Step [830/1250], Loss: 0.0308\n",
            "Epoch [26/30], Step [840/1250], Loss: 0.0919\n",
            "Epoch [26/30], Step [850/1250], Loss: 0.0143\n",
            "Epoch [26/30], Step [860/1250], Loss: 0.0009\n",
            "Epoch [26/30], Step [870/1250], Loss: 0.0248\n",
            "Epoch [26/30], Step [880/1250], Loss: 0.0268\n",
            "Epoch [26/30], Step [890/1250], Loss: 0.0072\n",
            "Epoch [26/30], Step [900/1250], Loss: 0.0225\n",
            "Epoch [26/30], Step [910/1250], Loss: 0.0076\n",
            "Epoch [26/30], Step [920/1250], Loss: 0.0070\n",
            "Epoch [26/30], Step [930/1250], Loss: 0.1087\n",
            "Epoch [26/30], Step [940/1250], Loss: 0.0013\n",
            "Epoch [26/30], Step [950/1250], Loss: 0.0020\n",
            "Epoch [26/30], Step [960/1250], Loss: 0.1782\n",
            "Epoch [26/30], Step [970/1250], Loss: 0.0030\n",
            "Epoch [26/30], Step [980/1250], Loss: 0.0466\n",
            "Epoch [26/30], Step [990/1250], Loss: 0.0662\n",
            "Epoch [26/30], Step [1000/1250], Loss: 0.0117\n",
            "Epoch [26/30], Step [1010/1250], Loss: 0.0211\n",
            "Epoch [26/30], Step [1020/1250], Loss: 0.1021\n",
            "Epoch [26/30], Step [1030/1250], Loss: 0.0027\n",
            "Epoch [26/30], Step [1040/1250], Loss: 0.0051\n",
            "Epoch [26/30], Step [1050/1250], Loss: 0.0111\n",
            "Epoch [26/30], Step [1060/1250], Loss: 0.0194\n",
            "Epoch [26/30], Step [1070/1250], Loss: 0.0005\n",
            "Epoch [26/30], Step [1080/1250], Loss: 0.0072\n",
            "Epoch [26/30], Step [1090/1250], Loss: 0.0090\n",
            "Epoch [26/30], Step [1100/1250], Loss: 0.0174\n",
            "Epoch [26/30], Step [1110/1250], Loss: 0.0176\n",
            "Epoch [26/30], Step [1120/1250], Loss: 0.0072\n",
            "Epoch [26/30], Step [1130/1250], Loss: 0.0513\n",
            "Epoch [26/30], Step [1140/1250], Loss: 0.0002\n",
            "Epoch [26/30], Step [1150/1250], Loss: 0.1037\n",
            "Epoch [26/30], Step [1160/1250], Loss: 0.0394\n",
            "Epoch [26/30], Step [1170/1250], Loss: 0.0865\n",
            "Epoch [26/30], Step [1180/1250], Loss: 0.0015\n",
            "Epoch [26/30], Step [1190/1250], Loss: 0.0478\n",
            "Epoch [26/30], Step [1200/1250], Loss: 0.0032\n",
            "Epoch [26/30], Step [1210/1250], Loss: 0.0093\n",
            "Epoch [26/30], Step [1220/1250], Loss: 0.1526\n",
            "Epoch [26/30], Step [1230/1250], Loss: 0.0048\n",
            "Epoch [26/30], Step [1240/1250], Loss: 0.0058\n",
            "Epoch [26/30], Step [1250/1250], Loss: 0.0297\n",
            "Epoch [27/30], Step [10/1250], Loss: 0.0660\n",
            "Epoch [27/30], Step [20/1250], Loss: 0.0041\n",
            "Epoch [27/30], Step [30/1250], Loss: 0.1916\n",
            "Epoch [27/30], Step [40/1250], Loss: 0.0519\n",
            "Epoch [27/30], Step [50/1250], Loss: 0.0069\n",
            "Epoch [27/30], Step [60/1250], Loss: 0.0029\n",
            "Epoch [27/30], Step [70/1250], Loss: 0.0093\n",
            "Epoch [27/30], Step [80/1250], Loss: 0.0532\n",
            "Epoch [27/30], Step [90/1250], Loss: 0.0334\n",
            "Epoch [27/30], Step [100/1250], Loss: 0.0067\n",
            "Epoch [27/30], Step [110/1250], Loss: 0.0878\n",
            "Epoch [27/30], Step [120/1250], Loss: 0.0044\n",
            "Epoch [27/30], Step [130/1250], Loss: 0.1054\n",
            "Epoch [27/30], Step [140/1250], Loss: 0.0042\n",
            "Epoch [27/30], Step [150/1250], Loss: 0.0026\n",
            "Epoch [27/30], Step [160/1250], Loss: 0.0019\n",
            "Epoch [27/30], Step [170/1250], Loss: 0.0569\n",
            "Epoch [27/30], Step [180/1250], Loss: 0.0338\n",
            "Epoch [27/30], Step [190/1250], Loss: 0.0017\n",
            "Epoch [27/30], Step [200/1250], Loss: 0.0024\n",
            "Epoch [27/30], Step [210/1250], Loss: 0.0016\n",
            "Epoch [27/30], Step [220/1250], Loss: 0.0077\n",
            "Epoch [27/30], Step [230/1250], Loss: 0.0434\n",
            "Epoch [27/30], Step [240/1250], Loss: 0.0529\n",
            "Epoch [27/30], Step [250/1250], Loss: 0.0039\n",
            "Epoch [27/30], Step [260/1250], Loss: 0.0010\n",
            "Epoch [27/30], Step [270/1250], Loss: 0.0012\n",
            "Epoch [27/30], Step [280/1250], Loss: 0.0343\n",
            "Epoch [27/30], Step [290/1250], Loss: 0.0436\n",
            "Epoch [27/30], Step [300/1250], Loss: 0.0058\n",
            "Epoch [27/30], Step [310/1250], Loss: 0.0475\n",
            "Epoch [27/30], Step [320/1250], Loss: 0.0080\n",
            "Epoch [27/30], Step [330/1250], Loss: 0.0022\n",
            "Epoch [27/30], Step [340/1250], Loss: 0.0100\n",
            "Epoch [27/30], Step [350/1250], Loss: 0.0540\n",
            "Epoch [27/30], Step [360/1250], Loss: 0.0098\n",
            "Epoch [27/30], Step [370/1250], Loss: 0.0013\n",
            "Epoch [27/30], Step [380/1250], Loss: 0.0003\n",
            "Epoch [27/30], Step [390/1250], Loss: 0.0192\n",
            "Epoch [27/30], Step [400/1250], Loss: 0.0499\n",
            "Epoch [27/30], Step [410/1250], Loss: 0.0005\n",
            "Epoch [27/30], Step [420/1250], Loss: 0.0075\n",
            "Epoch [27/30], Step [430/1250], Loss: 0.0135\n",
            "Epoch [27/30], Step [440/1250], Loss: 0.0009\n",
            "Epoch [27/30], Step [450/1250], Loss: 0.0198\n",
            "Epoch [27/30], Step [460/1250], Loss: 0.0005\n",
            "Epoch [27/30], Step [470/1250], Loss: 0.1159\n",
            "Epoch [27/30], Step [480/1250], Loss: 0.0076\n",
            "Epoch [27/30], Step [490/1250], Loss: 0.0038\n",
            "Epoch [27/30], Step [500/1250], Loss: 0.0521\n",
            "Epoch [27/30], Step [510/1250], Loss: 0.0101\n",
            "Epoch [27/30], Step [520/1250], Loss: 0.0216\n",
            "Epoch [27/30], Step [530/1250], Loss: 0.0995\n",
            "Epoch [27/30], Step [540/1250], Loss: 0.1304\n",
            "Epoch [27/30], Step [550/1250], Loss: 0.0234\n",
            "Epoch [27/30], Step [560/1250], Loss: 0.1319\n",
            "Epoch [27/30], Step [570/1250], Loss: 0.0062\n",
            "Epoch [27/30], Step [580/1250], Loss: 0.0263\n",
            "Epoch [27/30], Step [590/1250], Loss: 0.0263\n",
            "Epoch [27/30], Step [600/1250], Loss: 0.0024\n",
            "Epoch [27/30], Step [610/1250], Loss: 0.0452\n",
            "Epoch [27/30], Step [620/1250], Loss: 0.0015\n",
            "Epoch [27/30], Step [630/1250], Loss: 0.0291\n",
            "Epoch [27/30], Step [640/1250], Loss: 0.0397\n",
            "Epoch [27/30], Step [650/1250], Loss: 0.0081\n",
            "Epoch [27/30], Step [660/1250], Loss: 0.0306\n",
            "Epoch [27/30], Step [670/1250], Loss: 0.0079\n",
            "Epoch [27/30], Step [680/1250], Loss: 0.0924\n",
            "Epoch [27/30], Step [690/1250], Loss: 0.0201\n",
            "Epoch [27/30], Step [700/1250], Loss: 0.0074\n",
            "Epoch [27/30], Step [710/1250], Loss: 0.0465\n",
            "Epoch [27/30], Step [720/1250], Loss: 0.0020\n",
            "Epoch [27/30], Step [730/1250], Loss: 0.0037\n",
            "Epoch [27/30], Step [740/1250], Loss: 0.0042\n",
            "Epoch [27/30], Step [750/1250], Loss: 0.0208\n",
            "Epoch [27/30], Step [760/1250], Loss: 0.0098\n",
            "Epoch [27/30], Step [770/1250], Loss: 0.0655\n",
            "Epoch [27/30], Step [780/1250], Loss: 0.0206\n",
            "Epoch [27/30], Step [790/1250], Loss: 0.0120\n",
            "Epoch [27/30], Step [800/1250], Loss: 0.0046\n",
            "Epoch [27/30], Step [810/1250], Loss: 0.0011\n",
            "Epoch [27/30], Step [820/1250], Loss: 0.0139\n",
            "Epoch [27/30], Step [830/1250], Loss: 0.0015\n",
            "Epoch [27/30], Step [840/1250], Loss: 0.0290\n",
            "Epoch [27/30], Step [850/1250], Loss: 0.0060\n",
            "Epoch [27/30], Step [860/1250], Loss: 0.0025\n",
            "Epoch [27/30], Step [870/1250], Loss: 0.0063\n",
            "Epoch [27/30], Step [880/1250], Loss: 0.0194\n",
            "Epoch [27/30], Step [890/1250], Loss: 0.0665\n",
            "Epoch [27/30], Step [900/1250], Loss: 0.0123\n",
            "Epoch [27/30], Step [910/1250], Loss: 0.0086\n",
            "Epoch [27/30], Step [920/1250], Loss: 0.0443\n",
            "Epoch [27/30], Step [930/1250], Loss: 0.0102\n",
            "Epoch [27/30], Step [940/1250], Loss: 0.0224\n",
            "Epoch [27/30], Step [950/1250], Loss: 0.0141\n",
            "Epoch [27/30], Step [960/1250], Loss: 0.0043\n",
            "Epoch [27/30], Step [970/1250], Loss: 0.0371\n",
            "Epoch [27/30], Step [980/1250], Loss: 0.0016\n",
            "Epoch [27/30], Step [990/1250], Loss: 0.0234\n",
            "Epoch [27/30], Step [1000/1250], Loss: 0.0035\n",
            "Epoch [27/30], Step [1010/1250], Loss: 0.0465\n",
            "Epoch [27/30], Step [1020/1250], Loss: 0.0015\n",
            "Epoch [27/30], Step [1030/1250], Loss: 0.0007\n",
            "Epoch [27/30], Step [1040/1250], Loss: 0.0081\n",
            "Epoch [27/30], Step [1050/1250], Loss: 0.0092\n",
            "Epoch [27/30], Step [1060/1250], Loss: 0.0411\n",
            "Epoch [27/30], Step [1070/1250], Loss: 0.0022\n",
            "Epoch [27/30], Step [1080/1250], Loss: 0.0004\n",
            "Epoch [27/30], Step [1090/1250], Loss: 0.0463\n",
            "Epoch [27/30], Step [1100/1250], Loss: 0.0061\n",
            "Epoch [27/30], Step [1110/1250], Loss: 0.0137\n",
            "Epoch [27/30], Step [1120/1250], Loss: 0.0038\n",
            "Epoch [27/30], Step [1130/1250], Loss: 0.0036\n",
            "Epoch [27/30], Step [1140/1250], Loss: 0.0250\n",
            "Epoch [27/30], Step [1150/1250], Loss: 0.0092\n",
            "Epoch [27/30], Step [1160/1250], Loss: 0.0281\n",
            "Epoch [27/30], Step [1170/1250], Loss: 0.0359\n",
            "Epoch [27/30], Step [1180/1250], Loss: 0.0019\n",
            "Epoch [27/30], Step [1190/1250], Loss: 0.0033\n",
            "Epoch [27/30], Step [1200/1250], Loss: 0.1312\n",
            "Epoch [27/30], Step [1210/1250], Loss: 0.0037\n",
            "Epoch [27/30], Step [1220/1250], Loss: 0.0117\n",
            "Epoch [27/30], Step [1230/1250], Loss: 0.0710\n",
            "Epoch [27/30], Step [1240/1250], Loss: 0.0172\n",
            "Epoch [27/30], Step [1250/1250], Loss: 0.1904\n",
            "Epoch [28/30], Step [10/1250], Loss: 0.0116\n",
            "Epoch [28/30], Step [20/1250], Loss: 0.0201\n",
            "Epoch [28/30], Step [30/1250], Loss: 0.0017\n",
            "Epoch [28/30], Step [40/1250], Loss: 0.0037\n",
            "Epoch [28/30], Step [50/1250], Loss: 0.0433\n",
            "Epoch [28/30], Step [60/1250], Loss: 0.0052\n",
            "Epoch [28/30], Step [70/1250], Loss: 0.0751\n",
            "Epoch [28/30], Step [80/1250], Loss: 0.0005\n",
            "Epoch [28/30], Step [90/1250], Loss: 0.0218\n",
            "Epoch [28/30], Step [100/1250], Loss: 0.0026\n",
            "Epoch [28/30], Step [110/1250], Loss: 0.0293\n",
            "Epoch [28/30], Step [120/1250], Loss: 0.0165\n",
            "Epoch [28/30], Step [130/1250], Loss: 0.0137\n",
            "Epoch [28/30], Step [140/1250], Loss: 0.0193\n",
            "Epoch [28/30], Step [150/1250], Loss: 0.0029\n",
            "Epoch [28/30], Step [160/1250], Loss: 0.0408\n",
            "Epoch [28/30], Step [170/1250], Loss: 0.0012\n",
            "Epoch [28/30], Step [180/1250], Loss: 0.0093\n",
            "Epoch [28/30], Step [190/1250], Loss: 0.0014\n",
            "Epoch [28/30], Step [200/1250], Loss: 0.0083\n",
            "Epoch [28/30], Step [210/1250], Loss: 0.0012\n",
            "Epoch [28/30], Step [220/1250], Loss: 0.0348\n",
            "Epoch [28/30], Step [230/1250], Loss: 0.0035\n",
            "Epoch [28/30], Step [240/1250], Loss: 0.0188\n",
            "Epoch [28/30], Step [250/1250], Loss: 0.0054\n",
            "Epoch [28/30], Step [260/1250], Loss: 0.0042\n",
            "Epoch [28/30], Step [270/1250], Loss: 0.0010\n",
            "Epoch [28/30], Step [280/1250], Loss: 0.0049\n",
            "Epoch [28/30], Step [290/1250], Loss: 0.0517\n",
            "Epoch [28/30], Step [300/1250], Loss: 0.0301\n",
            "Epoch [28/30], Step [310/1250], Loss: 0.0109\n",
            "Epoch [28/30], Step [320/1250], Loss: 0.0015\n",
            "Epoch [28/30], Step [330/1250], Loss: 0.0196\n",
            "Epoch [28/30], Step [340/1250], Loss: 0.1801\n",
            "Epoch [28/30], Step [350/1250], Loss: 0.0011\n",
            "Epoch [28/30], Step [360/1250], Loss: 0.0276\n",
            "Epoch [28/30], Step [370/1250], Loss: 0.0021\n",
            "Epoch [28/30], Step [380/1250], Loss: 0.0139\n",
            "Epoch [28/30], Step [390/1250], Loss: 0.0122\n",
            "Epoch [28/30], Step [400/1250], Loss: 0.0187\n",
            "Epoch [28/30], Step [410/1250], Loss: 0.0035\n",
            "Epoch [28/30], Step [420/1250], Loss: 0.0048\n",
            "Epoch [28/30], Step [430/1250], Loss: 0.0524\n",
            "Epoch [28/30], Step [440/1250], Loss: 0.0006\n",
            "Epoch [28/30], Step [450/1250], Loss: 0.0026\n",
            "Epoch [28/30], Step [460/1250], Loss: 0.0029\n",
            "Epoch [28/30], Step [470/1250], Loss: 0.0103\n",
            "Epoch [28/30], Step [480/1250], Loss: 0.0009\n",
            "Epoch [28/30], Step [490/1250], Loss: 0.0071\n",
            "Epoch [28/30], Step [500/1250], Loss: 0.1591\n",
            "Epoch [28/30], Step [510/1250], Loss: 0.0277\n",
            "Epoch [28/30], Step [520/1250], Loss: 0.0030\n",
            "Epoch [28/30], Step [530/1250], Loss: 0.0034\n",
            "Epoch [28/30], Step [540/1250], Loss: 0.0044\n",
            "Epoch [28/30], Step [550/1250], Loss: 0.0057\n",
            "Epoch [28/30], Step [560/1250], Loss: 0.0005\n",
            "Epoch [28/30], Step [570/1250], Loss: 0.0033\n",
            "Epoch [28/30], Step [580/1250], Loss: 0.0019\n",
            "Epoch [28/30], Step [590/1250], Loss: 0.0108\n",
            "Epoch [28/30], Step [600/1250], Loss: 0.1400\n",
            "Epoch [28/30], Step [610/1250], Loss: 0.0082\n",
            "Epoch [28/30], Step [620/1250], Loss: 0.2385\n",
            "Epoch [28/30], Step [630/1250], Loss: 0.0048\n",
            "Epoch [28/30], Step [640/1250], Loss: 0.0078\n",
            "Epoch [28/30], Step [650/1250], Loss: 0.0205\n",
            "Epoch [28/30], Step [660/1250], Loss: 0.0036\n",
            "Epoch [28/30], Step [670/1250], Loss: 0.0573\n",
            "Epoch [28/30], Step [680/1250], Loss: 0.0036\n",
            "Epoch [28/30], Step [690/1250], Loss: 0.0113\n",
            "Epoch [28/30], Step [700/1250], Loss: 0.0239\n",
            "Epoch [28/30], Step [710/1250], Loss: 0.0386\n",
            "Epoch [28/30], Step [720/1250], Loss: 0.0013\n",
            "Epoch [28/30], Step [730/1250], Loss: 0.0056\n",
            "Epoch [28/30], Step [740/1250], Loss: 0.0008\n",
            "Epoch [28/30], Step [750/1250], Loss: 0.0254\n",
            "Epoch [28/30], Step [760/1250], Loss: 0.0080\n",
            "Epoch [28/30], Step [770/1250], Loss: 0.0013\n",
            "Epoch [28/30], Step [780/1250], Loss: 0.0033\n",
            "Epoch [28/30], Step [790/1250], Loss: 0.0222\n",
            "Epoch [28/30], Step [800/1250], Loss: 0.0874\n",
            "Epoch [28/30], Step [810/1250], Loss: 0.0361\n",
            "Epoch [28/30], Step [820/1250], Loss: 0.0083\n",
            "Epoch [28/30], Step [830/1250], Loss: 0.0042\n",
            "Epoch [28/30], Step [840/1250], Loss: 0.0032\n",
            "Epoch [28/30], Step [850/1250], Loss: 0.0050\n",
            "Epoch [28/30], Step [860/1250], Loss: 0.0071\n",
            "Epoch [28/30], Step [870/1250], Loss: 0.0318\n",
            "Epoch [28/30], Step [880/1250], Loss: 0.0389\n",
            "Epoch [28/30], Step [890/1250], Loss: 0.0392\n",
            "Epoch [28/30], Step [900/1250], Loss: 0.0013\n",
            "Epoch [28/30], Step [910/1250], Loss: 0.0124\n",
            "Epoch [28/30], Step [920/1250], Loss: 0.0147\n",
            "Epoch [28/30], Step [930/1250], Loss: 0.0017\n",
            "Epoch [28/30], Step [940/1250], Loss: 0.0262\n",
            "Epoch [28/30], Step [950/1250], Loss: 0.0031\n",
            "Epoch [28/30], Step [960/1250], Loss: 0.0008\n",
            "Epoch [28/30], Step [970/1250], Loss: 0.0005\n",
            "Epoch [28/30], Step [980/1250], Loss: 0.1407\n",
            "Epoch [28/30], Step [990/1250], Loss: 0.0395\n",
            "Epoch [28/30], Step [1000/1250], Loss: 0.0387\n",
            "Epoch [28/30], Step [1010/1250], Loss: 0.0277\n",
            "Epoch [28/30], Step [1020/1250], Loss: 0.0042\n",
            "Epoch [28/30], Step [1030/1250], Loss: 0.0816\n",
            "Epoch [28/30], Step [1040/1250], Loss: 0.0078\n",
            "Epoch [28/30], Step [1050/1250], Loss: 0.0122\n",
            "Epoch [28/30], Step [1060/1250], Loss: 0.0329\n",
            "Epoch [28/30], Step [1070/1250], Loss: 0.1221\n",
            "Epoch [28/30], Step [1080/1250], Loss: 0.0122\n",
            "Epoch [28/30], Step [1090/1250], Loss: 0.0275\n",
            "Epoch [28/30], Step [1100/1250], Loss: 0.0070\n",
            "Epoch [28/30], Step [1110/1250], Loss: 0.0782\n",
            "Epoch [28/30], Step [1120/1250], Loss: 0.0267\n",
            "Epoch [28/30], Step [1130/1250], Loss: 0.0968\n",
            "Epoch [28/30], Step [1140/1250], Loss: 0.2644\n",
            "Epoch [28/30], Step [1150/1250], Loss: 0.0243\n",
            "Epoch [28/30], Step [1160/1250], Loss: 0.0028\n",
            "Epoch [28/30], Step [1170/1250], Loss: 0.0047\n",
            "Epoch [28/30], Step [1180/1250], Loss: 0.1707\n",
            "Epoch [28/30], Step [1190/1250], Loss: 0.0224\n",
            "Epoch [28/30], Step [1200/1250], Loss: 0.0213\n",
            "Epoch [28/30], Step [1210/1250], Loss: 0.0001\n",
            "Epoch [28/30], Step [1220/1250], Loss: 0.0064\n",
            "Epoch [28/30], Step [1230/1250], Loss: 0.0011\n",
            "Epoch [28/30], Step [1240/1250], Loss: 0.0160\n",
            "Epoch [28/30], Step [1250/1250], Loss: 0.0594\n",
            "Epoch [29/30], Step [10/1250], Loss: 0.0034\n",
            "Epoch [29/30], Step [20/1250], Loss: 0.0424\n",
            "Epoch [29/30], Step [30/1250], Loss: 0.0098\n",
            "Epoch [29/30], Step [40/1250], Loss: 0.0145\n",
            "Epoch [29/30], Step [50/1250], Loss: 0.0018\n",
            "Epoch [29/30], Step [60/1250], Loss: 0.0182\n",
            "Epoch [29/30], Step [70/1250], Loss: 0.1244\n",
            "Epoch [29/30], Step [80/1250], Loss: 0.0024\n",
            "Epoch [29/30], Step [90/1250], Loss: 0.0015\n",
            "Epoch [29/30], Step [100/1250], Loss: 0.2953\n",
            "Epoch [29/30], Step [110/1250], Loss: 0.0003\n",
            "Epoch [29/30], Step [120/1250], Loss: 0.0045\n",
            "Epoch [29/30], Step [130/1250], Loss: 0.0071\n",
            "Epoch [29/30], Step [140/1250], Loss: 0.0012\n",
            "Epoch [29/30], Step [150/1250], Loss: 0.0071\n",
            "Epoch [29/30], Step [160/1250], Loss: 0.0313\n",
            "Epoch [29/30], Step [170/1250], Loss: 0.0175\n",
            "Epoch [29/30], Step [180/1250], Loss: 0.0481\n",
            "Epoch [29/30], Step [190/1250], Loss: 0.0620\n",
            "Epoch [29/30], Step [200/1250], Loss: 0.0335\n",
            "Epoch [29/30], Step [210/1250], Loss: 0.0096\n",
            "Epoch [29/30], Step [220/1250], Loss: 0.1340\n",
            "Epoch [29/30], Step [230/1250], Loss: 0.0463\n",
            "Epoch [29/30], Step [240/1250], Loss: 0.0834\n",
            "Epoch [29/30], Step [250/1250], Loss: 0.0055\n",
            "Epoch [29/30], Step [260/1250], Loss: 0.0009\n",
            "Epoch [29/30], Step [270/1250], Loss: 0.0079\n",
            "Epoch [29/30], Step [280/1250], Loss: 0.0624\n",
            "Epoch [29/30], Step [290/1250], Loss: 0.0341\n",
            "Epoch [29/30], Step [300/1250], Loss: 0.0050\n",
            "Epoch [29/30], Step [310/1250], Loss: 0.0213\n",
            "Epoch [29/30], Step [320/1250], Loss: 0.0453\n",
            "Epoch [29/30], Step [330/1250], Loss: 0.0025\n",
            "Epoch [29/30], Step [340/1250], Loss: 0.0192\n",
            "Epoch [29/30], Step [350/1250], Loss: 0.0093\n",
            "Epoch [29/30], Step [360/1250], Loss: 0.0112\n",
            "Epoch [29/30], Step [370/1250], Loss: 0.0048\n",
            "Epoch [29/30], Step [380/1250], Loss: 0.0048\n",
            "Epoch [29/30], Step [390/1250], Loss: 0.0017\n",
            "Epoch [29/30], Step [400/1250], Loss: 0.0017\n",
            "Epoch [29/30], Step [410/1250], Loss: 0.0015\n",
            "Epoch [29/30], Step [420/1250], Loss: 0.0276\n",
            "Epoch [29/30], Step [430/1250], Loss: 0.0010\n",
            "Epoch [29/30], Step [440/1250], Loss: 0.0313\n",
            "Epoch [29/30], Step [450/1250], Loss: 0.0099\n",
            "Epoch [29/30], Step [460/1250], Loss: 0.0357\n",
            "Epoch [29/30], Step [470/1250], Loss: 0.0086\n",
            "Epoch [29/30], Step [480/1250], Loss: 0.0512\n",
            "Epoch [29/30], Step [490/1250], Loss: 0.0681\n",
            "Epoch [29/30], Step [500/1250], Loss: 0.0014\n",
            "Epoch [29/30], Step [510/1250], Loss: 0.0003\n",
            "Epoch [29/30], Step [520/1250], Loss: 0.0227\n",
            "Epoch [29/30], Step [530/1250], Loss: 0.0023\n",
            "Epoch [29/30], Step [540/1250], Loss: 0.0152\n",
            "Epoch [29/30], Step [550/1250], Loss: 0.0005\n",
            "Epoch [29/30], Step [560/1250], Loss: 0.0011\n",
            "Epoch [29/30], Step [570/1250], Loss: 0.0017\n",
            "Epoch [29/30], Step [580/1250], Loss: 0.0019\n",
            "Epoch [29/30], Step [590/1250], Loss: 0.0306\n",
            "Epoch [29/30], Step [600/1250], Loss: 0.0474\n",
            "Epoch [29/30], Step [610/1250], Loss: 0.0211\n",
            "Epoch [29/30], Step [620/1250], Loss: 0.0027\n",
            "Epoch [29/30], Step [630/1250], Loss: 0.0028\n",
            "Epoch [29/30], Step [640/1250], Loss: 0.0126\n",
            "Epoch [29/30], Step [650/1250], Loss: 0.0011\n",
            "Epoch [29/30], Step [660/1250], Loss: 0.0125\n",
            "Epoch [29/30], Step [670/1250], Loss: 0.0436\n",
            "Epoch [29/30], Step [680/1250], Loss: 0.0046\n",
            "Epoch [29/30], Step [690/1250], Loss: 0.0019\n",
            "Epoch [29/30], Step [700/1250], Loss: 0.0188\n",
            "Epoch [29/30], Step [710/1250], Loss: 0.0089\n",
            "Epoch [29/30], Step [720/1250], Loss: 0.0266\n",
            "Epoch [29/30], Step [730/1250], Loss: 0.0011\n",
            "Epoch [29/30], Step [740/1250], Loss: 0.0033\n",
            "Epoch [29/30], Step [750/1250], Loss: 0.0535\n",
            "Epoch [29/30], Step [760/1250], Loss: 0.0012\n",
            "Epoch [29/30], Step [770/1250], Loss: 0.0020\n",
            "Epoch [29/30], Step [780/1250], Loss: 0.0023\n",
            "Epoch [29/30], Step [790/1250], Loss: 0.0564\n",
            "Epoch [29/30], Step [800/1250], Loss: 0.0666\n",
            "Epoch [29/30], Step [810/1250], Loss: 0.0749\n",
            "Epoch [29/30], Step [820/1250], Loss: 0.0822\n",
            "Epoch [29/30], Step [830/1250], Loss: 0.0013\n",
            "Epoch [29/30], Step [840/1250], Loss: 0.0383\n",
            "Epoch [29/30], Step [850/1250], Loss: 0.0007\n",
            "Epoch [29/30], Step [860/1250], Loss: 0.0473\n",
            "Epoch [29/30], Step [870/1250], Loss: 0.0024\n",
            "Epoch [29/30], Step [880/1250], Loss: 0.0021\n",
            "Epoch [29/30], Step [890/1250], Loss: 0.1104\n",
            "Epoch [29/30], Step [900/1250], Loss: 0.0004\n",
            "Epoch [29/30], Step [910/1250], Loss: 0.0215\n",
            "Epoch [29/30], Step [920/1250], Loss: 0.0287\n",
            "Epoch [29/30], Step [930/1250], Loss: 0.0047\n",
            "Epoch [29/30], Step [940/1250], Loss: 0.0073\n",
            "Epoch [29/30], Step [950/1250], Loss: 0.0542\n",
            "Epoch [29/30], Step [960/1250], Loss: 0.0132\n",
            "Epoch [29/30], Step [970/1250], Loss: 0.0024\n",
            "Epoch [29/30], Step [980/1250], Loss: 0.0003\n",
            "Epoch [29/30], Step [990/1250], Loss: 0.0106\n",
            "Epoch [29/30], Step [1000/1250], Loss: 0.0306\n",
            "Epoch [29/30], Step [1010/1250], Loss: 0.0011\n",
            "Epoch [29/30], Step [1020/1250], Loss: 0.0150\n",
            "Epoch [29/30], Step [1030/1250], Loss: 0.0019\n",
            "Epoch [29/30], Step [1040/1250], Loss: 0.0405\n",
            "Epoch [29/30], Step [1050/1250], Loss: 0.0268\n",
            "Epoch [29/30], Step [1060/1250], Loss: 0.0116\n",
            "Epoch [29/30], Step [1070/1250], Loss: 0.0002\n",
            "Epoch [29/30], Step [1080/1250], Loss: 0.0009\n",
            "Epoch [29/30], Step [1090/1250], Loss: 0.0129\n",
            "Epoch [29/30], Step [1100/1250], Loss: 0.0178\n",
            "Epoch [29/30], Step [1110/1250], Loss: 0.0387\n",
            "Epoch [29/30], Step [1120/1250], Loss: 0.0005\n",
            "Epoch [29/30], Step [1130/1250], Loss: 0.0496\n",
            "Epoch [29/30], Step [1140/1250], Loss: 0.0150\n",
            "Epoch [29/30], Step [1150/1250], Loss: 0.0146\n",
            "Epoch [29/30], Step [1160/1250], Loss: 0.1843\n",
            "Epoch [29/30], Step [1170/1250], Loss: 0.0123\n",
            "Epoch [29/30], Step [1180/1250], Loss: 0.0284\n",
            "Epoch [29/30], Step [1190/1250], Loss: 0.0315\n",
            "Epoch [29/30], Step [1200/1250], Loss: 0.0855\n",
            "Epoch [29/30], Step [1210/1250], Loss: 0.0160\n",
            "Epoch [29/30], Step [1220/1250], Loss: 0.0087\n",
            "Epoch [29/30], Step [1230/1250], Loss: 0.0340\n",
            "Epoch [29/30], Step [1240/1250], Loss: 0.0282\n",
            "Epoch [29/30], Step [1250/1250], Loss: 0.0069\n",
            "Epoch [30/30], Step [10/1250], Loss: 0.0057\n",
            "Epoch [30/30], Step [20/1250], Loss: 0.0014\n",
            "Epoch [30/30], Step [30/1250], Loss: 0.0142\n",
            "Epoch [30/30], Step [40/1250], Loss: 0.0012\n",
            "Epoch [30/30], Step [50/1250], Loss: 0.0005\n",
            "Epoch [30/30], Step [60/1250], Loss: 0.0391\n",
            "Epoch [30/30], Step [70/1250], Loss: 0.0018\n",
            "Epoch [30/30], Step [80/1250], Loss: 0.0442\n",
            "Epoch [30/30], Step [90/1250], Loss: 0.0035\n",
            "Epoch [30/30], Step [100/1250], Loss: 0.0021\n",
            "Epoch [30/30], Step [110/1250], Loss: 0.0138\n",
            "Epoch [30/30], Step [120/1250], Loss: 0.0168\n",
            "Epoch [30/30], Step [130/1250], Loss: 0.0006\n",
            "Epoch [30/30], Step [140/1250], Loss: 0.0030\n",
            "Epoch [30/30], Step [150/1250], Loss: 0.0134\n",
            "Epoch [30/30], Step [160/1250], Loss: 0.0071\n",
            "Epoch [30/30], Step [170/1250], Loss: 0.0007\n",
            "Epoch [30/30], Step [180/1250], Loss: 0.0077\n",
            "Epoch [30/30], Step [190/1250], Loss: 0.0010\n",
            "Epoch [30/30], Step [200/1250], Loss: 0.0223\n",
            "Epoch [30/30], Step [210/1250], Loss: 0.0028\n",
            "Epoch [30/30], Step [220/1250], Loss: 0.0006\n",
            "Epoch [30/30], Step [230/1250], Loss: 0.0120\n",
            "Epoch [30/30], Step [240/1250], Loss: 0.0015\n",
            "Epoch [30/30], Step [250/1250], Loss: 0.0013\n",
            "Epoch [30/30], Step [260/1250], Loss: 0.0011\n",
            "Epoch [30/30], Step [270/1250], Loss: 0.0163\n",
            "Epoch [30/30], Step [280/1250], Loss: 0.0407\n",
            "Epoch [30/30], Step [290/1250], Loss: 0.0095\n",
            "Epoch [30/30], Step [300/1250], Loss: 0.0011\n",
            "Epoch [30/30], Step [310/1250], Loss: 0.0005\n",
            "Epoch [30/30], Step [320/1250], Loss: 0.0055\n",
            "Epoch [30/30], Step [330/1250], Loss: 0.0210\n",
            "Epoch [30/30], Step [340/1250], Loss: 0.0066\n",
            "Epoch [30/30], Step [350/1250], Loss: 0.0051\n",
            "Epoch [30/30], Step [360/1250], Loss: 0.0035\n",
            "Epoch [30/30], Step [370/1250], Loss: 0.0003\n",
            "Epoch [30/30], Step [380/1250], Loss: 0.0213\n",
            "Epoch [30/30], Step [390/1250], Loss: 0.0006\n",
            "Epoch [30/30], Step [400/1250], Loss: 0.0229\n",
            "Epoch [30/30], Step [410/1250], Loss: 0.0781\n",
            "Epoch [30/30], Step [420/1250], Loss: 0.0017\n",
            "Epoch [30/30], Step [430/1250], Loss: 0.0013\n",
            "Epoch [30/30], Step [440/1250], Loss: 0.3470\n",
            "Epoch [30/30], Step [450/1250], Loss: 0.0002\n",
            "Epoch [30/30], Step [460/1250], Loss: 0.0835\n",
            "Epoch [30/30], Step [470/1250], Loss: 0.0487\n",
            "Epoch [30/30], Step [480/1250], Loss: 0.0518\n",
            "Epoch [30/30], Step [490/1250], Loss: 0.0104\n",
            "Epoch [30/30], Step [500/1250], Loss: 0.0021\n",
            "Epoch [30/30], Step [510/1250], Loss: 0.0048\n",
            "Epoch [30/30], Step [520/1250], Loss: 0.0024\n",
            "Epoch [30/30], Step [530/1250], Loss: 0.0063\n",
            "Epoch [30/30], Step [540/1250], Loss: 0.0471\n",
            "Epoch [30/30], Step [550/1250], Loss: 0.0008\n",
            "Epoch [30/30], Step [560/1250], Loss: 0.0483\n",
            "Epoch [30/30], Step [570/1250], Loss: 0.0098\n",
            "Epoch [30/30], Step [580/1250], Loss: 0.0025\n",
            "Epoch [30/30], Step [590/1250], Loss: 0.0101\n",
            "Epoch [30/30], Step [600/1250], Loss: 0.0006\n",
            "Epoch [30/30], Step [610/1250], Loss: 0.0014\n",
            "Epoch [30/30], Step [620/1250], Loss: 0.0352\n",
            "Epoch [30/30], Step [630/1250], Loss: 0.0105\n",
            "Epoch [30/30], Step [640/1250], Loss: 0.0677\n",
            "Epoch [30/30], Step [650/1250], Loss: 0.0320\n",
            "Epoch [30/30], Step [660/1250], Loss: 0.0055\n",
            "Epoch [30/30], Step [670/1250], Loss: 0.0160\n",
            "Epoch [30/30], Step [680/1250], Loss: 0.0021\n",
            "Epoch [30/30], Step [690/1250], Loss: 0.0011\n",
            "Epoch [30/30], Step [700/1250], Loss: 0.0180\n",
            "Epoch [30/30], Step [710/1250], Loss: 0.0264\n",
            "Epoch [30/30], Step [720/1250], Loss: 0.0185\n",
            "Epoch [30/30], Step [730/1250], Loss: 0.2592\n",
            "Epoch [30/30], Step [740/1250], Loss: 0.0077\n",
            "Epoch [30/30], Step [750/1250], Loss: 0.0014\n",
            "Epoch [30/30], Step [760/1250], Loss: 0.0168\n",
            "Epoch [30/30], Step [770/1250], Loss: 0.0011\n",
            "Epoch [30/30], Step [780/1250], Loss: 0.0048\n",
            "Epoch [30/30], Step [790/1250], Loss: 0.0194\n",
            "Epoch [30/30], Step [800/1250], Loss: 0.0100\n",
            "Epoch [30/30], Step [810/1250], Loss: 0.0888\n",
            "Epoch [30/30], Step [820/1250], Loss: 0.0740\n",
            "Epoch [30/30], Step [830/1250], Loss: 0.0630\n",
            "Epoch [30/30], Step [840/1250], Loss: 0.0028\n",
            "Epoch [30/30], Step [850/1250], Loss: 0.0193\n",
            "Epoch [30/30], Step [860/1250], Loss: 0.0011\n",
            "Epoch [30/30], Step [870/1250], Loss: 0.0003\n",
            "Epoch [30/30], Step [880/1250], Loss: 0.0041\n",
            "Epoch [30/30], Step [890/1250], Loss: 0.0167\n",
            "Epoch [30/30], Step [900/1250], Loss: 0.0060\n",
            "Epoch [30/30], Step [910/1250], Loss: 0.0119\n",
            "Epoch [30/30], Step [920/1250], Loss: 0.0832\n",
            "Epoch [30/30], Step [930/1250], Loss: 0.0135\n",
            "Epoch [30/30], Step [940/1250], Loss: 0.0286\n",
            "Epoch [30/30], Step [950/1250], Loss: 0.2238\n",
            "Epoch [30/30], Step [960/1250], Loss: 0.0002\n",
            "Epoch [30/30], Step [970/1250], Loss: 0.0251\n",
            "Epoch [30/30], Step [980/1250], Loss: 0.0689\n",
            "Epoch [30/30], Step [990/1250], Loss: 0.0020\n",
            "Epoch [30/30], Step [1000/1250], Loss: 0.0093\n",
            "Epoch [30/30], Step [1010/1250], Loss: 0.0088\n",
            "Epoch [30/30], Step [1020/1250], Loss: 0.0091\n",
            "Epoch [30/30], Step [1030/1250], Loss: 0.0030\n",
            "Epoch [30/30], Step [1040/1250], Loss: 0.0010\n",
            "Epoch [30/30], Step [1050/1250], Loss: 0.0060\n",
            "Epoch [30/30], Step [1060/1250], Loss: 0.0007\n",
            "Epoch [30/30], Step [1070/1250], Loss: 0.0064\n",
            "Epoch [30/30], Step [1080/1250], Loss: 0.0027\n",
            "Epoch [30/30], Step [1090/1250], Loss: 0.0008\n",
            "Epoch [30/30], Step [1100/1250], Loss: 0.1724\n",
            "Epoch [30/30], Step [1110/1250], Loss: 0.0009\n",
            "Epoch [30/30], Step [1120/1250], Loss: 0.0077\n",
            "Epoch [30/30], Step [1130/1250], Loss: 0.0019\n",
            "Epoch [30/30], Step [1140/1250], Loss: 0.0050\n",
            "Epoch [30/30], Step [1150/1250], Loss: 0.0050\n",
            "Epoch [30/30], Step [1160/1250], Loss: 0.0041\n",
            "Epoch [30/30], Step [1170/1250], Loss: 0.0083\n",
            "Epoch [30/30], Step [1180/1250], Loss: 0.0285\n",
            "Epoch [30/30], Step [1190/1250], Loss: 0.0097\n",
            "Epoch [30/30], Step [1200/1250], Loss: 0.0095\n",
            "Epoch [30/30], Step [1210/1250], Loss: 0.0423\n",
            "Epoch [30/30], Step [1220/1250], Loss: 0.0019\n",
            "Epoch [30/30], Step [1230/1250], Loss: 0.0010\n",
            "Epoch [30/30], Step [1240/1250], Loss: 0.0064\n",
            "Epoch [30/30], Step [1250/1250], Loss: 0.0005\n",
            "Training Done\n",
            "22248698.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    n_samples += labels.size(0)\n",
        "    n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      label = labels[i]\n",
        "      pred = predicted[i]\n",
        "      if (label == pred):\n",
        "        n_class_correct[label] += 1\n",
        "      n_class_samples[label] += 1\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Accuracy of the network: {acc}%')\n",
        "\n",
        "  for i in range(10):\n",
        "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "    print(f'Accuracy of {classes[i]}: {acc}%')"
      ],
      "metadata": {
        "id": "WXtpG_UB2ZsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3ebd99-cae5-496e-ed70-017f480da076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network: 78.53%\n",
            "Accuracy of plane: 81.9%\n",
            "Accuracy of car: 86.6%\n",
            "Accuracy of bird: 62.0%\n",
            "Accuracy of cat: 58.1%\n",
            "Accuracy of deer: 73.7%\n",
            "Accuracy of dog: 74.5%\n",
            "Accuracy of frog: 84.7%\n",
            "Accuracy of horse: 86.4%\n",
            "Accuracy of ship: 88.7%\n",
            "Accuracy of truck: 88.7%\n"
          ]
        }
      ]
    }
  ]
}